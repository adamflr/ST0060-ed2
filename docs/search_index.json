[["index.html", "R-anvisningar till Grundläggande statistik Introduktion", " R-anvisningar till Grundläggande statistik 2024-10-06 Introduktion Detta dokument ger en introduktion till R för en kurs i grundläggande statistik. "],["installation-av-r-och-rstudio.html", "Installation av R och RStudio 0.1 Inledning 0.2 Installation av R 0.3 Installation av RStudio 0.4 Gränssnittet i RStudio 0.5 Paket i R", " Installation av R och RStudio 0.1 Inledning För att köra R-kod på sin dator krävs en installation av programspråket R. För att effektivt arbeta i R används ofta en utvecklingsmiljö (ett tilläggsprogram som på flera sätt förenklar arbetet) och här ges anvisningar till RStudio - den vanligaste utvecklingsmiljön för R. För att komma ingång måste man alltså installera R och RStudio. 0.2 Installation av R Programspråket R kan laddas ner från https://www.r-project.org/ med följande steg: Klicka på CRAN längst upp till vänster. Klicka på den översta länken under 0-Cloud. Välj en nedladdning beroende på operativsystem. För Windows, välj base. För macOS, välj den senaste tillgängliga versionen. Installera R från den nedladdade filen. Installation sker som för andra nedladdade program. 0.3 Installation av RStudio RStudio kan laddas ner från https://www.posit.co/ med följande steg: Klicka på Download RStudio uppe till höger. Scrolla nedåt och välj Download under Install RStudio. Installera RStudio från den nedladdade filen. Installation sker som för andra nedladdade program. 0.4 Gränssnittet i RStudio När man nu öppnar RStudio ser man att fönstret är uppdelat i fyra delar och att varje del består av en eller flera flikar. De viktigaste är i nuläget Console där kod körs och resultat skrivs ut, Environment där man ser skapade objekt, History där man ser tidigare körd kod, Plots där man ser skapade grafer, och Help där man ser hjälpsidor för funktioner. Ofta skriver man inte sin kod direkt i konsollen, utan i ett separat skript - en vanlig textfil som innehåller den kod man vill köra. Genom att organisera sin kod i ett skript kan man lätt strukturera och dokumentera sitt arbete. I RStudio kan man öppna ett nytt skript genom att gå till File &gt; New File &gt; R Script eller genom att klicka Ctrl + Shift + N. Ett tomt skript öppnar sig då i det övre vänstra delfönstret. Om man skriver a &lt;- 5 i skriptet och trycker Ctrl + Enter bör man se att koden i skriptet körs i konsollen. Om man tittar i fliken Environment ska man också se att det nu skapats ett objekt a. 0.5 Paket i R En av de stora styrkorna med R är att språket kan byggas ut av dess användare. De här tilläggen kan sedan samlas i paket (packages) och delas med andra. Rs officiella bibliotek för paket kallas för CRAN (Comprehensive R Archive Network) och består av drygt 20 000 uppladdade paket som innehåller allt från fritt tillgänglig data till avancerade statistiska modeller. För att använda ett specifikt paket måste det först installeras. Om man vet namnet på paketet man vill installera kan man köra install.packages(&quot;tidyverse&quot;) I det här fallet installeras paketet tidyverse, vilket innehåller funktioner för hantering av data. I RStudio kan man också installera paket från Packages-fliken. Paket måste också laddas för varje ny session. Innan man kan använda innehållet i ett paket måste man därför köra library(tidyverse) "],["datahantering-och-grafer.html", "1 Datahantering och grafer 1.1 Uppstart och orientering 1.2 Packages från CRAN 1.3 Objekt och funktioner 1.4 Sekvenser av funktioner 1.5 Datainskrivning 1.6 Urval ur en tabell med select och filter 1.7 Grafer med ggplot2 1.8 AI-uppgift I", " 1 Datahantering och grafer Datorövning 1 handlar om grunderna till R. Efter övningen ska vi kunna Starta RStudio och orientera oss i gränssnittet, Installera och ladda tilläggspaket (Packages), Definera objekt och tillämpa funktioner i R, Transformera en tabell med data genom att välja kolumner och filtrera rader, Skapa grafer med ggplot2. 1.1 Uppstart och orientering För att arbeta i R måste vi installera språket R och ett gränssnitt för att arbeta i R, vanligen RStudio. Både R och RStudio kan laddas ner gratis, från https://www.r-project.org/ respektive https://posit.co/. Starta RStudio, till exempel genom att gå till Startmenyn och söka på RStudio eller genom att dubbelklicka på en fil som öppnas i RStudio. Gränssnittet i RStudio är uppdelat i fyra delar och varje del består av en eller flera flikar. De viktigaste är i nuläget Console där kod körs och resultat skrivs ut, Environment där man ser skapade objekt, History där man ser tidigare körd kod, Plots där man ser skapade grafer, och Help där man ser hjälpsidor för funktioner. Uppgift 1.1 (Help-fliken) Hitta fliken Help, klicka på husikonen under fliken. Finns det en länk med RStudio Cheat Sheets? Följ den länken för att hitta guider till R som kan bli nyttiga längre fram. För nu, gå tillbaka till RStudio. Ofta skriver man inte sin kod direkt i konsollen, utan i ett separat skript - en vanlig textfil som innehåller den kod man vill köra. I RStudio kan man öppna ett nytt skript genom att gå till File &gt; New File &gt; R Script eller genom att klicka Ctrl + Shift + N. Uppgift 1.2 (Ett första skript) Öppna ett nytt skript genom File-menyn eller genom Ctrl + Shift + N. Skriv a &lt;- 5 i skriptet och tryck Ctrl + Enter. Titta i flikarna Console och Environment. Har något hänt? Du bör se att koden i skriptet körts i konsollen och att ett nytt objekt a ligger i Environment. 1.2 Packages från CRAN En av de stora styrkorna med R är att språket kan byggas ut av dess användare. De här tilläggen kan sedan samlas i paket (packages) och delas med andra. Rs officiella bibliotek för paket kallas för CRAN (Comprehensive R Archive Network). För att använda ett specifikt paket måste det först installeras. Om man vet namnet på paketet man vill installera kan man köra install.packages(&quot;tidyverse&quot;) I det här fallet installeras paketet tidyverse, vilket innehåller funktioner för hantering av data. I RStudio kan man också installera paket från Packages-fliken. Uppgift 1.3 (Installera tidyverse-paketet) Kör raden ovan för att installera tidyverse. Du kan antingen köra raden genom att skriva den i Console eller genom att skriva i ett skript och köra därifrån genom Ctrl + Enter. Uppgift 1.4 (Installera gapminder-paketet) Paketet gapminder innehåller lite intressant data vi kommer använda senare. Installera paketet gapminder genom att fylla i den saknade biten och köra raden nedan. install.packages(&quot;___&quot;) Paket måste också laddas för varje ny session. Innan man kan använda innehållet i ett paket måste man därför köra library(tidyverse) Uppgift 1.5 (Ladda gapminder-paketet) Ladda paketet gapminder genom att fylla i och köra raden nedan. library(___) Uppgift 1.6 (Paket som inte finns) Vad händer om man försöker installera ett paket som inte finns på CRAN? Testa till exempel install.packages(&quot;ThisIsNotTheNameOfAnyPackage&quot;) och library(ThisIsNotTheNameOfAnyPackage) 1.3 Objekt och funktioner Ett objekt i R är en namngiven informationsmängd. Objekt kan se ut på många olika sätt - under kursens gång används objekt som består av insamlad data (konstruerade som vektorer eller tabeller), objekt som är statistiska modeller, och flera andra former. I R skapar man objekt med assign-pilen &lt;- (mindre än och bindestreck). I ett tidigare exempel fanns raden a &lt;- 5 Här skapas ett objekt med namnet a som innehåller informationen 5. Assign-pilen pekar alltså på det namn man vill ge objektet och pekar från objektets innehåll. Ett lite mer komplicerat exempel på ett objekt ges av b &lt;- c(3, 1, 4, 1, 5, 9) Här skapas ett objekt b som innehåller en serie numeriska värden (en vektor). Värdena i en vektor är ordnade och man kan plocka ut ett specifikt värde med hakparenteser. b[3] # Det tredje värdet i vektorn b ## [1] 4 b[c(3,5)] # Det tredje och femte värdet i b ## [1] 4 5 Uppgift 1.7 (Skapa en vektor) Skapa ett objekt med namnet new_vector som innehåller värden 5, 7 och 10 genom att fylla i följande rad. new_vector &lt;- c(_, _, _) Uppgift 1.8 (Ta ut andra värdet) Använd hakparenteser för att plocka ut det andra värdet ur vektorn new_vector. Objekt kan manipuleras genom att tillämpa funktioner. En funktion tar någon ingående data och ger något utgående resultat. Funktioner anges genom att skriva funktionens namn följt av ingående data inom parenteser, och resultatet kan antingen skrivas ut i konsollen eller sparas som ett nytt objekt. En grundinstallation av R innehåller en mängd färdiga funktioner, t.ex. sum(b) ## [1] 23 vilket ger summan av värdena i vektorn b, plot(b) som ger en simpel graf, och sqrt(b) ## [1] 1.732051 1.000000 2.000000 1.000000 2.236068 3.000000 som beräknar kvadratroten för varje element i vektorn. Uppgift 1.9 (Summera vektorn) Fyll i och kör följande rad för att beräkna summan av vektorn new_vector sum(___) Vid konstruktionen av vektorn användes också en grundläggande funktion - funktionen c(), som tar en serie värden och skapar en sammanhängande vektor av värden. Alla R-funktioner har en tillhörande hjälpfil som kan plockas fram genom att skriva frågetecken följt av funktionsnamnet, t.ex. ?sum. Från hjälpfilen får man att sum() tar numeriska vektorer som ingående värde och beräknar summan. Man kan styra funktionens beteende genom att sätta ett argument na.rm (vilket här styr hur funktionen hanterar saknade värden). Som illustration kan man titta på b &lt;- c(3, 1, 4, 1, 5, 9, NA) # Lägger till ett saknat värde sum(b) # na.rm = FALSE är grundinställning ## [1] NA sum(b, na.rm = TRUE) # na.rm sätts till TRUE ## [1] 23 Det första försöket sum(b) ger utfallet NA, men om man sätter na.rm = TRUE beräknas summan efter att det saknade värdet plockats bort. Notera också att skript kan kommenteras med #. 1.4 Sekvenser av funktioner Ofta vill man genomföra flera operationer på ett objekt. Man behöver då genomföra en sekvens av funktioner. Säg till exempel att man har värdena \\[(-4, -2, -1, 1, 2, 4)\\] och vill ta absolutvärde (vilket gör negativa tal till motsvarande positiva tal) och sedan summera. Den typen av sekvenser kan genomföras på ett par olika sätt. Ett första sätt är att spara resultatet i varje steg och sedan använda utfallet i nästa steg: c &lt;- c(-4, -2, -1, 1, 2, 4) # Skapa en vektor av värden c_absolute &lt;- abs(c) # Ta absolutvärden. Skapa c_absolut sum(c_absolute) # Summera värden i c_absolut ## [1] 14 Här skapas ett objekt c som innehåller en vektor där några tal är negativa. I nästa rad används abs för att skapa absolutvärden. Slutligen summeras absolutvärdena med sum. Notera att det är möjligt att skapa ett objekt med namnet c trots att det redan är namnet på en funktion - R förstår ur sammanhanget om objektet eller funktionen ska användas. Det kan dock bli lite oklart för en läsare, så försök som regel att undvika att skapa objekt med vanliga funktionsnamn som sum och mean. Uppgift 1.10 (Kvadrat, summa och roten ur) Fyll i och kör följande rader för att ta varje värde i new_vector i kvadrat, sedan summera, och sedan ta roten ur. new_vector_squared &lt;- new_vector^2 # Ta kvadraten av varje värde new_vector_squared_sum &lt;- sum(___) # Summera kvadraterna sqrt(___) # Ta kvadratroten ur summan Ett alternativ till att spara utfallet i varje steg är att skriva en senare funktion runt en tidigare funktion. Det fungerar för att R utvärderar funktioner inifrån-ut. Med samma exempel som tidigare får man sum(abs(c(-4, -2, -1, 1, 2, 4))) # Ta summan av absolutvärden av vektorn medan beräkningen i övningen blir sqrt(sum(new_vector^2)) # Ta roten ur summan av vektorn i kvadrat Den här typen av skrivning kan spara plats men blir snabbt svårläst. Ett sista alternativ är att använda en så kallad pipe (namnet kommer från att en sekvens funktioner kallas en pipeline). En pipe skrivs %&gt;% och kan i RStudio tas fram med kortkommandon Ctrl + Shift + M. Pipen tar utfallet av en funktion till vänster och sänder till en funktion till höger. Den kan utläsas i dagligt tal som och sen. Med samma exempel som tidigare kan vi skriva library(tidyverse) c(-4, -2, -1, 1, 2, 4) %&gt;% # Skapa en datamängd och sen abs() %&gt;% # ta absolutvärden, och sen sum() # beräkna summan. ## [1] 14 Uppgift 1.11 (Kvadrat, summa och rot med pipe) Fyll i de saknade funktionerna och kör följande rader för att ta varje värde i new_vector i kvadrat, sedan summera, och sedan ta roten ur, denna gång genom att länka funktionerna med en pipe %&gt;%. new_vector^2 %&gt;% # Ta kvadraterna av new_vector, och sen ___() %&gt;% # beräkna summan, och sen ____() # Ta kvadratroten med sqrt() 1.5 Datainskrivning Det första praktiska steget i en statistisk analys är att importera data. I R kan det göras genom att direkt skriva in sin data och spara som ett nytt objekt, men ett bättre och vanligare sätt är att importera sin data från en extern fil eller databas. I ett tidigare exempel användes funktionen c() för att skapa en vektor av data. Ofta ordnas flera vektorer i en tabell där varje kolumn är en vektor och varje rad en observation av någon enhet. En datatabell (en data.frame i R) skapas genom funktionen data.frame() följt av namngivna vektorer. Exempeldata kan skrivas in genom föjande. dat &lt;- data.frame(Vecka = c(7,7,7,7,7,7, 11,11,11,11,11,11), Behandling = c(&quot;A&quot;,&quot;A&quot;,&quot;A&quot;,&quot;B&quot;,&quot;B&quot;,&quot;B&quot;, &quot;A&quot;,&quot;A&quot;,&quot;A&quot;,&quot;B&quot;,&quot;B&quot;,&quot;B&quot;), Vikt = c(232,161,148,368,218,257, 1633,2213,972,2560,2430,855), N = c(2.63,2.90,2.99,3.54,3.30,2.85, 1.53,1.90,NA,2.58,NA,NA)) dat Radbrytningar och blanksteg är oviktiga i R, och används bara för läsbarhet här. Saknade värden skrivs in som NA för not available. Notera att alla kolumner inte behöver vara av samma datatyp men att värden inom en kolumn måste vara det. Här är Behandling text medan övriga kolumner är numeriska. Uppgift 1.12 (Alea iacta est) Kasta din tärning tio gånger och skriv in resultatet i en datatabell i R med hjälp av grundkoden nedan. Om du saknar en tärning, fråga lämplig person om du kan få en. Behåll tärningen, den behövs till nästa datorövning (och närhelst man står inför ett avgörande livsbeslut). dat_dice &lt;- data.frame(Kast = c(1,2,3,4,5,6,7,8,9,10), Utfall = c(_,_,_,_,_,_,_,_,_,_)) dat_dice Objektet dat är av typen data.frame - en tabell med rader och kolumner. Man kan ange en specifik kolumn i en data.frame med dollartecken följt av kolumnens namn. dat$Vikt ## [1] 232 161 148 368 218 257 1633 2213 972 2560 2430 855 Man kan också plocka ut rader och kolumner med hakparenteser och ordningstal. dat[2,3] # Andra raden och tredje kolumnen dat[2, ] # Tomt värde ger alla värden. dat[ ,3] # Alla värden i kolumn 3 Uppgift 1.13 (Plocka ut en specifik kolumn) I den tidigare övningen skapade du ett objekt dat_dice. Använd dollartecken för att plocka ut kolumnen Utfall från det objektet. dat_dice$___ Genom att plocka ut en kolumn från en data.frame kan man beräkna vanlig beskrivande statistik med funktioner som mean() (medelvärde) och sd() (standardavvikelsen). mean(dat$Vikt) ## [1] 1003.917 sd(dat$Vikt) ## [1] 951.3067 Funktionen plot() ger en enkel graf. plot(dat$Vecka, dat$Vikt) Uppgift 1.14 (Tärningsgraf) Använd datan i objektet dat_dice och skapa ett diagram med kolumnen kast på x-axeln och kolumnen Utfall på y-axeln. plot(dat_dice$___, dat_dice$___) 1.6 Urval ur en tabell med select och filter En vanlig operation på en tabell är att göra ett urval - antingen ett urval av rader (t.ex. ett visst land), vilket kallas filtrering eller ett urval av variabler (t.ex. land och befolkning), vilket kallas selektion. Här tittar vi på hur det kan göras med funktionerna filter() och select() från paketet tidyverse. Vi använder gapminder-datan som kan laddas med library(gapminder). För att filtrera på ett givet land kan man använda pipe-funktionen från datan till en filter-funktion, t.ex. gapminder %&gt;% # Ta gapminder-datan och sen filter(country == &quot;Sweden&quot;) # filtrera för ett land Inom filterfunktionen anges ett logisk villkor country == \"Sweden\" och utfallet är de rader där villkoret är sant. Notera de dubbla likhetstecknen - de måste användas för ett logisk villkor eftersom enkelt likhetstecken används för att skapa objekt och sätta funktionsargument. Uppgift 1.15 (Filtrera för land) Vad måste ändras i koden för att istället plocka ut rader där landet är Finland? Hur många rader har det urvalet i datan? gapminder %&gt;% # Ta gapminder-datan och sen filter(country == &quot;Sweden&quot;) # filtrera för ett land Om man vill välja flera länder kan man använda funktionen %in% på ett liknande sätt. gapminder %&gt;% filter(country %in% c(&quot;Sweden&quot;, &quot;Finland&quot;)) och om man vill ha mer än ett villkor kan man rada dem i filter-funktionen: gapminder %&gt;% # Ta datan, och sen filter(country %in% c(&quot;Sweden&quot;, &quot;Finland&quot;), # filtrera för land year == 2002) # och för år För att se fler eller färre rader kan man använda en pipe %&gt;% till funktionen print(). Följande skriver ut fem rader gapminder %&gt;% filter(country %in% c(&quot;Sweden&quot;, &quot;Finland&quot;)) %&gt;% print(n = 5) Om man istället vill göra ett urval av kolumner kan man använda select(). Som argument anges de kolumner man vill välja, t.ex. gapminder %&gt;% # Ta datan, och sen select(country, lifeExp) # välj kolumner Uppgift 1.16 (Befolkade länder) Funktionen arrange() sorterar data efter en angiven kolumn. Följande stycke ger oss Europas länder efter befolkning. gapminder %&gt;% filter(continent == &quot;Europe&quot;, year == 1962) %&gt;% select(country, lifeExp, pop) %&gt;% arrange(-pop) Gör lämpliga ändringar för att få Asiens länder från 2002 ordnade efter förväntad medellivslängd. 1.7 Grafer med ggplot2 Vi kan nu börja titta på grafer. R har en mängd grundläggande funktioner för grafer. Vi såg tidigare ett exempel på funktionen plot(). gm_2002 &lt;- gapminder %&gt;% filter(year == 2002) plot(gm_2002$lifeExp, gm_2002$gdpPercap) Ett object gm_2002skapas efter att ha filtrerat för året 2002. Tecknet $ används för att välja kolumnerna lifeExp och gdpPercap ur objektet gm_2002. För mer avancerade grafer används dock ofta funktioner ur Rs paketbibliotek. Här illustreras det mest populära - ggplot2. I ggplot2 byggs grafer upp med tre grundläggande byggstenar: data, informationen man vill visualisera, aestethics, en koppling mellan data och visuella element såsom grafens axlar, objekts storlek och färg, geometries, de geometriska former som visas i grafen. En graf skrivs med en startfunktion ggplot som anger namnet på datan och grafens aestethics, och därefter sätts geometriska element genom funktioner som börjar med geom_. Ett spridningsdiagram kan t.ex. skapas med geom_point. ggplot(gm_2002, aes(x = lifeExp, y = gdpPercap)) + geom_point() Grafen kan byggas ut genom att sätta aestethics för färg och storlek. Man kan också dela en graf i småfönster med facet_wrap och styra grafens utseende genom att sätta ett tema såsom theme_bw. ggplot(gm_2002, aes(x = lifeExp, y = gdpPercap, color = continent, size = pop)) + geom_point() + facet_wrap(~ continent) Uppgift 1.17 (Livslängd över tid) Vad ska ändras i stycket nedan för att skapa en graf med år på x-axeln, medellivslängd på y-axeln och skilda småfönster för olika kontinenter? ggplot(gm_2002, aes(x = ____, y = ____)) + geom_point() + facet_wrap(~ continent) Andra graftyper kan skapas med andra geom_-funktioner. Stapeldiagram ges av geom_col (col för column). Man kan också använda geom_bar om man bara vill räkna antal rader per någon kategori. Följande väljer ut en kontinent och år och plottar ländernas befolkning stapeldiagram. dat_small &lt;- gapminder %&gt;% filter(continent == &quot;Europe&quot;, year == &quot;2002&quot;) ggplot(dat_small, aes(pop, country, fill = gdpPercap)) + geom_col(color = &quot;black&quot;) Argumentet fill styr färgen för ytor (här staplarnas ytor) medan color i geom_col() styr kanten runt varje stapel. Man kan styra grafiken i en ggplot genom funktionen theme(). Det är ett ganska komplicerat ämne, men låt oss titta på några grunder. Vi börjar med att skapa en enkel graf: en boxplot över medellivslängd per kontinent. dat_small &lt;- gapminder %&gt;% filter(year == 2002) ggplot(dat_small, aes(x = lifeExp, y = continent)) + geom_boxplot() Vi kan ändra utseendet på grafen genom argument inom geometrier och med funktionen theme(). I theme() sätter man de specifika egenskaper man vill ändra genom att tillskriva dem ett element. Valet av element beror på typen av grafiskt objekt - text sätts t.ex. med element_text() och ytor med element_rect() (för rectangle). Vi ger ett exempel med ändrad bakgrund, rutmönster, och teckenstorlek. ggplot(dat_small, aes(lifeExp, continent)) + geom_boxplot(fill = &quot;lightblue&quot;) + theme(panel.background = element_rect(fill = &quot;red3&quot;), text = element_text(size = 15, color = &quot;white&quot;, family = &quot;serif&quot;), axis.text = element_text(color = &quot;white&quot;), plot.background = element_rect(fill = &quot;grey30&quot;, color = &quot;black&quot;), panel.grid.major.y = element_blank()) Uppgift 1.18 (Temaval 1) Ändra färgvalen i grafen ovan för att skapa snyggast möjliga graf. Funktionen colors() ger de färger som finns tillängliga i R. Man kan också använda hex-koden för färger, t.ex. fill = \"#ffdd00\". Uppgift 1.19 (Temaval 2) Ändra färgvalen i grafen ovan för att skapa fulast möjliga graf. Visa de två graferna för någon annan och se om de kan säga vilken som är vilken. 1.8 AI-uppgift I Nedan har vi en graf gjord med ggplot2 med flera olika geom och ändringar från standardtemat. Uppgift 1.20 (Dekonstruera grafen) Vilka geografiska former (punkter, linjer ytor) visas i grafen och hur är de kopplade till datans variabler? Vilka ändringar har gjorts från standardtemat (bakgrundsfärg, typsnitt, teckenstorlek)? Uppgift 1.21 (Rekonstrera grafen) Använd en chatbot (såsom Microsofts co-pilot eller OpenAIs ChatGPT) för att rekonstrera grafen. Börja med att beskriva grafen i ord och be om R-kod. Klipp ut koden och kör i R. Läs koden du fått. Finns det några delar som är svåra att förstå. Med vissa chatverktyg kan man också klippa in bilden och be om den bakomliggande koden. Uppgift 1.22 (Steg i Excel) Hur skulle man gå tillväga för att skapa samma graf i Excel? Be en chatbot om en stegvis instruktion. "],["beskrivande-statistik.html", "2 Beskrivande statistik 2.1 Repetition från datorövning 1 2.2 Import av data från en Excelfil 2.3 Ändra och skapa nya kolumner med mutate 2.4 Sammanfattande lägesmått 2.5 Sammanfattande spridningsmått 2.6 Ordna upp beskrivande statistik och exportera 2.7 Kumulativt medelvärde 2.8 Tredimensionella grafer med plotly 2.9 AI-uppgift II", " 2 Beskrivande statistik Datorövning 2 handlar om beräkning av beskrivande statistik i R. Efter övningen ska vi kunna Importera data från en excelfil, Beräkna lämpliga lägesmått för en variabel, Beräkna lämpliga spridningsmått för en variabel, Konstruera grafer som jämför två eller flera gruppers läge och spridning. 2.1 Repetition från datorövning 1 När man arbetar i R är det klokt att använda ett avancerat gränssnitt som RStudio och att skriva sin kod i ett separat skript. I RStudio kan man starta ett nytt skript genom Ctrl + Shift + N. Mycket funktionalitet i R ligger i tilläggspaket (Packages). Paket måste installeras första gången de används och laddas varje session de används, t.ex. # install.packages(&quot;tidyverse&quot;) # Installera tidyverse library(tidyverse) # Ladda ett paket Objekt skapas med assign-pilen &lt;-. Det är ett sätt att importera data till R. Det är dock vanligare importera från en extern fil. Mer om det senare. Vi arbetar nästan alltid med data på tabellformat där variablerna är kolumner och observationerna rader. I gapminder-datan ges raderna av ett land för ett visst år. library(gapminder) gapminder # Skriv ut objektet gapminder Funktioner agerar på objekt och ger något utfall. Här nedan beräknas medelvärdet av livslängd med funktionen mean(). Dollartecknet används för att ange en specifik kolumn i dataobjektet. Funktioner styrs av möjliga argument - här används na.rm för att ange att saknade värden inte ska tas med i beräkningen mean(gapminder$lifeExp, na.rm = T) # Beräkna medel av lifeExp ## [1] 59.47444 Funktionerna filter() och select() kan användas för att välja kolumner och rader. Funktioner kan länkas samman med en pipe %&gt;% för att skapa sekvenser av funktioner. Man kan tänka på pipen som och sen. gapminder %&gt;% filter(country == &quot;Norway&quot;, year &gt; 1972) %&gt;% select(country, lifeExp) Slutligen tittade vi på grafer med ggplot2-paketet. En ggplot byggs upp med tre grundelar: data, geometrier (grafens objekt och former), och aesthetics (utseende och placering av geometrierna). I ett enkelt spridningsdiagram är data två numeriska variabler, geometrierna är punkter, och punkternas placering ges av en x-koordinat och en y-koordinat. Ytterligare aesthetics kan vara punkternas färger (color) och storlek (size). dat_small &lt;- gapminder %&gt;% filter(year == 2007) ggplot(dat_small, aes(x = gdpPercap, y = lifeExp, size = pop, color = continent)) + geom_point() 2.2 Import av data från en Excelfil Inom vetenskapen är Excel det vanligaste filformatet för mindre datamängder. Till den här delen ska vi återigen arbeta med data från Gapminder. Uppgift 2.1 (Excelfil från Canvas) Hitta excelfilen Gapminder.xlsx på Canvas och ladda ner den. Hitta mappen som filen laddats ned till. I R kan man läsa in data från en Excel-fil med funktionen read_excel() från paketet readxl. Som argument till funktionen sätts filens sökväg - dess placering på hårddisken. Stycket nedan importerar från en excelfil som ligger på hårddisken C: i mappen Downloads, under User_name, under Users. library(readxl) # Ladda readxl gapminder &lt;- read_excel(&quot;C:/Users/Name/Downloads/Gapminder.xlsx&quot;) # Läs in från en lokal excelfil gapminder Uppgift 2.2 (Importera från excelfil) Var ligger den nedladdade filen Gapminder.xlsx? Gör lämplig ändring i koden ovan för att läsa in data från den filen. Notera att R använder högerlutande snedstreck /, så om en kopierad sökväg har vänster-snedstreck måste de ändras. Kontrollera att datan blivit korrekt inläst genom att köra objektnamnet gapminder. En R-session har alltid en grundmapp, ett Working directory. Man kan se vilken mapp det är genom att köra getwd() # Ange working directory En filsökväg kan anges antingen som en fullständig sökväg, som ovan, eller relativt working directory. Om man till exempel har en fil Gapminder.xlsx som ligger i en mapp Data som i sin tur ligger i working directory, kan man importera data från filen med gapminder &lt;- read_excel(&quot;Data/Gapminder.xlsx&quot;) # Läs in från en lokal excelfil (relativt wd) gapminder Uppgift 2.3 (Working directory) Identifiera working directory för din nuvarande Rs-session genom att köra getwd(). RStudio har också en inbyggd funktionalitet för att importera data. Man kan hitta den genom att gå till Environment-fliken och sedan Import Dataset. Det kan vara en bra hjälp, i synnerhet om man vill sätta datatyp för någon specifik kolumn. Om du inte har tillgång till Canvas kan Gapminder-datan alternativt hämtas från paketet Gapminder. # install.packages(&quot;gapminder&quot;) library(gapminder) gapminder 2.3 Ändra och skapa nya kolumner med mutate Variabler kan omräknas och nya variabler kan skapas med mutate-funktionen. I gapminder-datan finns bnp per capita. Om man vill ha nationell BNP kan man skapa en ny kolumn och beräkna den som bnp per capita gånger populationen. gapminder &lt;- gapminder %&gt;% # Ta datan, och sen mutate(gdp = gdpPercap * pop) # Beräkna bnp Den inledande delen med gapminder &lt;- gör så att utfallet av beräkningen sparas i objektet gapminder. Vi kan skriva ut objektet och se resultatet av beräkningen: gapminder Om man vill skapa en kolumn med mellanrum i namnet måste man skriva namnet inom backticks ` för att ange att namnet ska tolkas som en enhet. Jag rekommenderar att undvika mellanrum i kolumnnamn och istället använda stora bokstäver eller understreck för ett nytt ord (NationalGDP eller National_GDP). gapminder &lt;- gapminder %&gt;% mutate(`National GDP` = gdpPercap * pop) gapminder 2.4 Sammanfattande lägesmått Den importerade datan anger medellivslängd, populationsstorlek och bnp per capita per land och år. Vi kan börja med att producera en bubbelgraf över datan - en av de presentationer Gapminder ofta använder. En bubbelgraf är ett spridningsdiagram där punktens storlek beror på en tredje variabel. ggplot(gapminder, aes(x = gdpPercap, y = lifeExp, size = pop, color = continent)) + geom_point() + facet_wrap(~ year) En interaktiv version kan vara bra om man vill identifiera någon specifik punkt. g &lt;- ggplot(gapminder, aes(x = gdpPercap, y = lifeExp, size = pop, color = continent, text = country)) + geom_point() + facet_wrap(~ year) # install.packages(&quot;plotly&quot;) # Kör om ej installerat tidigare library(plotly) # Ladda paketet plotly ggplotly(g) # Interaktiv graf g Under föreläsningen såg vi exempel på två lägesmått: medelvärdet (egentligen det aritmetiska medelvärdet) och medianen. De har bägge enkla funktioner i R: mean() respektive median(). Vi plockar ut en variabel ur datan och beräknar bägge. gapminder$gdpPercap # Vektorn med data ## [1] 779.4453 820.8530 853.1007 836.1971 739.9811 786.1134 ## [7] 978.0114 852.3959 649.3414 635.3414 726.7341 974.5803 ## [13] 1601.0561 1942.2842 2312.8890 2760.1969 3313.4222 3533.0039 ## [19] 3630.8807 3738.9327 2497.4379 3193.0546 4604.2117 5937.0295 ## [25] 2449.0082 3013.9760 2550.8169 3246.9918 4182.6638 4910.4168 ## [31] 5745.1602 5681.3585 5023.2166 4797.2951 5288.0404 6223.3675 ## [37] 3520.6103 3827.9405 4269.2767 5522.7764 5473.2880 3008.6474 ## [43] 2756.9537 2430.2083 2627.8457 2277.1409 2773.2873 4797.2313 ## [49] 5911.3151 6856.8562 7133.1660 8052.9530 9443.0385 10079.0267 ## [55] 8997.8974 9139.6714 9308.4187 10967.2820 8797.6407 12779.3796 ## [61] 10039.5956 10949.6496 12217.2269 14526.1246 16788.6295 18334.1975 ## [67] 19477.0093 21888.8890 23424.7668 26997.9366 30687.7547 34435.3674 ## [73] 6137.0765 8842.5980 10750.7211 12834.6024 16661.6256 19749.4223 ## [79] 21597.0836 23687.8261 27042.0187 29095.9207 32417.6077 36126.4927 ## [85] 9867.0848 11635.7995 12753.2751 14804.6727 18268.6584 19340.1020 ## [91] 19211.1473 18524.0241 19035.5792 20292.0168 23403.5593 29796.0483 ## [97] 684.2442 661.6375 686.3416 721.1861 630.2336 659.8772 ## [103] 676.9819 751.9794 837.8102 972.7700 1136.3904 1391.2538 ## [109] 8343.1051 9714.9606 10991.2068 13149.0412 16672.1436 19117.9745 ## [115] 20979.8459 22525.5631 25575.5707 27561.1966 30485.8838 33692.6051 ## [121] 1062.7522 959.6011 949.4991 1035.8314 1085.7969 1029.1613 ## [127] 1277.8976 1225.8560 1191.2077 1232.9753 1372.8779 1441.2849 ## [133] 2677.3263 2127.6863 2180.9725 2586.8861 2980.3313 3548.0978 ## [139] 3156.5105 2753.6915 2961.6997 3326.1432 3413.2627 3822.1371 ## [145] 973.5332 1353.9892 1709.6837 2172.3524 2860.1698 3528.4813 ## [151] 4126.6132 4314.1148 2546.7814 4766.3559 6018.9752 7446.2988 ## [157] 851.2411 918.2325 983.6540 1214.7093 2263.6111 3214.8578 ## [163] 4551.1421 6205.8839 7954.1116 8647.1423 11003.6051 12569.8518 ## [169] 2108.9444 2487.3660 3336.5858 3429.8644 4985.7115 6660.1187 ## [175] 7030.8359 7807.0958 6950.2830 7957.9808 8131.2128 9065.8008 ## [181] 2444.2866 3008.6707 4254.3378 5577.0028 6597.4944 7612.2404 ## [187] 8224.1916 8239.8548 6302.6234 5970.3888 7696.7777 10680.7928 ## [193] 543.2552 617.1835 722.5120 794.8266 854.7360 743.3870 ## [199] 807.1986 912.0631 931.7528 946.2950 1037.6452 1217.0330 ## [205] 339.2965 379.5646 355.2032 412.9775 464.0995 556.1033 ## [211] 559.6032 621.8188 631.6999 463.1151 446.4035 430.0707 ## [217] 368.4693 434.0383 496.9136 523.4323 421.6240 524.9722 ## [223] 624.4755 683.8956 682.3032 734.2852 896.2260 1713.7787 ## [229] 1172.6677 1313.0481 1399.6074 1508.4531 1684.1465 1783.4329 ## [235] 2367.9833 2602.6642 1793.1633 1694.3375 1934.0114 2042.0952 ## [241] 11367.1611 12489.9501 13462.4855 16076.5880 18970.5709 22090.8831 ## [247] 22898.7921 26626.5150 26342.8843 28954.9259 33328.9651 36319.2350 ## [253] 1071.3107 1190.8443 1193.0688 1136.0566 1070.0133 1109.3743 ## [259] 956.7530 844.8764 747.9055 740.5063 738.6906 706.0165 ## [265] 1178.6659 1308.4956 1389.8176 1196.8106 1104.1040 1133.9850 ## [271] 797.9081 952.3861 1058.0643 1004.9614 1156.1819 1704.0637 ## [277] 3939.9788 4315.6227 4519.0943 5106.6543 5494.0244 4756.7638 ## [283] 5095.6657 5547.0638 7596.1260 10118.0532 10778.7838 13171.6388 ## [289] 400.4486 575.9870 487.6740 612.7057 676.9001 741.2375 ## [295] 962.4214 1378.9040 1655.7842 2289.2341 3119.2809 4959.1149 ## [301] 2144.1151 2323.8056 2492.3511 2678.7298 3264.6600 3815.8079 ## [307] 4397.5757 4903.2191 5444.6486 6117.3617 5755.2600 7006.5804 ## [313] 1102.9909 1211.1485 1406.6483 1876.0296 1937.5777 1172.6030 ## [319] 1267.1001 1315.9808 1246.9074 1173.6182 1075.8116 986.1479 ## [325] 780.5423 905.8602 896.3146 861.5932 904.8961 795.7573 ## [331] 673.7478 672.7748 457.7192 312.1884 241.1659 277.5519 ## [337] 2125.6214 2315.0566 2464.7832 2677.9396 3213.1527 3259.1790 ## [343] 4879.5075 4201.1949 4016.2395 3484.1644 3484.0620 3632.5578 ## [349] 2627.0095 2990.0108 3460.9370 4161.7278 5118.1469 5926.8770 ## [355] 5262.7348 5629.9153 6160.4163 6677.0453 7723.4472 9645.0614 ## [361] 1388.5947 1500.8959 1728.8694 2052.0505 2378.2011 2517.7365 ## [367] 2602.7102 2156.9561 1648.0738 1786.2654 1648.8008 1544.7501 ## [373] 3119.2365 4338.2316 5477.8900 6960.2979 9164.0901 11305.3852 ## [379] 13221.8218 13822.5839 8447.7949 9875.6045 11628.3890 14619.2227 ## [385] 5586.5388 6092.1744 5180.7559 5690.2680 5305.4453 6380.4950 ## [391] 7316.9181 7532.9248 5592.8440 5431.9904 6340.6467 8948.1029 ## [397] 6876.1403 8256.3439 10136.8671 11399.4449 13108.4536 14800.1606 ## [403] 15377.2285 16310.4434 14297.0212 16048.5142 17596.2102 22833.3085 ## [409] 9692.3852 11099.6593 13583.3135 15937.2112 18866.2072 20422.9015 ## [415] 21688.0405 25116.1758 26406.7399 29804.3457 32166.5001 35278.4187 ## [421] 2669.5295 2864.9691 3020.9893 3020.0505 3694.2124 3081.7610 ## [427] 2879.4681 2880.1026 2377.1562 1895.0170 1908.2609 2082.4816 ## [433] 1397.7171 1544.4030 1662.1374 1653.7230 2189.8745 2681.9889 ## [439] 2861.0924 2899.8422 3044.2142 3614.1013 4563.8082 6025.3748 ## [445] 3522.1107 3780.5467 4086.1141 4579.0742 5280.9947 6679.6233 ## [451] 7213.7913 6481.7770 7103.7026 7429.4559 5773.0445 6873.2623 ## [457] 1418.8224 1458.9153 1693.3359 1814.8807 2024.0081 2785.4936 ## [463] 3503.7296 3885.4607 3794.7552 4173.1818 4754.6044 5581.1810 ## [469] 3048.3029 3421.5232 3776.8036 4358.5954 4520.2460 5138.9224 ## [475] 4098.3442 4140.4421 4444.2317 5154.8255 5351.5687 5728.3535 ## [481] 375.6431 426.0964 582.8420 915.5960 672.4123 958.5668 ## [487] 927.8253 966.8968 1132.0550 2814.4808 7703.4959 12154.0897 ## [493] 328.9406 344.1619 380.9958 468.7950 514.3242 505.7538 ## [499] 524.8758 521.1341 582.8585 913.4708 765.3500 641.3695 ## [505] 362.1463 378.9042 419.4564 516.1186 566.2439 556.8084 ## [511] 577.8607 573.7413 421.3535 515.8894 530.0535 690.8056 ## [517] 6424.5191 7545.4154 9371.8426 10921.6363 14358.8759 15605.4228 ## [523] 18533.1576 21141.0122 20647.1650 23723.9502 28204.5906 33207.0844 ## [529] 7029.8093 8662.8349 10560.4855 12999.9177 16107.1917 18292.6351 ## [535] 20293.8975 22066.4421 24703.7961 25889.7849 28926.0323 30470.0167 ## [541] 4293.4765 4976.1981 6631.4592 8358.7620 11401.9484 21745.5733 ## [547] 15113.3619 11864.4084 13522.1575 14722.8419 12521.7139 13206.4845 ## [553] 485.2307 520.9267 599.6503 734.7829 756.0868 884.7553 ## [559] 835.8096 611.6589 665.6244 653.7302 660.5856 752.7497 ## [565] 7144.1144 10187.8267 12902.4629 14745.6256 18016.1803 20512.9212 ## [571] 22031.5327 24639.1857 26505.3032 27788.8842 30035.8020 32170.3744 ## [577] 911.2989 1043.5615 1190.0411 1125.6972 1178.2237 993.2240 ## [583] 876.0326 847.0061 925.0602 1005.2458 1111.9846 1327.6089 ## [589] 3530.6901 4916.2999 6017.1907 8513.0970 12724.8296 14195.5243 ## [595] 15268.4209 16120.5284 17541.4963 18747.6981 22514.2548 27538.4119 ## [601] 2428.2378 2617.1560 2750.3644 3242.5311 4031.4083 4879.9927 ## [607] 4820.4948 4246.4860 4439.4508 4684.3138 4858.3475 5186.0500 ## [613] 510.1965 576.2670 686.3737 708.7595 741.6662 874.6859 ## [619] 857.2504 805.5725 794.3484 869.4498 945.5836 942.6542 ## [625] 299.8503 431.7905 522.0344 715.5806 820.2246 764.7260 ## [631] 838.1240 736.4154 745.5399 796.6645 575.7047 579.2317 ## [637] 1840.3669 1726.8879 1796.5890 1452.0577 1654.4569 1874.2989 ## [643] 2011.1595 1823.0160 1456.3095 1341.7269 1270.3649 1201.6372 ## [649] 2194.9262 2220.4877 2291.1568 2538.2694 2529.8423 3203.2081 ## [655] 3121.7608 3023.0967 3081.6946 3160.4549 3099.7287 3548.3308 ## [661] 3054.4212 3629.0765 4692.6483 6197.9628 8315.9281 11186.1413 ## [667] 14560.5305 20038.4727 24757.6030 28377.6322 30209.0152 39724.9787 ## [673] 5263.6738 6040.1800 7550.3599 9326.6447 10168.6561 11674.8374 ## [679] 12545.9907 12986.4800 10535.6285 11712.7768 14843.9356 18008.9444 ## [685] 7267.6884 9244.0014 10350.1591 13319.8957 15798.0636 19654.9625 ## [691] 23269.6075 26923.2063 25144.3920 28061.0997 31163.2020 36180.7892 ## [697] 546.5657 590.0620 658.3472 700.7706 724.0325 813.3373 ## [703] 855.7235 976.5127 1164.4068 1458.8174 1746.7695 2452.2104 ## [709] 749.6817 858.9003 849.2898 762.4318 1111.1079 1382.7021 ## [715] 1516.8730 1748.3570 2383.1409 3119.3356 2873.9129 3540.6516 ## [721] 3035.3260 3290.2576 4187.3298 5906.7318 9613.8186 11888.5951 ## [727] 7608.3346 6642.8814 7235.6532 8263.5903 9240.7620 11605.7145 ## [733] 4129.7661 6229.3336 8341.7378 8931.4598 9576.0376 14688.2351 ## [739] 14517.9071 11643.5727 3745.6407 3076.2398 4390.7173 4471.0619 ## [745] 5210.2803 5599.0779 6631.5973 7655.5690 9530.7729 11150.9811 ## [751] 12618.3214 13872.8665 17558.8155 24521.9471 34077.0494 40675.9964 ## [757] 4086.5221 5385.2785 7105.6307 8393.7414 12786.9322 13306.6192 ## [763] 15367.0292 17122.4799 18051.5225 20896.6092 21905.5951 25523.2771 ## [769] 4931.4042 6248.6562 8243.5823 10022.4013 12269.2738 14255.9847 ## [775] 16537.4835 19207.2348 22013.6449 24675.0245 27968.0982 28569.7197 ## [781] 2898.5309 4756.5258 5246.1075 6124.7035 7433.8893 6650.1956 ## [787] 6068.0513 6351.2375 7404.9237 7121.9247 6994.7749 7320.8803 ## [793] 3216.9563 4317.6944 6576.6495 9847.7886 14778.7864 16610.3770 ## [799] 19384.1057 22375.9419 26824.8951 28816.5850 28604.5919 31656.0681 ## [805] 1546.9078 1886.0806 2348.0092 2741.7963 2110.8563 2852.3516 ## [811] 4161.4160 4448.6799 3431.5936 3645.3796 3844.9172 4519.4612 ## [817] 853.5409 944.4383 896.9664 1056.7365 1222.3600 1267.6132 ## [823] 1348.2258 1361.9369 1341.9217 1360.4850 1287.5147 1463.2493 ## [829] 1088.2778 1571.1347 1621.6936 2143.5406 3701.6215 4106.3012 ## [835] 4106.5253 4106.4923 3726.0635 1690.7568 1646.7582 1593.0655 ## [841] 1030.5922 1487.5935 1536.3444 2029.2281 3030.8767 4657.2210 ## [847] 5622.9425 8533.0888 12104.2787 15993.5280 19233.9882 23348.1397 ## [853] 108382.3529 113523.1329 95458.1118 80894.8833 109347.8670 59265.4771 ## [859] 31354.0357 28118.4300 34932.9196 40300.6200 35110.1057 47306.9898 ## [865] 4834.8041 6089.7869 5714.5606 6006.9830 7486.3843 8659.6968 ## [871] 7640.5195 5377.0913 6890.8069 8754.9639 9313.9388 10461.0587 ## [877] 298.8462 335.9971 411.8006 498.6390 496.5816 745.3695 ## [883] 797.2631 773.9932 977.4863 1186.1480 1275.1846 1569.3314 ## [889] 575.5730 620.9700 634.1952 713.6036 803.0055 640.3224 ## [895] 572.1996 506.1139 636.6229 609.1740 531.4824 414.5073 ## [901] 2387.5481 3448.2844 6757.0308 18772.7517 21011.4972 21951.2118 ## [907] 17364.2754 11770.5898 9640.1385 9467.4461 9534.6775 12057.4993 ## [913] 1443.0117 1589.2027 1643.3871 1634.0473 1748.5630 1544.2286 ## [919] 1302.8787 1155.4419 1040.6762 986.2959 894.6371 1044.7701 ## [925] 369.1651 416.3698 427.9011 495.5148 584.6220 663.2237 ## [931] 632.8039 635.5174 563.2000 692.2758 665.4231 759.3499 ## [937] 1831.1329 1810.0670 2036.8849 2277.7424 2849.0948 3827.9216 ## [943] 4920.3560 5249.8027 7277.9128 10132.9096 10206.9779 12451.6558 ## [949] 452.3370 490.3822 496.1743 545.0099 581.3689 686.3953 ## [955] 618.0141 684.1716 739.0144 790.2580 951.4098 1042.5816 ## [961] 743.1159 846.1203 1055.8960 1421.1452 1586.8518 1497.4922 ## [967] 1481.1502 1421.6036 1361.3698 1483.1361 1579.0195 1803.1515 ## [973] 1967.9557 2034.0380 2529.0675 2475.3876 2575.4842 3710.9830 ## [979] 3688.0377 4783.5869 6058.2538 7425.7053 9021.8159 10956.9911 ## [985] 3478.1255 4131.5466 4581.6094 5754.7339 6809.4067 7674.9291 ## [991] 9611.1475 8688.1560 9472.3843 9767.2975 10742.4405 11977.5750 ## [997] 786.5669 912.6626 1056.3540 1226.0411 1421.7420 1647.5117 ## [1003] 2000.6031 2338.0083 1785.4020 1902.2521 2140.7393 3095.7723 ## [1009] 2647.5856 3682.2599 4649.5938 5907.8509 7778.4140 9595.9299 ## [1015] 11222.5876 11732.5102 7003.3390 6465.6133 6557.1943 9253.8961 ## [1021] 1688.2036 1642.0023 1566.3535 1711.0448 1930.1950 2370.6200 ## [1027] 2702.6204 2755.0470 2948.0473 2982.1019 3258.4956 3820.1752 ## [1033] 468.5260 495.5868 556.6864 566.6692 724.9178 502.3197 ## [1039] 462.2114 389.8762 410.8968 472.3461 633.6179 823.6856 ## [1045] 331.0000 350.0000 388.0000 349.0000 357.0000 371.0000 ## [1051] 424.0000 385.0000 347.0000 415.0000 611.0000 944.0000 ## [1057] 2423.7804 2621.4481 3173.2156 3793.6948 3746.0809 3876.4860 ## [1063] 4191.1005 3693.7313 3804.5380 3899.5243 4072.3248 4811.0604 ## [1069] 545.8657 597.9364 652.3969 676.4422 674.7881 694.1124 ## [1075] 718.3731 775.6325 897.7404 1010.8921 1057.2063 1091.3598 ## [1081] 8941.5719 11276.1934 12790.8496 15363.2514 18794.7457 21209.0592 ## [1087] 21399.4605 23651.3236 26790.9496 30246.1306 33724.7578 36797.9333 ## [1093] 10556.5757 12247.3953 13175.6780 14463.9189 16046.0373 16233.7177 ## [1099] 17632.4104 19007.1913 18363.3249 21050.4138 23189.8014 25185.0091 ## [1105] 3112.3639 3457.4159 3634.3644 4643.3935 4688.5933 5486.3711 ## [1111] 3470.3382 2955.9844 2170.1517 2253.0230 2474.5488 2749.3210 ## [1117] 761.8794 835.5234 997.7661 1054.3849 954.2092 808.8971 ## [1123] 909.7221 668.3000 581.1827 580.3052 601.0745 619.6769 ## [1129] 1077.2819 1100.5926 1150.9275 1014.5141 1698.3888 1981.9518 ## [1135] 1576.9738 1385.0296 1619.8482 1624.9413 1615.2864 2013.9773 ## [1141] 10095.4217 11653.9730 13450.4015 16361.8765 18965.0555 23311.3494 ## [1147] 26298.6353 31540.9748 33965.6611 41283.1643 44683.9753 49357.1902 ## [1153] 1828.2303 2242.7466 2924.6381 4720.9427 10618.0385 11848.3439 ## [1159] 12954.7910 18115.2231 18616.7069 19702.0558 19774.8369 22316.1929 ## [1165] 684.5971 747.0835 803.3427 942.4083 1049.9390 1175.9212 ## [1171] 1443.4298 1704.6866 1971.8295 2049.3505 2092.7124 2605.9476 ## [1177] 2480.3803 2961.8009 3536.5403 4421.0091 5364.2497 5351.9121 ## [1183] 7009.6016 7034.7792 6618.7431 7113.6923 7356.0319 9809.1856 ## [1189] 1952.3087 2046.1547 2148.0271 2299.3763 2523.3380 3248.3733 ## [1195] 4258.5036 3998.8757 4196.4111 4247.4003 3783.6742 4172.8385 ## [1201] 3758.5234 4245.2567 4957.0380 5788.0933 5937.8273 6281.2909 ## [1207] 6434.5018 6360.9434 4446.3809 5838.3477 5909.0201 7408.9056 ## [1213] 1272.8810 1547.9448 1649.5522 1814.1274 1989.3741 2373.2043 ## [1219] 2603.2738 2189.6350 2279.3240 2536.5349 2650.9211 3190.4810 ## [1225] 4029.3297 4734.2530 5338.7521 6557.1528 8006.5070 9508.1415 ## [1231] 8451.5310 9082.3512 7738.8812 10159.5837 12002.2391 15389.9247 ## [1237] 3068.3199 3774.5717 4727.9549 6361.5180 9022.2474 10172.4857 ## [1243] 11753.8429 13039.3088 16207.2666 17641.0316 19970.9079 20509.6478 ## [1249] 3081.9598 3907.1562 5108.3446 6929.2777 9123.0417 9770.5249 ## [1255] 10330.9891 12281.3419 14641.5871 16999.4333 18855.6062 19328.7090 ## [1261] 2718.8853 2769.4518 3173.7233 4021.1757 5047.6586 4319.8041 ## [1267] 5267.2194 5303.3775 6101.2558 6071.9414 6316.1652 7670.1226 ## [1273] 3144.6132 3943.3702 4734.9976 6470.8665 8011.4144 9356.3972 ## [1279] 9605.3141 9696.2733 6598.4099 7346.5476 7885.3601 10808.4756 ## [1285] 493.3239 540.2894 597.4731 510.9637 590.5807 670.0806 ## [1291] 881.5706 847.9912 737.0686 589.9445 785.6538 863.0885 ## [1297] 879.5836 860.7369 1071.5511 1384.8406 1532.9853 1737.5617 ## [1303] 1890.2181 1516.5255 1428.7778 1339.0760 1353.0924 1598.4351 ## [1309] 6459.5548 8157.5912 11626.4197 16903.0489 24837.4287 34167.7626 ## [1315] 33693.1753 21198.2614 24841.6178 20586.6902 19014.5412 21654.8319 ## [1321] 1450.3570 1567.6530 1654.9887 1612.4046 1597.7121 1561.7691 ## [1327] 1518.4800 1441.7207 1367.8994 1392.3683 1519.6353 1712.4721 ## [1333] 3581.4594 4981.0909 6289.6292 7991.7071 10522.0675 12980.6696 ## [1339] 15181.0927 15870.8785 9325.0682 7914.3203 7236.0753 9786.5347 ## [1345] 879.7877 1004.4844 1116.6399 1206.0435 1353.7598 1348.2852 ## [1351] 1465.0108 1294.4478 1068.6963 574.6482 699.4897 862.5408 ## [1357] 2315.1382 2843.1044 3674.7356 4977.4185 8597.7562 11210.0895 ## [1363] 15169.1611 18861.5308 24769.8912 33519.4766 36023.1054 47143.1796 ## [1369] 5074.6591 6093.2630 7481.1076 8412.9024 9674.1676 10922.6640 ## [1375] 11348.5459 12037.2676 9498.4677 12126.2306 13638.7784 18678.3144 ## [1381] 4215.0417 5862.2766 7402.3034 9405.4894 12383.4862 15277.0302 ## [1387] 17866.7218 18678.5349 14214.7168 17161.1073 20660.0194 25768.2576 ## [1393] 1135.7498 1258.1474 1369.4883 1284.7332 1254.5761 1450.9925 ## [1399] 1176.8070 1093.2450 926.9603 930.5964 882.0818 926.1411 ## [1405] 4725.2955 5487.1042 5768.7297 7114.4780 7765.9626 8028.6514 ## [1411] 8568.2662 7825.8234 7225.0693 7479.1882 7710.9464 9269.6578 ## [1417] 3834.0347 4564.8024 5693.8439 7993.5123 10638.7513 13236.9212 ## [1423] 13926.1700 15764.9831 18603.0645 20445.2990 24835.4717 28821.0637 ## [1429] 1083.5320 1072.5466 1074.4720 1135.5143 1213.3955 1348.7757 ## [1435] 1648.0798 1876.7668 2153.7392 2664.4773 3015.3788 3970.0954 ## [1441] 1615.9911 1770.3371 1959.5938 1687.9976 1659.6528 2202.9884 ## [1447] 1895.5441 1507.8192 1492.1970 1632.2108 1993.3983 2602.3950 ## [1453] 1148.3766 1244.7084 1856.1821 2613.1017 3364.8366 3781.4106 ## [1459] 3895.3840 3984.8398 3553.0224 3876.7685 4128.1169 4513.4806 ## [1465] 8527.8447 9911.8782 12329.4419 15258.2970 17832.0246 18855.7252 ## [1471] 20667.3812 23586.9293 23880.0168 25266.5950 29341.6309 33859.7484 ## [1477] 14734.2327 17909.4897 20431.0927 22966.1443 27195.1130 26982.2905 ## [1483] 28397.7151 30281.7046 31871.5303 32135.3230 34480.9577 37506.4191 ## [1489] 1643.4854 2117.2349 2193.0371 1881.9236 2571.4230 3195.4846 ## [1495] 3761.8377 3116.7743 3340.5428 4014.2390 4090.9253 4184.5481 ## [1501] 1206.9479 1507.8613 1822.8790 2643.8587 4062.5239 5596.5198 ## [1507] 7426.3548 11054.5618 15215.6579 20206.8210 23235.4233 28718.2768 ## [1513] 716.6501 698.5356 722.0038 848.2187 915.9851 962.4923 ## [1519] 874.2426 831.8221 825.6825 789.1862 899.0742 1107.4822 ## [1525] 757.7974 793.5774 1002.1992 1295.4607 1524.3589 1961.2246 ## [1531] 2393.2198 2982.6538 4616.8965 5852.6255 5913.1875 7458.3963 ## [1537] 859.8087 925.9083 1067.5348 1477.5968 1649.6602 1532.7770 ## [1543] 1344.5780 1202.2014 1034.2989 982.2869 886.2206 882.9699 ## [1549] 3023.2719 4100.3934 4997.5240 5621.3685 6619.5514 7899.5542 ## [1555] 9119.5286 7388.5978 7370.9909 8792.5731 11460.6002 18008.5092 ## [1561] 1468.4756 1395.2325 1660.3032 1932.3602 2753.2860 3120.8768 ## [1567] 3560.2332 3810.4193 4332.7202 4876.7986 5722.8957 7092.9230 ## [1573] 1969.1010 2218.7543 2322.8699 2826.3564 3450.6964 4269.1223 ## [1579] 4241.3563 5089.0437 5678.3483 6601.4299 6508.0857 8458.2764 ## [1585] 734.7535 774.3711 767.2717 908.9185 950.7359 843.7331 ## [1591] 682.2662 617.7244 644.1708 816.5591 927.7210 1056.3801 ## [1597] 9979.5085 11283.1779 12477.1771 14142.8509 15895.1164 17428.7485 ## [1603] 18232.4245 21664.7877 22705.0925 26074.5314 29478.9992 33203.2613 ## [1609] 13990.4821 14847.1271 16173.1459 19530.3656 21806.0359 24072.6321 ## [1615] 25009.5591 29884.3504 32003.9322 35767.4330 39097.0995 42951.6531 ## [1621] 5716.7667 6150.7730 5603.3577 5444.6196 5703.4089 6504.3397 ## [1627] 6920.2231 7452.3990 8137.0048 9230.2407 7727.0020 10611.4630 ## [1633] 7689.7998 9802.4665 8422.9742 9541.4742 10505.2597 13143.9510 ## [1639] 11152.4101 9883.5846 10733.9263 10165.4952 8605.0478 11415.8057 ## [1645] 605.0665 676.2854 772.0492 637.1233 699.5016 713.5371 ## [1651] 707.2358 820.7994 989.0231 1385.8968 1764.4567 2441.5764 ## [1657] 1515.5923 1827.0677 2198.9563 2649.7150 3133.4093 3682.8315 ## [1663] 4336.0321 5107.1974 6017.6548 7110.6676 4515.4876 3025.3498 ## [1669] 781.7176 804.8305 825.6232 862.4421 1265.0470 1829.7652 ## [1675] 1977.5570 1971.7415 1879.4967 2117.4845 2234.8208 2280.7699 ## [1681] 1147.3888 1311.9568 1452.7258 1777.0773 1773.4983 1588.6883 ## [1687] 1408.6786 1213.3151 1210.8846 1071.3538 1071.6139 1271.2116 ## [1693] 406.8841 518.7643 527.2722 569.7951 799.3622 685.5877 ## [1699] 788.8550 706.1573 693.4208 792.4500 672.0386 469.7093 mean(gapminder$gdpPercap) # Beräkna medelvärdet ## [1] 7215.327 median(gapminder$gdpPercap) # Beräkna medianen ## [1] 3531.847 Samma sak kan göras med en pipe %&gt;% och summarise(). gapminder %&gt;% summarise(Mean = mean(gdpPercap), Median = median(gdpPercap)) Uppgift 2.4 (Lägesmått av livslängd) Gör lämpliga ändringar i exemplet ovan för att beräkna lägesmått för medellivslängd (lifeExp). Den andra lösningen, med en pipe och summarise(), kan enkelt utvecklas med ett group_by()-steg för att beräkna medel och median per någon grupp, t.ex. per år. gapminder %&gt;% # Ta datan, och sen group_by(year) %&gt;% # gruppera efter år, och summarise(Mean = mean(gdpPercap), # beräkna medelvärde och Median = median(gdpPercap)) # medianen av gdpPercap Uppgift 2.5 (Lägesmått per kontinent) Gör lämpliga ändringar i exemplet ovan för att beräkna lägesmått per kontinent. Vad måste läggas till för att också beräkna maximum och minimum per kontinent (funktionerna max() och min())? Uppgift 2.6 (Upprepade mätningar) Finns det några problem med att beräkna medelvärde per kontinent på den här datan? I vetenskapliga publikationer redovisas medelvärden ofta med ett stapeldiagram. Som exempel ges staplar för medelvärdet av bnp per kontinent för 2007. dat_gdp_2007 &lt;- gapminder %&gt;% # Ta datan, och sen filter(year == 2007) %&gt;% # filtrera för 2007, och sen group_by(continent) %&gt;% # gruppera kontinenter, och summarise(Mean = mean(gdpPercap)) # summera med medelvärdet ggplot(dat_gdp_2007, aes(continent, Mean)) + geom_col() # Illustrera med kolumner (columns) Uppgift 2.7 (Graf för livslängd) Gör om stapeldiagrammet. Denna gång med livslängd (lifeExp) istället för bnp per capita (gdpPercap). 2.5 Sammanfattande spridningsmått Under föreläsningarna såg vi några mått på spridning: varians, standardavvikelse och kvartilavstånd (IQR, inter-quartile range). De har alla motsvarande funktioner i R (var(), sd(), och IQR()) som kan användas på samma sätt som funktionerna för lägesmått. gdpPercap &lt;- gapminder$gdpPercap # Skapa en vektor gdpPercap var(gdpPercap) # Beräkna varians sd(gdpPercap) # Beräkna standardavvikelse IQR(gdpPercap) # Beräkna kvartilavstånd Alternativt med en pipe och summarise(). gapminder %&gt;% # Ta datan, och summarise(Var = var(gdpPercap), # beräkna varians, Sd = sd(gdpPercap), # standardavvikelse, IQR = IQR(gdpPercap)) # och kvartilavstånd Lösningen med pipe och summarise() kan som tidigare utvecklas med group_by(). gapminder %&gt;% group_by(year) %&gt;% summarise(Varians = var(gdpPercap), Standardavvikelse = sd(gdpPercap), Kvartilavstånd = IQR(gdpPercap)) Uppgift 2.8 (Graf för livslängd) Gör lämpliga ändringar i det sista exempel för att istället beräkna spridningsmått för livslängd. Vi avslutar med tre vanliga illustrationer av vetenskaplig data - ett linjediagram med felstaplar, ett stapeldiagram med felstaplar, och ett lådagram. För linjediagrammet beräknar vi medelvärdet och spridningsmått för bnp över år och kontinent. Som spridningsmått använder vi standard error (sv. medelfel), vilket beräknas som standardavvikelse delat på roten ur antalet observationer. Funktionen n() ger antalet observationer per kontinent och år. dat_year_continent &lt;- gapminder %&gt;% group_by(year, continent) %&gt;% summarise(Mean = mean(gdpPercap), SE = sd(gdpPercap) / sqrt(n())) dat_year_continent Med ggplot2 kan vi bygga ett linjediagram med geom_line() och lägga till felstaplar med geom_errorbar(). Den senare behöver aes()-argument för ymin och ymax - nedre och övre del av felstapeln. Vi sätter dem till medelvärdet minus respektive plus ett medelfel. ggplot(dat_year_continent, aes(x = year, y = Mean, color = continent)) + geom_line() + geom_errorbar(aes(ymin = Mean - SE, ymax = Mean + SE)) Uppgift 2.9 (Bredd) Felstaplarna från geom_errorbar() har väldigt breda ändar. Använd hjälpsidan för geomet ?geom_errorbar, i synnerhet exemplen längst ned, och se om det går att ändra bredden. En graf med staplar och felstaplar kan konstrueras på ett liknande sätt. Följande exempel visar staplar över livslängd per kontinent. Felstapeln ges av standardavvikelsen. dat_2007 &lt;- gapminder %&gt;% # Ta datan, och sen filter(year == 2007) %&gt;% # filtrera på år, och sen group_by(continent) %&gt;% # gruppera efter kontinent, summarise(Mean = mean(lifeExp), # summera med medelvärde, SD = sd(lifeExp)) # och standardavvikelse dat_2007 Vi bygger en ggplot med geom_col() och geom_errorbar(). Felstapels konstruktion kan anges i en notis med funktionen labs(). ggplot(dat_2007, aes(continent, Mean, fill = continent)) + geom_col()+ geom_errorbar(aes(ymin = Mean - SD, ymax = Mean + SD)) + labs(title = &quot;Average life expectancy by continent, 2007&quot;, caption = &quot;Errorbars given by mean +/- standard deviation. Source: Gapminder&quot;) Uppgift 2.10 (Staplar för 1982) Gör lämpliga ändringar i exempel ovan för att konstruera ett stapeldiagram med felstaplar för året 1982 och variabeln medellivslängd. Ett lådagram anger fördelningen av en variabel genom att illustrera minimum, maximum och kvartiler. Kvartiler är mått som delar en datamängd i fyra lika stora delar (så att en fjärdedel ligger under första kvartilen, en fjärdedel mellan första och andra kvartil, och så vidare). Med ggplot2 kan vi bygga ett lådagram med geom_boxplot(). Exempel ger en låda per år och kontinent. ggplot(gapminder, aes(year, lifeExp, fill = continent, group = year)) + geom_boxplot() + facet_wrap(~ continent) Uppgift 2.11 (Group-argumentet) I lådagrammet används argumentet group. Vad gör det? Vad händer om man tar bort det? 2.6 Ordna upp beskrivande statistik och exportera Efter att ha beräknat någon beskrivande statistik kan det vara bra att titta på hur resultaten kan snyggas upp och exporteras i något lämpligt format. Ta den tabell med medelvärden vi producerade i ett tidigare exempel. dat_2007 &lt;- gapminder %&gt;% # Ta datan, och sen filter(year == 2007) %&gt;% # filtrera på år, och sen group_by(continent) %&gt;% # gruppera efter kontinent, summarise(Mean = mean(lifeExp), # summera med medelvärde, SD = sd(lifeExp)) # och standardavvikelse dat_2007 Objekt kan exporteras från R på liknande som det importeras - med särskilda exportfunktioner (write-funktioner) beroende på filtyp. För att exportera till en csv-fil man man använda write_csv(). Ingående argument är det objekt man vill exportera och den fil man vill exportera till. R ger ingen varning om man skriver över en existerande fil, så var lite försiktiga här. Precis som vid import använder R working directory om inget annat anges. Följande exporterar objektet dat_2007 till en csv-fil Exporterad data från R.csv i working directory. getwd() # Se nuvarande working directory write_csv(dat_2007, &quot;Exporterad data från R.csv&quot;) # Exportera data Därifrån skulle man kunna öppna filen i något kalkylprogram, snygga till layouten, och sedan klippa in i ett textdokument. 2.7 Kumulativt medelvärde Om man har data som av någon anledning samlas in i sekvens kan det vara intressant att beräkna och illustrera den med ett kumulativt medelvärde. En serie med kumulativa medelvärden beräknas genom att för varje nytt värde ta medelvärden av de värden man hittills samlat in - vid tio värden tar man medelvärdet av de tio, vid elva värden medelvärdet av de elva, och så vidare. Med de tärningsvärden vi hade innan kan vi beräkna ett kumulativt medelvärde genom att först beräkna summan med cumsum() och sedan dela på antalet kast. För att förenkla beräkningen av antalen tar vi fram sekvensen med antal kast i ett mutate()-steg. dat_dice &lt;- data.frame(Utfall = c(6,3,2,3,5)) %&gt;% mutate(Kast = 1:n()) dat_dice dat_dice &lt;- dat_dice %&gt;% mutate(kumulativ_summa = cumsum(Utfall), kumulativt_medelvärde = kumulativ_summa / Kast) dat_dice Uppgift 2.12 (Kumulativt medelvärde) Vad ska läggas till för att stycket nedan ska ge en linjegraf över medelvärdet? ggplot(dat_dice, aes(x = Kast, y = ___)) + ___() Uppgift 2.13 (Fler tärningskast) Kasta din tärning ytterligare några gånger, gärna på en mjuk yta. Fyll i dina utfall och gör grafen från föregående uppgift. Kan man se en tendens för medelvärdet att minska i varians vid fler kast? Svänger kurvan in mot något specifikt värde? dat_dice &lt;- data.frame(Utfall = c(___)) %&gt;% mutate(Kast = 1:n(), kumulativ_summa = cumsum(Utfall), kumulativt_medelvärde = `Kumulativ summa` / Kast) dat_dice Uppgift 2.14 (Kumulativ frekvens) Om man vill titta på andelen gånger ett visst utfall inträffat talar man om kumulativ frekvens snarare än kumulativt medelvärde. Använd stycket nedan för att titta på andelen gånger utfallet varit en etta (ett positivt utfall, i begreppets kliniska mening). Om ett inte är ett möjligt utfall på din tärning, ändra ettan till något mer lämpligt. dat_dice &lt;- data.frame(Utfall = c(___)) %&gt;% mutate(Kast = 1:n(), positivt_utfall = Utfall == 1, kumulativt_antal = cumsum(positivt_utfall), kumulativ_frekvens = kumulativt_antal / Kast) dat_dice ggplot(dat_dice, aes(x = Kast, y = kumulativ_frekvens)) + geom_line() 2.8 Tredimensionella grafer med plotly De två avslutande avsnitten är mindre viktiga och kan läsas i mån av tid. Paketet plotly kan användas för att göra interaktiva graf och grafer med tre dimensioner. Börja med att ladda paketet. library(plotly) Vi börjar med ett enkelt exempel på en 3d-graf med lite skapad data. dat_ex &lt;- data.frame(Var1 = c(1,2,3), Var2 = c(3,1,2), Var3 = c(2,3,1), Type = c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;)) dat_ex plot_ly(dat_ex, x = ~Var1, y = ~Var2, z = ~Var3, color = ~Type) %&gt;% add_markers() Om grafen inte kommer upp direkt kan det fungera att trycka på den lilla ikonen med ett fönster och en pil i Viewer-fliken. Grafen ska då öppnas i en webbläsare. Syntaxen till plot_ly() är inte helt olik ggplot(). Först anges datan, därefter argument för x- y-, och z-koordinater. Notera tilde-tecknet ~ före variabelnamnen. Eventuell färg sätts med color. Efter det lägger man till punkter (här markers) med en pipe in i add_markers(). Vi vill göra en liknande graf med gapminder-datan, men får börja med att filtrera på ett visst år. Uppgift 2.15 (Filtrera för år) Vad måste läggas till i funktionen nedan för att filtrera för data där året är 2007? dat_2007 &lt;- gapminder %&gt;% filter(year == ___) Vi kan nu konstruera en 3d-graf med datan. Uppgift 2.16 (Gapminder i 3d) Vad måste läggas till i funktionen nedan för en 3d-graf med befolkningsmängd (pop) på x-axeln, livslängd (lifeExp) på y-axeln, bnp per capita (gdpPercap) på z-axeln, och färg efter kontinent (continent)? För att kunna identifiera specifika länder kan man också sätta argumentet text. plot_ly(data_2007, x = ~pop, y = ~___, z = ~___, color = ~continent, text = ~country) %&gt;% add_markers() Uppgift 2.17 (Log-transformationer) Inom statistiken är det vanligt att transformera variabler för att ta bort extremeffekter och visa på specifika dataegenskaper. En vanlig transform är att logaritmera ett värde, vilket innebär att man istället för att använda det ursprungliga värdet använder exponenten i någon bas (ofta basen tio). Ta till exempel värdet 10000, dess tio-logaritm är 4, eftersom 10 upphöjt i 4 är 10000. Logaritmer är vanliga vid data med extremvärden. Grafen i uppgiften ovan präglas mycket av skillnader i bnp och befolkningsstorlek. Testa att tio-logaritmera variablerna och se om det blir en mer eller mindre överskådlig graf. Logaritmen kan göras genom att byta den ursprungliga variabeln mot en variabel transformerad med log10(). Fyll i stycket nedan. plot_ly(dat_2007, x = ~log10(pop), y = ~log10(___), z = ~___, color = ~___, text = ~country) %&gt;% add_markers() Uppgift 2.18 (Följa ett land) Likt en ggplot kan man lägga till graf-element. Här använder man dock en pipe för lägga till ett nytt element. Fyll i kodstycket nedan. Vad, om något, har lagts till i grafen? plot_ly(dat_2007, x = ~log10(pop), y = ~log10(___), z = ~___, color = ~continent, text = ~country) %&gt;% add_markers() %&gt;% add_lines(data = gapminder %&gt;% filter(country == &quot;Costa Rica&quot;)) 2.9 AI-uppgift II Uppgift 2.19 (Standardavvikelse från gapminder-datan) Använd en chatbot (såsom Microsofts co-pilot eller OpenAIs ChatGPT) för att få kod som beräknar standardavvikelsen av medellivslängd från gapminder-datan. Fråga också om tolkning av standardavvikelsen och om det finns några specifika tolkningsproblem för just den här gapminder-datan. Uppgift 2.20 (3d-graf återigen) Använd en chatbot (såsom Microsofts co-pilot eller OpenAIs ChatGPT) för att få kod som skapar en 3d-graf lik den vi skapade ovan. Se om det går att utveckla grafen ytterligare, t.ex. med en linje som går ner till grafen botten, eller linjer som kopplar samma länder till kontinentens medelvärde. "],["ett-stickprov-av-normalfördelad-data.html", "3 Ett stickprov av normalfördelad data 3.1 Repetition från datorövning 2 3.2 Test av medelvärde för normalfördelad data 3.3 Konfidensintervall för normalfördelad data 3.4 Normalfördelad data och centrala gränsvärdesatsen 3.5 Centrala gränsvärdesatsen 3.6 Bonus. Simuleringar för t-test och konfidensintervall", " 3 Ett stickprov av normalfördelad data Datorövning 3 handlar om hypotestest och konfidensintervall för ett stickprov av normalfördelad data. Efter övningen ska vi kunna genomföra och tolka ett t-test för normalfördelad data, beräkna och tolka ett konfidensintervall för normalfördelad data, använda simulerad data för att förstå t-testets egenskaper. 3.1 Repetition från datorövning 2 När man startar en ny R-session bör man ladda de paket man vet kommer behövas med library(). Om paket inte finns installerade måste man först köra install.packages(). # install.packages(&quot;tidyverse&quot;) library(tidyverse) I datorövning 2 tittade vi på hur insamlade variabler kan sammanfattas med lägesmått och spridningsmått. Ett enkelt sätt att ta fram dem är att använda summarise() och ange de mått och variabler man vill använda. Vi hade uppe ett exempel på data från Gapminder som vi importerade från en excel-fil. För nu kan vi dock hämta datan från paketet gapminder. # install.packages(&quot;gapminder&quot;) library(gapminder) gapminder %&gt;% filter(year == 2007) %&gt;% group_by(continent) %&gt;% summarise(`Livslängd, medel` = mean(lifeExp), `Befolkning, median` = median(pop), `Bnp per capita, standardavvikelse` = sd(gdpPercap)) Beskrivande mått sammanfattas ofta i någon enkel vetenskaplig graf. Två vanliga val är lådagrammet, som illustrerar kvartiler och möjliga extremvärden, och stapeldiagrammet med felstaplar. Vi ger först ett exempel på ett lådagram över livslängd per kontinent uppdelat efter år. ggplot(gapminder, aes(lifeExp, continent, fill = continent)) + geom_boxplot() + facet_wrap(~ year) Därefter ett exempel på ett stapeldiagram med felstaplar för samma data. Felstapeln ges av standardavvikelsen. dat_sum &lt;- gapminder %&gt;% group_by(continent, year) %&gt;% summarise(Mean = mean(lifeExp), SD = sd(lifeExp)) dat_sum ## # A tibble: 60 × 4 ## # Groups: continent [5] ## continent year Mean SD ## &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Africa 1952 39.1 5.15 ## 2 Africa 1957 41.3 5.62 ## 3 Africa 1962 43.3 5.88 ## 4 Africa 1967 45.3 6.08 ## 5 Africa 1972 47.5 6.42 ## 6 Africa 1977 49.6 6.81 ## 7 Africa 1982 51.6 7.38 ## 8 Africa 1987 53.3 7.86 ## 9 Africa 1992 53.6 9.46 ## 10 Africa 1997 53.6 9.10 ## # ℹ 50 more rows ggplot(dat_sum, aes(continent, Mean, fill = continent)) + geom_col() + geom_errorbar(aes(ymin = Mean - SD, ymax = Mean + SD), width = 0.3) + facet_wrap(~ year) 3.2 Test av medelvärde för normalfördelad data Om man har en normalfördelad variabel och vill testa om populationens medelvärde är skilt från något hypotetiskt värde \\(\\mu_0\\) kan man använda ett t-test för ett stickprov. Ta som exempel följande data på 8 observationer av havreskörd. Av någon historisk anledning vill man testa om populationsmedelvärdet är skilt från 50. library(tidyverse) dat &lt;- data.frame(x = c(49.8, 58.4, 49.4, 57.1, 52.2, 49.1, 44.6, 55.4)) dat ## x ## 1 49.8 ## 2 58.4 ## 3 49.4 ## 4 57.1 ## 5 52.2 ## 6 49.1 ## 7 44.6 ## 8 55.4 ggplot(dat, aes(x, 0)) + geom_point() + geom_vline(xintercept = 50, color = &quot;red&quot;) I grafen ser vi att värdena ligger jämt spridda kring 50, så 50 är nog ganska rimligt som medelvärde, men låt oss göra ett formellt test. I R kan ett t-test genomföras med t.test(). t.test(dat$x, mu = 50) # Ett t-test på variabeln x i dataobjektet dat ## ## One Sample t-test ## ## data: dat$x ## t = 1.2086, df = 7, p-value = 0.266 ## alternative hypothesis: true mean is not equal to 50 ## 95 percent confidence interval: ## 48.08713 55.91287 ## sample estimates: ## mean of x ## 52 Utskriften ger ett p-värde från vilket vi kan dra en slutsats. I det här fallet är p-värdet högt (över fem procent) så vi kan inte förkasta nollhypotesen (vilken är att populationsmedelvärdet är lika med 50). Vi tittar nu på stegen bakom t-testet. Ett t-test bygger, som alla hypotestest, på en serie steg: sätt upp en nollhypotes och en alternativhypotes, beräkna ett testvärde från en testfunktion, identifiera en testfördelning, beräkna ett p-värde, eller uppskatta ett genom att ställa testvärde mot ett kritiskt värde, dra en klar slutsats om statistisk signifikans. Vi vill testa om medelskörden är skild från 50, så hypoteser ges av H0: mu lika med 50 H1: mu ej lika med 50 Alternativhypotesen är tvåsidig - vi tittar både på möjligheten att populationsmedelvärdet är större och på möjligheten att det är mindre. Uppgift 3.1 (Ensidig mothypotes) Hur hade hypoteserna sett ut om vi ville testa om medelvärdet är större än 50? Vårt mål är att testa ett medelvärde och det är rimligt att anta normalfördelning för den undersökta variabeln. Det lämpliga testet är då ett t-test för ett stickprov och testvärdet kan beräknas av en testfunktion som ges av det observerade stickprovet minus nollhypotesens värde, delat på standardavvikelsen delat på roten ur antalet observationer. Låt oss beräkna detta i flera steg och jämföra med utskriften från t.test(). mean(dat$x) ## [1] 52 sd(dat$x) ## [1] 4.680354 t_value &lt;- (52 - 50) / (4.680354 / sqrt(8)) Uppgift 3.2 (Operationsordning) Räkna ut samma sak på miniräknare eller telefon. Vad händer om man missar parenteser runt 4.680354 / sqrt(8)? Uppgift 3.3 (t-värdets delar) Vad händer med t-värdet om något av följande händer, givet att övriga delar är desamma? Det observerade medelvärdet (här 52) ökar. Nollhypotesens värde (här 50) minskar. Standardavvikelsen (här 4.680354) minskar. Antalet observationer (här 8) ökar. Testa genom att ändra värdena i kodstycket ovan och beräkna t_value på nytt. Nästa steg är att identifiera testfördelning, det vill säga den slumpfördelning testvärdet följet om nollhypotesen är sann. Fördelningen ges i regel av statistisk teori. I det här fallet är testfördelning en t-fördelning med n - 1 frihetsgrader. Vi har åtta observationer, så antalet frihetsgrader blir 7. I R kan man ta fram täthetsfunktionen för en t-fördelning med dt() och fördelningsfunktionen med pt(). dat_t &lt;- data.frame(x = seq(-4, 4, 0.1)) %&gt;% mutate(p = dt(x, df = 7), P = pt(x, df = 7)) ggplot(dat_t, aes(x, p)) + geom_line() ggplot(dat_t, aes(x, P)) + geom_line() Nästa steg i ett hypotestest är att ta fram ett p-värdet. P-värdet kan illustreras som ytan under t-fördelning bortom test-värdet. I ett tvåsidigt test tar vi med bägge svansarna. ggplot(dat_t) + geom_line(aes(x, p)) + geom_ribbon(aes(x = x, ymin = 0, ymax = p), data = dat_t %&gt;% filter(x &gt; abs(t_value)), fill = &quot;salmon&quot;) + geom_ribbon(aes(x = x, ymin = 0, ymax = p), data = dat_t %&gt;% filter(x &lt; -abs(t_value)), fill = &quot;salmon&quot;) De röda ytorna i svansarna motsvarar p-värdet. De anger sannolikheten att få ett större t-värde än det vi fått, under antagandet att nollhypotesen stämmer. Vi kan beräkna p-värdet med pt(). För ett tvåsidigt test multipliceras värdet med 2. 2 * pt(-abs(t_value), 7) # Tvåsidigt p-värde ## [1] 0.2660402 P-värdet ges av 0.266. En tolkning av det är om försöket upprepas ett stort antal gånger och nollhypotesen är sann, kommer vi 26.6 procent av gångerna få ett större testvärde än 1.2086. Det vi observerar är ganska sannolikt under nollhypotesen, vilket tyder på att nollhypotesen är rimligt. Det avslutande steget är att dra en formell slutsats och ge ett tydligt svar. Det klassiska sättet är att jämföra p-värdet med en förbestämd signifikansnivå, oftast fem procent. Här är p-värdet över den nivån, så vi kan inte förkasta nollhyptesen. Slutsatsen är att det inte finns någon signifikant skillnad från 50 i havreskörd. Uppgift 3.4 (Kritiskt värde) Om man gör ett t-test för hand kan man inte enkelt ta fram ett p-värde, men kan se om p-värdet är större eller mindre än fem procent genom att ställa testvärdet mot ett kritiskt värde. Använd en tabell för t-fördelning för att hitta det kritiska värdet. I R kan man ta fram kritiska värden med qt(). För fem procent i svansarna har man 0.025 i respektive svans och det kritiska värdet ges av qt(0.975, 7) ## [1] 2.364624 Som visades i början har R en specifik funktion för t-testet, t.test(). Funktionens argument är datan man testar och ett nollhypotesvärde mu. Om man vill ha ett ensidigt test kan det sättas med argumentet alternative. För vår data ges testet av t.test(dat$x, mu = 50) # Tvåsidigt test ## ## One Sample t-test ## ## data: dat$x ## t = 1.2086, df = 7, p-value = 0.266 ## alternative hypothesis: true mean is not equal to 50 ## 95 percent confidence interval: ## 48.08713 55.91287 ## sample estimates: ## mean of x ## 52 Funktionen skriver ut det beräkna t-värdet, antal frihetsgrader och p-värdet. Uppgift 3.5 (Ensigt test) Använd ?t.test för att ta fram funktionens hjälpsida. Försök att utifrån hjälpsidan beräkna ett ensidigt test för att se om medelskörden är större än 50. Uppgift 3.6 (Ny nollhypotes) Upprepa det tvåsidiga testet från exemplet ovan. Testa denna gång om medelskörden är skild från 48. Dra en tydlig slutsats. Uppgift 3.7 (Importera smältpunkt-data) På canvassidan finns en excelfil med data för kursens uppgifter Uppgiftsdata.xlsx. Fliken Smältdata innehåller data för en legerings smältpunkt. Ladda ner filen till lämplig plats på datorn och importera datan genom att fylla i följande rad. library(readxl) dat_smält &lt;- read_excel(&quot;___&quot;, sheet = &quot;Smältpunkt&quot;) Uppgift 3.8 (Plotta smältpunkt-data) Illustrera smältpunktsdatan på samma sätt som exempeldatan genom att fylla i följande kod. Vårt mål är att testa om medelvärde är skilt från 1050, vilket här kan noteras med ett vertikalt streck vid 1050. ggplot(___, aes(x = Smältpunkt, y = 0)) + ___() + geom_vline(xintercept = ___, color = &quot;red&quot;) Kan man utifrån grafen säga om 1050 är ett rimligt medelvärde för populationen, givet det stickprov vi observerar? Uppgift 3.9 (Hypotestest för hand) Genomför ett t-test för hand för att se om medelsmältpunkten är skild från 1050. Skriv ut tydliga hypoteser. Medelvärde och standardavvikelse ges av följande. mean(dat_smält$Smältpunkt) sd(dat_smält$Smältpunkt) Ett kritiskt värde kan tas från en tabell över t-fördelningen eller beräknas i R med qt(0.975, df = 9) Uppgift 3.10 (Hypotestest i R) Genomför ett t-test med funktionen t.test() för att se om medelsmältpunkten är skild från 1050. 3.3 Konfidensintervall för normalfördelad data För exemplet på havredata tittade vi på två olika värden för nollhypotesen. t.test(dat$x, mu = 50) t.test(dat$x, mu = 48) Från p-värdena kan man dra slutsatsen att förkasta vid nollhypotesen att mu är 48, men inte förkasta vid nollhypotesen att mu är 50. Värdet 50 är alltså i någon mening ett mer troligt värde på populationens medelvärde än vad 48 är. Konfidensintervall kan ses som en generalisering av den tanken: ett konfidensintervall ger ett spann av värden där man inte förkastar. Intervallet tolkas vanligen som att det täcker det sanna populationsmedelvärdet med en viss konfidens. För ett stickprov och antagen normalfördelning ges konfidensintervallet av medelvärde ± kvantil från t-fördelningen x standardavvikelse delat på roten ur antalet observationer Kvantilen från t-fördelningen kan hämtas från en tabell (samma som det kritiska värdet i testet) eller genom R. Antalet frihetsgrader ges av antalet observationer minus ett. I det här fallet ges delarna av mean(dat$x) ## [1] 52 sd(dat$x) ## [1] 4.680354 qt(0.975, 7) ## [1] 2.364624 och konfidensintervallet ges alltså av 52 ± 2.365 * 4.680 / sqrt(8) Uppgift 3.11 (Konfidensintervall för hand) Ta fram medelvärde, standardavvikelse och kritiskt värde för smältpunktsdata, med hjälp av R (eller en tabell för det kritiska värdet). Beräkna konfidensintervallet för smältpunktsdatan för hand. Funktionen t.test() ger automatiskt ett konfidensintervall, direkt under utfallet av testet. Notera att konfidensintervallet inte beror på nollhypotesen. Konfidensintervall kan beräknas med skilda konfidensnivåer, oftast 95 procent, vilket sätts med argumentet conf.level. Uppgift 3.12 (Konfidensnivå) Gör lämplig ändring i koden nedan för att beräkna ett 99-procentigt konfidensintervall, istället för ett 95-procentigt. t.test(dat$x, conf.level = 0.95) ## ## One Sample t-test ## ## data: dat$x ## t = 31.425, df = 7, p-value = 8.538e-09 ## alternative hypothesis: true mean is not equal to 0 ## 95 percent confidence interval: ## 48.08713 55.91287 ## sample estimates: ## mean of x ## 52 Är ett 99-procentigt konfidensintervall bredare eller smalare än ett 95-procentigt? Uppgift 3.13 (Ensidiga konfidensintervall) I en tidigare uppgift användes argumentet alternative för att göra ett ensidigt test med t.test(). Vad händer med konfidensintervallet om man anger ett ensidigt test? Uppgift 3.14 (Konfidensintervall för smältdata) Ta datan över smältpunkter och beräkna ett konfidensintervall med t.test(). Tolka intervallet. Ett konfidensintervall illustreras ofta med en felstapel. Vi kan lägga till en till den punktgraf vi tidigare sett för observationerna. interval &lt;- t.test(dat$x)$conf.int ggplot(dat, aes(x, 0)) + geom_point() + annotate(&quot;errorbar&quot;, xmin = interval[1], xmax = interval[2], y = -1, width = 0.1) Uppgift 3.15 (Illustration av smältdata) Använd exempelillustrationen för havredata till en liknande illustration av smältpunktsdatan. 3.4 Normalfördelad data och centrala gränsvärdesatsen Eftersom t-testet bygger på att data är normalfördelad är det förstås bra att kunna undersöka om det antagandet stämmer. Ett sätt är att göra ett histogram över datan - om den underliggande variabeln är normalfördelad bör stickprovet ge den typiska klockformen. Det här kräver dock ganska mycket data. Ta ett histogram för havredatan som exempel ggplot(dat, aes(x)) + geom_histogram(bins = 5) Uppenbarligen helt meningslöst. Låt oss titta på histogram över genererad normalfördelad data. n &lt;- 10 ggplot() + geom_histogram(aes(x = rnorm(n)), bins = 30) Uppgift 3.16 (Histogram för normalfördelning) Testa koden ovan för lite olika värden på n. Det kan vara nyttigt att sätta antalet staplar bins för att få ett bättre histogram. Hur stort måste n vara för att ge en karaktäristisk klockform för histogrammet? Ett annat vanligt alternativ för att grafisk undersöka om data följer en ungefärlig normalfördelning är en QQ-graf (QQ-plot). En qq-graf är ett spridningsdiagram med teoretiska kvantiler på en axel och datans kvantiler på den andra axeln. Om data perfekt följer en normalfördelning kommer grafen visa en rak diagonal linje. En QQ-graf kan tas fram med qqnorm() eller geom_qq() i en ggplot. En diagonal linje för jämförelse kan läggas till med geom_qq_line(). ggplot(dat, aes(sample = x)) + geom_qq() + geom_qq_line() Punkterna ligger nära linjen. Vi kan återigen demonstrera med lite genererad data. n &lt;- 10 dat_norm &lt;- data.frame(x = rnorm(n)) ggplot(dat_norm, aes(sample = x)) + geom_qq() + geom_qq_line() Uppgift 3.17 (Histogram för normalfördelning) Funktionen runif() ger slumpmässiga värden mellan 0 och 1. Testa att ändra i kodstycket ovan så att slumptal genereras med runif() istället för rnorm(). Hur påverkar det QQ-grafen? 3.5 Centrala gränsvärdesatsen Även om data inte är normalfördelad kan t-testet vara ett lämpligt val av test. Detta beror på centrala gränsvärdesatsen, som säger att summor (och därmed även medelvärden) av lika slumpvariabler går mot en normalfördelning där antalet observationer ökar. Den tidigare uppgiften gav att runif() inte ger normalfördelad data. Vad händer om vi tar medelvärdet av flera observationer från runif()? Följande kod beräknar tiotusen medelvärden av två observationer. n &lt;- 2 dat_sim_unif &lt;- expand_grid(Observation = 1:n, Upprepning = 1:10000) %&gt;% mutate(x = runif(n())) %&gt;% group_by(Upprepning) %&gt;% summarise(x = mean(x)) ggplot(dat_sim_unif, aes(x)) + geom_histogram(bins = 50) ggplot(dat_sim_unif, aes(sample = x)) + geom_qq() + geom_qq_line() Fördelningen för summan är inte likformig, men inte heller särskilt normalfördelad. Vad händer om vi ökar antal termer i summan? Uppgift 3.18 (Antalet observationer för normalfördelning) Vad måste ändras i koden ovan för beräkna medelvärdet av tio observationer? Följer de medelvärdena en ungefärlig normalfördelning? Vad är det lägsta antalet observationer som ger ungefärligen normalfördelade medelvärden? Under en tidigare datorövning såg vi exempel på diskreta fördelningar: binomial- och poissonfördelningarna. Vi ska senare titta på specifika test för variabler som följer en diskret fördelning, men centrala gränsvärdesatsen kan även då rättfärdiga ett t-test. Ta som exempel medelvärdet av tio observationer som följer en poissonfördelning med lambda = 10. n &lt;- 10 lambda &lt;- 10 dat_sim_unif &lt;- expand_grid(Observation = 1:n, Upprepning = 1:10000) %&gt;% mutate(x = rpois(n(), lambda = lambda)) %&gt;% group_by(Upprepning) %&gt;% summarise(x = mean(x)) ggplot(dat_sim_unif, aes(x)) + geom_histogram(bins = 30) ggplot(dat_sim_unif, aes(sample = x)) + geom_qq() + geom_qq_line() Histogrammet visar på en typisk klockform och punkterna följer linjen ungefärligt. QQ-grafens trappeffekt är typisk för diskret data. Det här tyder alltså på att t-testet är ett acceptabelt alternativ om man har en poissonfördelning med lambda runt tio och gör tio upprepningar. Uppgift 3.19 (Svag normalapproximation) Testa att minska värdena på n och lambda. Vad är de lägsta värdena som ger ett histogram med en symmetrisk fördelning och punkter nära linjen i QQ-grafen? Det kan också finnas situationer där någon matematisk transformation kan göra icke-normal data till normalfördelad data. Vanliga transformationer är att ta en kvadratrot eller att logaritmera datan. Som exempel kan vi återvända till Gapminder-datan vi använde i en tidigare datorövning. Paketet patchwork kan användas för att placera flera grafer bredvid varandra. Den exakta koden är mindre viktig här. library(gapminder) gapminder_2007 &lt;- gapminder %&gt;% filter(year == 2007) g1 &lt;- ggplot(gapminder_2007, aes(pop)) + geom_histogram(bins = 30) g2 &lt;- ggplot(gapminder_2007, aes(sample = pop)) + geom_qq() + geom_qq_line() g3 &lt;- ggplot(gapminder_2007, aes(sqrt(pop))) + geom_histogram(bins = 30) g4 &lt;- ggplot(gapminder_2007, aes(sample = sqrt(pop))) + geom_qq() + geom_qq_line() g5 &lt;- ggplot(gapminder_2007, aes(log10(pop))) + geom_histogram(bins = 30) g6 &lt;- ggplot(gapminder_2007, aes(sample = log10(pop))) + geom_qq() + geom_qq_line() library(patchwork) g1 + g3 + g5 + g2 + g4 + g6 I grafen har vi den ursprungliga variabeln (befolkning per land 2007), den kvadratrot-transformerade variabeln (sqrt()) och den log-transformerade variabeln (log10()). De två första fallen påverkas kraftigt av extremvärden och är klart icke-normala medan den log-transformerade variabeln ger en ungefärlig normalkurva och följer diagonalen väl i QQ-grafen. Uppgift 3.20 (Transformera medellivslängd) Använd kodstycket ovan som mall och ta fram grafer för medellivslängd (lifeExp) istället för befolkningsstorlek (pop). Visar grafen samma mönster som för befolkningsdatan? 3.6 Bonus. Simuleringar för t-test och konfidensintervall Följande kod simulerar ett dataset om tio observationer från en normalfördelning med medelvärde 7 och standardavvikelse 5, beräknar ett hypotestest med nollhypotesen att populationsmedelvärdet är 7, och beräknar ett konfidensintervall. dat_sim &lt;- data.frame(x = rnorm(10, mean = 7, sd = 5)) t.test(dat_sim$x, mu = 7) ## ## One Sample t-test ## ## data: dat_sim$x ## t = 0.76137, df = 9, p-value = 0.4659 ## alternative hypothesis: true mean is not equal to 7 ## 95 percent confidence interval: ## 4.592909 11.849407 ## sample estimates: ## mean of x ## 8.221158 Uppgift 3.21 (Upprepad simulering) Kör de två raderna i stycket ovan ett tiotal gånger. Du bör se att man ibland förkastar nollhypotesen trots att den ska stämma. Kan du få en känsla för hur stor andel av gångerna man felaktigt förkastar? Låt oss upprepa simuleringen tusen gånger. Ett sätt är att upprepa ett steg flera gånger är genom en for-loop. dat_sim &lt;- data.frame() for(i in 1:1000){ new_data &lt;- data.frame(x = rnorm(10, mean = 7, sd = 5)) test &lt;- t.test(new_data$x, mu = 7) new_results &lt;- data.frame(t_value = test$statistic, p_value = test$p.value, ci_lower = test$conf.int[1], ci_upper = test$conf.int[2]) dat_sim &lt;- bind_rows(dat_sim, new_results) } Enligt statistisk teori ska t-värdet följa en t-fördelning med nio frihetsgrader. Vi kan undersöka det genom ett histogram med en överliggande t-fördelning. ggplot(dat_sim) + geom_histogram(aes(t_value, y = ..density..), bins = 50, fill = &quot;white&quot;, color = &quot;black&quot;) + geom_function(fun = dt, args = list(df = 9), color = &quot;red&quot;, size = 1) Den teoretiska t-fördelning passar histogrammet nästan perfekt. Vidare ska p-värdet vara under fem procent fem procent av gångerna. mean(dat_sim$p_value &lt; 0.05) ## [1] 0.041 Även det stämmer någorlunda väl. Det här innebär alltså att om man har en signifikansnivå på fem procent kommer man förkasta nollhypotesen fem procent av gångerna även om nollhypotesen stämmer. Det kallas ett falskt positivt utfall. Uppgift 3.22 (Simulerade konfidensintervall) Hur många av de simulerade konfidensintervallen täcker värdet 7? Uppgift 3.23 (Signifikant skillnad) Stycket nedan simulerar data när populationsmedelvärdet är 9 och t-test har nollhypotesen att populationsmedelvärdet är 7. Här vill vi alltså förkasta nollhypotesen. dat_sim &lt;- data.frame() for(i in 1:1000){ new_data &lt;- data.frame(x = rnorm(10, mean = 9, sd = 5)) test &lt;- t.test(new_data$x, mu = 7) new_results &lt;- data.frame(t_value = test$statistic, p_value = test$p.value, ci_lower = test$conf.int[1], ci_upper = test$conf.int[2]) dat_sim &lt;- bind_rows(dat_sim, new_results) } Använd kod från den första simuleringen för att undersöka hur väl histogrammet stämmer med den teoretiska fördelningen och för att se hur stor andel av gångerna man förkastar nollhypotesen på signifikansnivån 5 procent. Uppgift 3.24 (50/50) Stycket nedan simulerar data när populationsmedelvärdet är 9 och t-test har nollhypotesen att populationsmedelvärdet är 7. Ändra värdet för n och se hur det påverkar andelen gånger man förkastar nollhypotesen. n &lt;- 10 dat_sim &lt;- data.frame() for(i in 1:1000){ new_data &lt;- data.frame(x = rnorm(n, mean = 9, sd = 5)) test &lt;- t.test(new_data$x, mu = 7) new_results &lt;- data.frame(t_value = test$statistic, p_value = test$p.value, ci_lower = test$conf.int[1], ci_upper = test$conf.int[2]) dat_sim &lt;- bind_rows(dat_sim, new_results) } mean(dat_sim$p_value &lt; 0.05) Ungefär hur många observationer behövs för att ha femtio procents sannolikhet att förkasta nollhypotesen? Uppgift 3.25 (Konfidensintervallets bredd) Ett konfidensintervall blir smalare och smalare ju större stickprovet är. Koden nedan ger medelvärdet för stickprovsbredden i simulerad data med standardavvikelsen 1. n &lt;- 10 dat_sim &lt;- data.frame() for(i in 1:1000){ new_data &lt;- data.frame(x = rnorm(n, mean = 0, sd = 1)) test &lt;- t.test(new_data$x, mu = 7) new_results &lt;- data.frame(t_value = test$statistic, p_value = test$p.value, ci_lower = test$conf.int[1], ci_upper = test$conf.int[2]) dat_sim &lt;- bind_rows(dat_sim, new_results) } mean(dat_sim$ci_upper - dat_sim$ci_lower) Ungefär hur många observationer behövs för att konfidensintervallets bredd ska bli under 1, under 0.9, under 0.8, och så vidare ned till 0.1? "],["ett-stickprov-av-icke-normalfördelad-data.html", "4 Ett stickprov av icke-normalfördelad data 4.1 Repetition av datorövning 3 4.2 Proportioner från binär data 4.3 Konfidensintervall för proportioner 4.4 Chi-två-test för goodness-of-fit 4.5 Chi-två-test när någon parameter skattas från datan 4.6 Bonus. Interaktiva kartor med leaflet", " 4 Ett stickprov av icke-normalfördelad data Datorövning 4 handlar om hypotestest och konfidensintervall för ett stickprov av icke-normalfördelad data. Efter övningen ska vi kunna genomföra och tolka ett z-test för proportioner, genomföra och tolka ett chi-två-test för nominal data beräkna och tolka ett konfidensintervall för proportioner, använda simulerad data för att förstå testens egenskaper. Om det finns tid för en bonussektion kommer vi också titta på interaktiva kartor med leaflet. 4.1 Repetition av datorövning 3 När man startar en ny R-session bör man ladda de paket man vet kommer behövas med library(). Om paket inte finns installerade måste man först köra install.packages(). # install.packages(&quot;tidyverse&quot;) library(tidyverse) I datorövning 4 tittade vi på analys av ett stickprov av normalfördelad data. Det underliggande upplägget är att vi vill säga något om en population genom att titta på ett stickprov. Ett t-test kan användas för att testa en given nollhypotes. Ett konfidensintervall ringar in populationens medelvärde med en viss konfidensgrad - oftast 95 procent. Ett normalfördelningsantagande kan undersökas med histogram eller QQ-grafer. Ta som exempel följande data på jord-pH och låt oss anta att det är relevant att testa om populationens medelvärde är 7. dat_pH &lt;- data.frame(pH = c(6.3, 6.55, 6.75, 6.4, 7.25, 6.65, 6.8, 7.3, 7.15, 6.7)) ggplot(dat_pH, aes(pH, 0)) + geom_point(size = 4) + geom_vline(xintercept = 7, size = 5, color = &quot;red&quot;, alpha = 0.4) + theme(axis.text.y = element_blank(), axis.title.y = element_blank(), axis.ticks = element_blank()) Hypoteser ges av H0: mu lika med 7 H1: mu ej lika med 7 Testet kan genomföras med funktionen t.test(). t.test(dat_pH$pH, mu = 7) ## ## One Sample t-test ## ## data: dat_pH$pH ## t = -1.9624, df = 9, p-value = 0.08132 ## alternative hypothesis: true mean is not equal to 7 ## 95 percent confidence interval: ## 6.537164 7.032836 ## sample estimates: ## mean of x ## 6.785 Ett p-värde över 0.05 ger att vi inte förkastar nollhypotesen - den observerade skillnaden mot 7 är inte statistiskt signifikant. Konfidensintervallet ger att populationens medelvärde ligger mellan 6.54 och 7.03 med 95 procents konfidens. En QQ-graf kan visa om det finns några avvikelser från normalantagandet. Med små datamängder är det oftast svårt att se några tydliga tecken på icke-normalitet. ggplot(dat_pH, aes(sample = pH)) + geom_qq() + geom_qq_line() 4.2 Proportioner från binär data Binär data är data där en observation har ett av två utfall, vilka kan kodas som noll och ett. Man talar ibland om utfallet ett som ett positivt utfall. Binär data kan sammanfattas med en proportion - antalet positiva utfall delat på det totala antalet upprepningar. En proportion kan testas med ett z-test för proportioner (eller relativ frekvens). Testet följer stegen för hypotestest (Hypoteser - Testvärde - Testfördelning - P-värde (eller jämförelse med kritiskt värde) - Slutsats). Låt oss importera lite exempeldata och beräkna ett exempel. Följande rad importerar matchresultat i fotbollsallsvenskan för damer 2000-2020. library(tidyverse) dat_alls &lt;- read_csv(&quot;https://raw.githubusercontent.com/adamflr/ST0060/main/Data/Allsvenskan%2C%20damer%2C%202000-2020.csv&quot;) ggplot(dat_alls, aes(hemmamal, bortamal)) + geom_jitter(size = 0.1) Uppgift 4.1 (En interaktiv målgraf) Kör stycket nedan för en interaktiv målgraf. Vilken match gav det högsta antalet gjorda bortamål? # install.packages(plotly) library(plotly) g &lt;- ggplot(dat_alls, aes(hemmamal, bortamal, text = paste(sasong, hemma, &quot;-&quot;, borta))) + geom_jitter(size = 0.1) ggplotly(g) Gammal bollkunskap säger att var tredje match är en bortavinst. Vi kan testa det med ett z-test för proportioner. För att ta fram antalet bortasegrar och totalt antal matcher använder vi count() på kolumnen resultat. Man kan också använda funktionen table() för ett liknande resultat. dat_alls %&gt;% count(resultat) ## # A tibble: 3 × 2 ## resultat n ## &lt;chr&gt; &lt;int&gt; ## 1 Bortaseger 947 ## 2 Hemmaseger 1285 ## 3 Oavgjort 518 table(dat_alls$resultat) ## ## Bortaseger Hemmaseger Oavgjort ## 947 1285 518 Datan har 947 bortasegrar av totalt 947 + 1803 matcher. Vår skattade proportion p och totala antal n är alltså n &lt;- 947 + 1803 p_est &lt;- 947 / n p_est ## [1] 0.3443636 n ## [1] 2750 För att genomföra ett z-test sätter vi upp hypoteser om proportionen bortasegrar. Nollhypotes H0: p lika med 0.33 Alternativhypotes H1: p ej lika med 0.33 Ett test kan köras i R med prop.test(). prop.test(x = 947, n = 2750, p = 0.33, correct = F) ## ## 1-sample proportions test without continuity correction ## ## data: 947 out of 2750, null probability 0.33 ## X-squared = 2.5661, df = 1, p-value = 0.1092 ## alternative hypothesis: true p is not equal to 0.33 ## 95 percent confidence interval: ## 0.3268327 0.3623288 ## sample estimates: ## p ## 0.3443636 P-värdet ställs mot en förbestämd signifikansnivå (vanligen 5 procent). I det här fallet leder det höga p-värdet till att nollhypotesen accepteras. Om vi tar en närmre titt på testets steg brörjar vi med att beräkna ett testvärde. p0 &lt;- 0.33 z_value &lt;- (p_est - p0) / sqrt(p0 * (1 - p0) / n) z_value ## [1] 1.601904 Därefter kan p-värdet räknas ut som arean under en standardiserad normalfördelning bortom z-värdet. Eftersom vi har en tvåsidig mothypotes adderas de två svansarna. dat_norm &lt;- data.frame(x = seq(-4, 4, 0.1)) %&gt;% mutate(p = dnorm(x)) ggplot(dat_norm) + geom_line(aes(x, p)) + geom_ribbon(aes(x = x, ymin = 0, ymax = p), data = dat_norm %&gt;% filter(x &gt; abs(z_value)), fill = &quot;salmon&quot;) + geom_ribbon(aes(x = x, ymin = 0, ymax = p), data = dat_norm %&gt;% filter(x &lt; -abs(z_value)), fill = &quot;salmon&quot;) Areans yta kan tas fram med normalfördelningens fördelningsfunktion pnorm(). 2 * pnorm(-z_value) ## [1] 0.1091769 Testets p-värde är ungefär 11 procent. Vår observation är alltså inte ett orimligt utfall om den faktiska sannolikheten för bortaseger är 0.33 och vi kan inte förkasta nollhypotesen på femprocentsnivån. Om man löste uppgiften för hand skulle man istället för att beräkna p-värdet jämföra z-värdet med ett kritisk värde ur en tabell. Det kritiska värdet för fem-procentig signifikans är 1.96. Vi kan också ta fram det genom qnorm(0.975). Vi kan jämföra den beräkning med den direkta R-funktionen. prop.test(x = 947, n = 2750, p = 0.33, correct = F) ## ## 1-sample proportions test without continuity correction ## ## data: 947 out of 2750, null probability 0.33 ## X-squared = 2.5661, df = 1, p-value = 0.1092 ## alternative hypothesis: true p is not equal to 0.33 ## 95 percent confidence interval: ## 0.3268327 0.3623288 ## sample estimates: ## p ## 0.3443636 Den stegvisa beräkningen gav samma utfall som funktionen (p-value = 0.01092). Funktionen ger inte z-värdet utan ett chi-två-värde (2.5661). Här är det värdet lika med z-värdet i kvadrat. z_value^2 ## [1] 2.566095 Uppgift 4.2 (Ensidigt test) Titta på hjälpsidan med ?prop.test. Hur genomför man ett ensidigt test? Gör lämpligt tillägg för att testa om andelen bortasegrar är större än 0.33. Uppgift 4.3 (Test för proportionen oavgjorda) Samma gamla bollkunskap säger att 20 procent av matcher blir oavgjorda. I datan är 518 av 2750 matcher oavgjorda. Ställ upp hypoteser och fyll i koden nedan för att testa om bollkunskapen stämmer. prop.test(x = ___, n = ___, p = ___, correct = F) Uppgift 4.4 (Test för proportionen hemmasegrar) Slutligen är då resten av matcherna, 1285 av 2750, hemmasegrar. Gammal bollkunskap säger: 47 procent av alla matcher är hemmasegrar. Genomför ett z-test för att testa det påstående. prop.test(x = ___, n = ___, p = ___, correct = F) Uppgift 4.5 (Population och stickprov) Ett hypotestest bygger på en underliggande tanke med en population (med någon för oss okänd proportion positiva utfall) och ett stickprov (i vilket vi kan observera andelen positiva utfall). Det är inte alltid uppenbart vad som egentligen är populationen. I fallet med fotbollsdatan, vad kan ses som populationen? Hur långt skulle man kunna generalisera de slutsatser man kan dra från datan? Uppgift 4.6 (Guldfiskgenetik) (Fråga från Olsson, Biometri) En teori inom genetik förutsäger att tre fjärdedelar i en grupp guldfiskar ska ha genomskinliga fjäll. Observationer ger att nittio av hundra har genomskinliga fjäll. Genomför ett test med prop.test() för att se om den faktiska proportionen skiljer sig från 0.75. Lös gärna först uppgiften för hand eller med miniräknare. Uppgift 4.7 (Mer guldfiskgenetik) (Fråga från Olsson, Biometri) En konkurrerande teori inom genetik förutsäger att femton sextondelar (proportionen 0.9375) ska ha genomskinliga fjäll. Observationer ger att nittio av hundra har genomskinliga fjäll. Genomför ett test med prop.test() för att se om proportionen skiljer sig från 0.9375. Lös gärna först uppgiften för hand eller med miniräknare. Hypotestestet för proportioner som används här, z-testet, bygger på en normalapproximation av en binomialfördelning. Approximation blir bättre när antalet observationer är stort och nollhypotesens värde p0 ligger nära 0.5. En vanlig tumregel för när approximationen är giltig är att n gånger p0 gånger (1 - p0) ska vara större än 10. För fotbollsdatan över oavgjorda matcher ger det 2750 * 0.2 * 0.8 vilket är klart större än 10. Uppgift 4.8 (Giltig approximation) I det andra guldfiskexemplet är antalet observationer 100 och nollhypotesens värde 0.9375. Är normalapproximationen giltig i det fallet? Uppgift 4.9 (Fågelproportioner) I ett naturreservat tror man fördelningen av tre fåglar (tärnmås, fiskmås och fisktärna) är 50, 30 respektive 20 procent. En studie ger antalen 115, 54 respektive 31. Genomför tre z-test för att testa den antagna andelarna. För tärnmås får man till exempel prop.test(115, 200, p = 0.5, correct = F). Uppgift 4.10 (Förbestämd signifikans) En intressant egenskap hos proportionstest är att man redan i förväg kan beräkna vilka utfall som ger signifikanta resulat. Säg att man har möjlighet att göra 100 replikat. Ändra i stycket nedan för att hitta det högsta värde på x som ger ett icke-signifikant utfall. prop.test(x, n = 100, p = 0.5, correct = F) Det är möjligt att göra liknande beräkningar för ett t-test för normalfördelad data, men då måste man göra antaganden om standardavvikelsens storlek. 4.3 Konfidensintervall för proportioner Konstruktionen av ett konfidensintervall för en proportion är ganska lik konstruktionen för ett medelvärde. För en skattad proportion p och antal observationer n kan man beräkna p plus/minus ett z-värde från tabell gånger medelfelet, där medelfelet ges av roten ur p * (1 - p) / n. För exemplet med bortasegrar i allsvenskan är p = 0.344 och n = 2750. Tabellvärdet hämtas från en tabell över kvantiler. För ett 95-procentigt konfidensintervall tar vi kvantilen 0.975 (2.5 procent i respektive svans) vilket ger värdet 1.96. Konfidensintervallet ges av n &lt;- 947 + 1803 p &lt;- 947 / n p - 1.96 * sqrt(p * (1 - p) / n) ## [1] 0.3266042 p + 1.96 * sqrt(p * (1 - p) / n) ## [1] 0.3621231 Notera att 0.33, det värde som var nollhypotesen i det tidigare testet, ingår i intervallet. Om man tittar på utskriften från prop.test() kan man se ett konfidensintervall. Det intervallet är dock inte beräknat på samma sätt den formel som förekommer på föreläsningarna. För att få matchande utskrift kan vi använda paketet binom och funktionen binom.asymp(). #install.packages(&quot;binom&quot;) library(binom) binom.asymp(x = 947, n = 2750) ## method x n mean lower upper ## 1 asymptotic 947 2750 0.3443636 0.3266045 0.3621228 Uppgift 4.11 (99-procentigt konfidensintervall) Gör lämplig ändring i koden nedan för att beräkna ett 99-procentigt konfidensintervall för andelen bortasegrar. binom.asymp(x = 947, n = 2750, conf.level = 0.95) Uppgift 4.12 (Perfekta utfall) Vad händer om man försöker räkna ut ett konfidensintervall för ett perfekt utfall - t.ex. om man får 100 av 100 positiva utfall? Uppgift 4.13 (Konfidensintervall för guldfiskar) Använd funktionen binom.asymp() för att ta fram konfidensintervallet för andelen guldfiskar från den tidigare uppgiften. Hur förhåller sig resultatet till nollhypotesernas värden (0.75 respektive 0.9375)? Gör motsvarande beräkning med miniräknare. 4.4 Chi-två-test för goodness-of-fit Ett proportionstest kan ses som ett test av en variabel med två möjliga klasser som utfall. Ett goodness-of-fit-test utvecklar det till valfritt antal klasser. Testet utförs som ett chi-två-test genom att beräkna ett observerat antal O och ett förväntat antal E för varje klass. Testvärdet ges av att man beräknar (O - E)^2 / E för varje klass och sedan summerar. Testfunktionen är en chi-två-fördelning där antalet frihetsgrader beror på antalet klasser. Låt oss göra ett exempel baserat på fotbollsdatan. Där hade vi utfallet 947, 518 och 1285 för bortaseger, oavgjort och hemmaseger. Klassisk bollkunskap gav oss sannolikheterna 33, 20 och 47 procent. Testets hypoteser ges av H0: sannolikheterna för de olika utfallet ges av 33, 20 respektive 47 procent H1: minst något utfall har en annan sannolikhet än 33, 20 respektive 47 procent För att få de förväntade värdena E multipliceras nollhypotesens sannolikheter med det totala antalet matcher. O &lt;- c(947, 518, 1285) E &lt;- c(0.33,0.20,0.47) * 2750 Uppgift 4.14 (Granska E) Skriv ut objektet E och jämför med de observerade värdena. Notera att de förväntade värdena inte måste vara heltal, trots att de observerade värdena förstås alltid kommer vara det. Testvärdet beräknas genom formeln för varje term följt av summan. chisq_value &lt;- sum((O - E)^2 / E) P-värdet beräknas från en chi-två-fördelning. Antalet frihetsgrader ges av antalet klasser minus antalet skattade parametrar minus ett. I det här fallet har inga parametrar skattats från datan så antalet frihetsgrader blir två. Ett chi-två-test beräknas med kvadrater så vi är enbart intresserade av högra svansen. dat_chisq &lt;- data.frame(x = seq(0, 10, 0.1)) %&gt;% mutate(p = dchisq(x, df = 2)) ggplot() + geom_line(aes(x, p), data = dat_chisq) + geom_ribbon(aes(x, ymin = 0, ymax = p), data = dat_chisq %&gt;% filter(x &gt; chisq_value), fill = &quot;salmon&quot;) Man kan också beräkna ytan i svansen med pchisq(). Ett minus det resultatet ger den övre delen. 1 - pchisq(chisq_value, df = 2) ## [1] 0.1632763 P-värdet är alltså 0.16, över den klassiska signifikansnivån på 5 procent, vilket ger att vi inte kan förkasta nollhypotesen. Om man gör ett chi-två-test för hand jämför man det observerade chi-två-värdet med ett tabellvärde över kvantiler. Tabellvärdet kan också hämtas med funktionen qchisq(), i det här fallet qchisq(0.95, df = 2) ## [1] 5.991465 Notera att man tar 0.95 eftersom man alltid tittar på den yttre svansen i ett chi-två-test. R har en inbyggd funktion för chi-två-test. Dess argument ges av observerade antal och sannolikheter. chisq.test(O, p = c(0.33, 0.2, 0.47)) ## ## Chi-squared test for given probabilities ## ## data: O ## X-squared = 3.6246, df = 2, p-value = 0.1633 Testet ger samma chi-två-värde och p-värde som beräknats ovan. Uppgift 4.15 (Chi-två med två klasser) Situationen med flera klasser kan som sagt ses som en generalisering av fallet med två klasser. Det är alltså logiskt att chi-två-test kan användas även när man har två klasser. Följande exempel ger samma test som vi sett tidigare av andelen bortasegrar. chisq.test(x = c(947, 1803), p = c(0.33, 0.67), correct = F) ## ## Chi-squared test for given probabilities ## ## data: c(947, 1803) ## X-squared = 2.5661, df = 1, p-value = 0.1092 Likt prop.test() sätter vi correct till FALSE för att inte göra en korrektion. Notera att x här anges som positiva och negativa utfall istället för positiva utfall och totalt antal utfall, vilket var fallet i prop.test(). Använd stycket ovan som mall för att göra uppgiften om guldfiskar som ett chi-två-test. Testa nollhypotesen att andelen positiva utfall är 0.75. Chi-två-testet bygger på en underliggande normal-liknande approximation. En vanlig tumregel är att alla förväntade värden ska vara större än 5. R ger en varning om så inte är fallet. chisq.test(c(6,4), p = c(0.51, 0.49)) ## ## Chi-squared test for given probabilities ## ## data: c(6, 4) ## X-squared = 0.32413, df = 1, p-value = 0.5691 Uppgift 4.16 (Chi-två med lika sannolikheter) En vanlig tillämpning av goodness-of-fit-testet är för att testa om alla klasser är lika sannolika. En jämn fördelning är grundinställning i chisq.test() så i det fallet behöver man bara ange de observerade värdena. En datainsamling om M&amp;M-godis gav följande antal. dat_mnm &lt;- data.frame(Color = c(&quot;blue&quot;, &quot;brown&quot;, &quot;green&quot;, &quot;orange&quot;, &quot;red&quot;, &quot;yellow&quot;), Count = c(180, 80, 88, 160, 134, 166)) ggplot(dat_mnm, aes(Color, Count, fill = Color)) + geom_col() + scale_fill_manual(values = dat_mnm$Color) Använd de observerade värdena i kolumnen Count för att testa om alla godisfärger är lika vanliga. Om man har flera klasser kan det vara värdefullt att se vilken klass som bidrar mest till chi-två-värdet. Det kan ge en bild av vilka klasser som är mest speciella. Ett enkelt sätt att göra det på är att spara utfallet av chisq.test() som ett objekt och därifrån hämta observed och expected. Som fortsättning på fotbollsexemplet: test &lt;- chisq.test(c(947, 518, 1285), p = c(0.33, 0.2, 0.47)) test$expected ## [1] 907.5 550.0 1292.5 test$observed ## [1] 947 518 1285 (test$observed - test$expected)^2 / test$expected ## [1] 1.71928375 1.86181818 0.04352031 Antalet hemmavinster (det tredje värdet) ligger när den teoretiska sannolikheten medan de övriga två utfallen ligger längre från. Uppgift 4.17 (Udda färger) Spara testobjektet från testet på M&amp;M-färger för att se vilka färger som avviker mest från det väntade utfallet. Uppgift 4.18 (Fågelproportioner som chi-två) I naturreservatet från en tidigare uppgift tror man fördelningen av tre fåglar (tärnmås, fiskmås och fisktärna) är 50, 30 respektive 20 procent. En studie ger antalen 115, 54 respektive 31. Genomför ett chi-två-test för att testa de antagna andelarna. Är resultatet i linje med de separata testen från den tidigare uppgiften? Uppgift 4.19 (Udda fåglar) Spara testobjektet från chi-två-testet för fåglarna för att se vilka fågelarter som avviker mest från det väntade utfallet. 4.5 Chi-två-test när någon parameter skattas från datan (Det här stycket är överkurs och kan läsas översiktligt eller hoppas över.) I de exempel vi sett hittills har nollhypotesen direkt givit de sannolikheter vi vill testa. Ett annat vanligt fall är att man testar om värdena följer en viss fördelning, men parametervärden i den fördelningen skattas från den insamlade datan. Ta som exempel frågan om antal mål per match följer en poissonfördelning. Hypoteserna ges av H0: antal mål följer en poissonfördelning, H1: antal mål följer ej en poissonfördelning. Här måste vi skatta medelvärdet från datan för att beräkna sannolikheter från fördelningen. mean_goals &lt;- mean(dat_alls$hemmamal + dat_alls$bortamal) mean_goals ## [1] 3.290182 dat_goals &lt;- dat_alls %&gt;% count(Mål = bortamal + hemmamal, name = &quot;O&quot;) %&gt;% mutate(p = dpois(Mål, lambda = mean_goals), E = p * 2750) dat_goals ## # A tibble: 13 × 4 ## Mål O p E ## &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0 138 0.0372 102. ## 2 1 383 0.123 337. ## 3 2 548 0.202 554. ## 4 3 542 0.221 608. ## 5 4 466 0.182 500. ## 6 5 306 0.120 329. ## 7 6 183 0.0656 180. ## 8 7 97 0.0308 84.8 ## 9 8 42 0.0127 34.9 ## 10 9 29 0.00464 12.8 ## 11 10 6 0.00153 4.20 ## 12 11 5 0.000456 1.26 ## 13 12 5 0.000125 0.344 En graf kan illustrera faktiska antal (som punkter) och den skattade poissonfördelningen (som linje). Uppgift 4.20 (Målgraf) Fyll i de saknade delarna i koden nedan för en graf med faktiska antal O som punkter och förväntade antal E som en linje. ggplot(dat_goals) + geom_point(aes(x = Mål, y = ___)) + geom_line(aes(x = Mål, y = ___)) De faktiska observationerna är inte så långt från poissonfördelningen. Ett problem med de förväntade antalen är att några av dem är under 5 - den gräns vi satte för en acceptabel chi-två-approximation. Det vanligaste sättet att hantera det är att slå ihop klasser. Här slås klasser över 9 ihop till en grupp. Det är inte så väsentligt hur det görs här, även om ifelse() kan vara ett nyttigt trick. dat_goals_merged &lt;- dat_goals %&gt;% mutate(Mål = ifelse(Mål &gt; 9, 10, Mål)) %&gt;% group_by(Mål) %&gt;% summarise(O = sum(O), p = sum(p), E = sum(E)) dat_goals_merged ## # A tibble: 11 × 4 ## Mål O p E ## &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0 138 0.0372 102. ## 2 1 383 0.123 337. ## 3 2 548 0.202 554. ## 4 3 542 0.221 608. ## 5 4 466 0.182 500. ## 6 5 306 0.120 329. ## 7 6 183 0.0656 180. ## 8 7 97 0.0308 84.8 ## 9 8 42 0.0127 34.9 ## 10 9 29 0.00464 12.8 ## 11 10 16 0.00211 5.80 En sista svårighet är antalet frihetsgrader. I ett goodness-of-fit-test ges antalet frihetsgrader av antalet klasser minus antalet skattade parametrar minus 1. I det här fallet har vi nu 11 klasser och vi har skattat en parameter. Vi ska alltså ha 9 frihetsgrader i testet. Funktionen chisq.test() beräknar tyvärr antalet frihetsgrader internt som antalet klasser minus 1, så vi får beräkna chi-två-värde och p-värde på egen hand. chisq_value &lt;- sum((dat_goals_merged$O - dat_goals_merged$E)^2 / dat_goals_merged$E) 1 - pchisq(chisq_value, df = 9) ## [1] 6.984746e-12 Chi-två-värdet blir extremt stort och p-värdet väldigt lågt. Nollhypotesen att antalet mål följer en poissonfördelning förkastas. 4.6 Bonus. Interaktiva kartor med leaflet Paketet leaflet (https://rstudio.github.io/leaflet/) kopplar R till leaflet - ett verktyg för interaktiva kartor som ofta använd för kartor online. Uppgift 4.21 (Installera leaflet) Installera och ladda `leaflet genom att fylla i och köra raden nedan. install.packages(&quot;leaflet&quot;) library(leaflet) Som en första kontroll kan vi köra den exempelkod som ges på hemsidan länkad till ovan. m &lt;- leaflet() %&gt;% addTiles() %&gt;% addMarkers(lng = 174.768, lat = -36.852, popup=&quot;The birthplace of R&quot;) m På canvassidan finns en excelfil med data tillgänglig på Artportalen - Artportalen, feromoninventering, 2011-2013.xlsx. Datan kommer från från ett inventeringsprojekt vid SLU. Uppgift 4.22 (Importera datan) Ladda ner excelfilen och läs in datan med read_excel() från paketet readxl. library(readxl) dat_leaf &lt;- read_excel(&quot;___&quot;) Kartans utseende kan ändras genom att ange en källa och karttyp. Tillgängliga alternativ kan skrivas ut med providers. leaflet() %&gt;% addTiles() %&gt;% addProviderTiles(providers$Stamen.Toner) Uppgift 4.23 (Baskarta) Skriv ut tillgängliga baskartor med providers. Välj ett alternativ slumpmässigt och ändra koden ovan för att se hur det ser ut. För att lägga till datapunkter kan man använda addCircleMarkers(). leaflet() %&gt;% addTiles() %&gt;% addCircleMarkers(lng = dat_leaf$lng, lat = dat_leaf$lat, radius = 10) Uppgift 4.24 (Cirkelstorlek) Ändra storleken på cirklarna från addCircleMarkers() genom argumentet radius. Slutligen kan vi lägga till en etikett för år med argumentet popup. Texten kommer upp när man klickar på en punkt. leaflet() %&gt;% addTiles() %&gt;% addCircleMarkers(lng = dat_leaf$lng, lat = dat_leaf$lat, radius = 10, popup = dat_leaf$Rödlistade) Uppgift 4.25 (Artnamn) Ändra i koden ovan för att ange artnamn som popup-text istället för rödlistestatus. Funktionen paste() kan också vara intressant för att ta med mer information i texten: paste(dat_leaf$Rödlistade, dat_leaf$Antal) skulle exempelvis ge både status och antal individer vid den specifika observationen. "],["test-för-två-stickprov.html", "5 Test för två stickprov 5.1 Repetition av datorövning 4 5.2 Två stickprov och normalfördelad data 5.3 z-test och konfidensintervall för två proportioner 5.4 Chi-två-test för korstabeller 5.5 Bonus. Bilder i R", " 5 Test för två stickprov Datorövning 5 handlar om hypotestest och konfidensintervall för jämförelse av två stickprov. Efter övningen ska vi kunna genomföra och tolka t-test för jämförelse av två medelvärden, z-test för jämförelse av två proportioner, chi-två-test för jämförelse fördelningar mellan två eller flera grupper, konfidensintervall för skillnaden mellan två medelvärden eller två proportioner. 5.1 Repetition av datorövning 4 När man startar en ny R-session bör man ladda de paket man vet kommer behövas med library(). Om paket inte finns installerade måste man först köra install.packages(). # install.packages(&quot;tidyverse&quot;) library(tidyverse) I datorövning 5 tittade vi på tester som inte bygger på normalfördelning: dels tester för proportioner, där varje observation är något av två möjliga utfall; dels tester för kategoridata, där varje observation har ett ufall i någon av flera kategorier. Proportioner kan testas med ett z-test. Säg att man testar om en doft har en effekt på en insekt, man skickar 20 insekter i ett y-rör och 16 går mot doften. Hypoteserna ges av H0: proportionen i populationen är 0.5, H1: proportionen i populationen är inte 0.5. I R genomförs ett z-test med prop.test(). Funktionen gör en korrektion som ger ett något bättre test än det man ofta beräknar för hand. Korrektionen kan sättas av med argumentet correct. prop.test(x = 16, n = 20, p = 0.5, correct = F) ## ## 1-sample proportions test without continuity correction ## ## data: 16 out of 20, null probability 0.5 ## X-squared = 7.2, df = 1, p-value = 0.00729 ## alternative hypothesis: true p is not equal to 0.5 ## 95 percent confidence interval: ## 0.5839826 0.9193423 ## sample estimates: ## p ## 0.8 Ett lågt p-värde tyder på en signifikant skillnad från 0.5. För att få samma konfidensintervall som det man beräknar för hand kan man använda binom.asymp() från paketet binom. library(binom) binom.asymp(16, 20) ## method x n mean lower upper ## 1 asymptotic 16 20 0.8 0.6246955 0.9753045 Populationens proportion ligger med 95 procents konfidens mellan 0.62 och 0.98. Om utfallen är mer än två kategorier kan en hypotes om datans fördelning testas med ett goodness-of-fit-test, vilket är ett slags chi-två-test. Testet bygger på att observerade antal (O) ställs mot förväntade antal (E). I R genomförs ett chi-två-test med chisq.test(). Säg som exempel att man studerar fågelpopulationer genom en observationsstudie. Observerade antal av fyra fågelarter är 102, 53, 75 och 12 och de förväntade andelarna av arterna är 50, 15, 25 och 10 procent. Testets hypoteser ges av H0: proportionerna följer den förväntade fördelningen, H1: proportionerna följer inte den förväntade fördelningen, och testet ges av chisq.test(c(102, 53, 75, 12), p = c(0.5, 0.15, 0.25, 0.1)) ## ## Chi-squared test for given probabilities ## ## data: c(102, 53, 75, 12) ## X-squared = 20.292, df = 3, p-value = 0.0001477 Ett lågt p-värde tyder på att de antagna proportionerna inte stämmer. Antalet frihetsgrader ges i ett chi-två-test av antalet klasser minus antalet skattade parametrar minus ett. I det här fallet finns fyra klasser och ingen skattad parameter. 5.2 Två stickprov och normalfördelad data Vid normalfördelad data från två stickprov eller grupper vill vi nästan alltid testa om populationerna har samma medelvärde. Det kan också ses som att vi testar om differensen mellan medelvärdena är noll. Vi skiljer mellan två fall: matchade stickprov - där varje observation i den ena gruppen är kopplad till en observation i den andra gruppen; och oberoende stickprov - där det inte finns någon sådan koppling mellan stickproven. Typiska exempel på matchade stickprov är när man mäter samma individ för och efter en behandling och syskonstudier där ett syskon får en behandling och den andra en annan behandling. 5.2.1 t-test för två matchade stickprov Vid matchade stickprov kan varje observation i en behandlingsgrupp paras med en observation i den andra gruppen. Själva testet är ett t-test för ett stickprov på differensserien beräknat från varje par. I R kan man antingen beräkna den differensserien eller använda t.test() med två dataserier och argumentet för parvisa observationer satt till sant, paired = T. Som exempel ges följande data från en studie på äpple, där trädhöjd mätts före och efter en näringsbehandling. dat_apple &lt;- tibble(Tree = 1:4, Before = c(48, 43, 30, 47), After = c(51, 44, 42, 54)) dat_apple ## # A tibble: 4 × 3 ## Tree Before After ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 48 51 ## 2 2 43 44 ## 3 3 30 42 ## 4 4 47 54 Datan kan illustreras med ett punktdiagram där en linje binder samman paret. För att enkelt skapa grafen i ggplot2 kan man först omstrukturera datan till lång form genom pivot_longer. dat_long &lt;- dat_apple %&gt;% pivot_longer(-Tree, names_to = &quot;Time&quot;, values_to = &quot;Height&quot;) dat_long ## # A tibble: 8 × 3 ## Tree Time Height ## &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 1 Before 48 ## 2 1 After 51 ## 3 2 Before 43 ## 4 2 After 44 ## 5 3 Before 30 ## 6 3 After 42 ## 7 4 Before 47 ## 8 4 After 54 Uppgift 5.1 (Äppelgraf) Fyll i kodstycket nedan för en graf av äppeldatan. Axlarna ges av Time och Height. Två observationer kan kopplas genom att sätta Tree som grupp. ggplot(dat_long, aes(___, ___, group = ___)) + geom_point() + geom_line() För att testa för skillnad före och efter behandling sätter vi upp hypoteser H0: mu före behandling är lika med mu efter behandling H1: mu före behandling är skild från mu efter behandling Testet kan antingen utföras som ett enkelt t-test på differensserien t.test(dat_apple$Before - dat_apple$After) ## ## One Sample t-test ## ## data: dat_apple$Before - dat_apple$After ## t = -2.3681, df = 3, p-value = 0.09868 ## alternative hypothesis: true mean is not equal to 0 ## 95 percent confidence interval: ## -13.477405 1.977405 ## sample estimates: ## mean of x ## -5.75 eller som ett t-test för två stickprov där man särskilt anger att datan är parad t.test(dat_apple$Before, dat_apple$After, paired = T) ## ## Paired t-test ## ## data: dat_apple$Before and dat_apple$After ## t = -2.3681, df = 3, p-value = 0.09868 ## alternative hypothesis: true mean difference is not equal to 0 ## 95 percent confidence interval: ## -13.477405 1.977405 ## sample estimates: ## mean difference ## -5.75 För bägge alternativen måste datan vara ordnad så att de två vektorerna matchar varandra parvis. Ett p-värde på \\(0.0987\\) ger att man inte förkastar vid en signifikansnivå på fem procent. Vi drar därmed slutsatsen att det inte finns någon signifikant skillnad före och efter behandling. Uppgift 5.2 (Ensidigt test) Gör ett tillägg till ett av kodstyckena med t.test() för att beräkna ett ensidigt test med mothypotesen att träden ökar i höjd efter behandling. Hjälpsidan för t.test() kan tas fram genom att köra ?t.test(). Konfidensintervallet beräknas från differenserna på samma sätt som vid ett stickprov med normalfördelad data. Tolkningen liknar den för ett stickprov: med 95 procents konfidens ligger den sanna skillnaden i medelvärden i intervallet. Uppgift 5.3 (Lökimport) Åtta monoglukosidmätningar på lök samlas in från fyra konventionella och fyra ekologiska ordlare. Resultatet finns i fliken Lökfärg i excelfilen Uppgiftsdata.xlsx på canvassidan. Ladda ner filen och importera datan genom att fylla i raden nedan. library(readxl) dat_onion &lt;- read_excel(&quot;____&quot;, sheet = &quot;Lökfärg&quot;) # dat_onion &lt;- read_csv(&quot;https://raw.githubusercontent.com/adamflr/ST0060/main/Data/Uppgiftsdata/Uppgift_L%C3%B6kf%C3%A4rg.csv&quot;) # Alternativ lösning Uppgift 5.4 (Lökgraf) Fyll i stycket nedan för en graf av lökdatan från föregående uppgift. dat_long &lt;- dat_onion %&gt;% pivot_longer(-Odlare, names_to = &quot;Odlingstyp&quot;, values_to = &quot;Utfall&quot;) dat_long ggplot(dat_long, aes(___, ___, group = Odlare)) + geom_point() + geom_line() Tyder grafen på någon skillnad mellan odlingstyper? Uppgift 5.5 (Löktest) Använd lökdatan i föregående uppgift för att testa om det finns en signifikant skillnad mellan konventionell och ekologisk. Formulera hypoteser och genomför testet med t.test(). Lös gärna uppgiften med miniräknare först. 5.2.2 t-test för två oberoende stickprov Ett t-test för två oberoende stickprov testar om två populationsmedelvärden är lika. Ta som exempel följande data på jordgubbsskörd vid två olika näringsbehandlingar (A och B). Här är stickproven inte matchade - det finns ingen direkt koppling mellan en observation i den ena behandlingsgruppen till någon observation i den andra. dat_berry &lt;- data.frame(Behandling = c(&quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;B&quot;, &quot;B&quot;, &quot;B&quot;, &quot;B&quot;), Vikt = c(40, 48.2, 39.2, 47.9, 57.5, 61.5, 58, 66.5)) dat_berry ## Behandling Vikt ## 1 A 40.0 ## 2 A 48.2 ## 3 A 39.2 ## 4 A 47.9 ## 5 B 57.5 ## 6 B 61.5 ## 7 B 58.0 ## 8 B 66.5 Datan kan illustreras med ett enkelt punktdiagram. ggplot(dat_berry, aes(Behandling, Vikt)) + geom_point() Ett t-test för två oberoende stickprov har nollhypotesen att grupperna har samma populationsmedelvärde och alternativhypotesen att populationsmedelvärdena är skilda (för det tvåsidiga fallet): H0: mu_A är lika med mu_B H1: mu_A är ej lika med mu_B Testet kan utföras i R genom funktionen t.test(). Data kan antingen anges som en formel med dess data Vikt ~ Behandling, data = dat_berry (vilket man kan läsa som vikt uppdelat efter behandling) eller som två skilda vektorer. Det förra alternativet är oftast enklare om man har datan på lång form - med en kolumn som anger grupp (i exemplet Behandling) och en kolumn som anger utfallsvärdet (i exemplet Vikt). För formen med formel ger det # Formelskrivning t.test(Vikt ~ Behandling, data = dat_berry, var.equal = T) ## ## Two Sample t-test ## ## data: Vikt by Behandling ## t = -5.3157, df = 6, p-value = 0.001803 ## alternative hypothesis: true difference in means between group A and group B is not equal to 0 ## 95 percent confidence interval: ## -24.898417 -9.201583 ## sample estimates: ## mean in group A mean in group B ## 43.825 60.875 och för formen med vektorer # Två separata vektorer ## Filtrera ut data där behandling är A Vikt_A &lt;- dat_berry$Vikt[dat_berry$Behandling == &quot;A&quot;] ## Filtrera ut data där behandling är B Vikt_B &lt;- dat_berry$Vikt[dat_berry$Behandling == &quot;B&quot;] t.test(Vikt_A, Vikt_B, var.equal = T) ## ## Two Sample t-test ## ## data: Vikt_A and Vikt_B ## t = -5.3157, df = 6, p-value = 0.001803 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -24.898417 -9.201583 ## sample estimates: ## mean of x mean of y ## 43.825 60.875 Argumentet var.equal = T används för att beräkna testet där gruppernas varianser antas vara lika. Grundinställningen är testet där varianser inte antas vara lika, så t.test(Vikt ~ Behandling, data = dat) ger ett lite annat resultat. Uppgift 5.6 (Ej lika varianser) Vilka resultatvärden ändras i utskriften om man sätter var.equal = F? Testet ger ett p-värde på \\(0.0018\\), vilket leder till att nollhypotesen förkastas på enprocentsnivån. Detta tyder på att det finns en viktskillnad mellan behandlingarna. Utskriften ger också ett 95-procentigt konfidensintervall på \\((-24.898, -9.202)\\). Tolkningen är att skillnaden mellan populationsmedelvärden ligger i intervallet med 95 procents konfidens. Notera att värdet noll inte ligger i intervallet. Uppgift 5.7 (Ensidigt test) Gör lämpliga tillägg till kodstycket nedan för att göra ett ensidigt test (om B ger högre vikt än A). t.test(Vikt ~ Behandling, data = dat_berry, var.equal = T, alternative = &quot;two.sided&quot;) Om man har fler än två grupper kan man vilja göra parvisa t-test - alltså ett t-test för varje par av grupper. Ett exempel på funktionen pairwise.t.test() ges nedan. Funktionen bygger på att datan är i lång form, med en kolumn som anger det numeriska utfallet och en kolumn som anger behandlingen. pairwise.t.test(dat_berry$Vikt, dat_berry$Behandling, p.adjust.method = &quot;none&quot;, pool.sd = F) ## ## Pairwise comparisons using t tests with non-pooled SD ## ## data: dat_berry$Vikt and dat_berry$Behandling ## ## A ## B 0.002 ## ## P value adjustment method: none Matchade observationer kan också kallas parade (eng. paired) så se upp med terminologin. Funktionen pairwise.t.test() för parvisa jämförelse mellan behandlingar, men testerna är t-test för oberoende stickprov. Uppgift 5.8 (Ekorrdata) I en undersökning av hur den europeiska ekorren (Sciurus vulgaris) förändras i vikt under övervintring mäts 7 slumpmässigt valda ekorrar före och 5 slumpmässigt valda ekorrar efter övervintring. Datan finns tillgänglig i excelfilen Uppgiftsdata.xlsx på canvassidan, i fliken Ekorrar. Ladda ner filen och fyll i stycket nedan för att importera datan. dat_sq &lt;- read_excel(&quot;___&quot;, sheet = &quot;Ekorrar&quot;) dat_sq # dat_sq &lt;- read_csv(&quot;https://raw.githubusercontent.com/adamflr/ST0060/main/Data/Uppgiftsdata/Uppgift_Ekorrar.csv&quot;) # Alternativ lösning Uppgift 5.9 (Ekorrgraf) Fyll i följande stycke för en lämplig graf för att jämföra mätningarna före och mätningarna efter. ggplot(dat_sq, aes(x = ___, y = ___)) + ___() Finns det någon synlig viktskillnad? Uppgift 5.10 (Ekorrtest) Genomför ett t-test för två oberoende stickprov på ekorrdatan genom att fylla i kodstycket nedan. Formulera tydliga hypoteser och dra en klar slutsats. t.test(___ ~ ___, data = dat_sq, var.equal = ___) Uppgift 5.11 (Ekorrdesign) Ett problem med att mäta skilda individer före och efter övervintring är att det kan finnas en stor skillnad i vikt mellan individuella ekorrar. Kan man lägga upp försöket på ett sätt som reducerar det problemet? 5.3 z-test och konfidensintervall för två proportioner Om man vill jämföra två proportioner kan man använda z-testet för två stickprov. Säg till exempel att man har två sorter av någon planta och vill se hur stor proportion som är infekterad av bladmögel. I den ena gruppen (sort A) är 17 av 50 infektera och i den andra (sort B) är 26 av 60 infekterade. Testets hypoteser är i det tvåsidiga fallet H0: proportion A är lika med proportion B H1: proportion A är skild från proportion B I R kan testet genomföras med prop.test-funktionen. Funktionens första argument är antalen infekterade, som en vektor med två värden, och dess andra argument är totalerna. Likt testet med ett stickprov finns en möjlighet att göra en kontinuitetskorrektion med correct-argumentet. För att få samma resultat som räkning för hand anger vi att korrektion inte ska göras med correct = F. prop.test(c(17, 26), c(50, 60), correct = F) ## ## 2-sample test for equality of proportions without continuity correction ## ## data: c(17, 26) out of c(50, 60) ## X-squared = 0.9978, df = 1, p-value = 0.3178 ## alternative hypothesis: two.sided ## 95 percent confidence interval: ## -0.27488771 0.08822105 ## sample estimates: ## prop 1 prop 2 ## 0.3400000 0.4333333 Notera att funktionen inte ger ett z-värde utan ett \\(\\chi^2\\)-värde (utskrivet X-squared). Det beror på att funktionen beräknar z-testet som ett likvärdigt \\(\\chi^2\\)-test. Det z-värde man får om man genomför testet som ett z-test är detsamma som roten ur utskriftens \\(\\chi^2\\)-värde. Testet ger ett högt p-värde på 0.32 vilket innebär att nollhypotesen inte förkastas: det finns ingen signifikant skillnad i infektionsproportion. Funktionen prop.test() ger också en utskrift av konfidensintervallet. Tolkning är att skillnaden i proportioner mellan populationerna ligger i intervallet med 95 procents konfidens. Notera att nollan ingår i intervallet. Uppgift 5.12 (Lämplig approximation?) Z-test bygger på en normalapproximation. Som tumregel för när approximationen är rimlig används ofta att n * p * (1 - p) ska vara större än 10 för bägge stickproven. Gör beräkningen för datan i exemplet (17 av 50 respektive 26 av 60). Uppgift 5.13 (Burfågel) Det finns en förvånansvärt stor mängd studier på kopplingen mellan innehav av burfågel och lungcancer. En sådan studie (Kohlmeier et al 1992) ger följande antal för burfågelägande och lungcancer. dat_bird &lt;- data.frame(Burfågel = c(&quot;Burfågel&quot;, &quot;Ej_burfågel&quot;), Lungcancer = c(98, 141), Ej_lungcancer = c(101, 328)) dat_bird ## Burfågel Lungcancer Ej_lungcancer ## 1 Burfågel 98 101 ## 2 Ej_burfågel 141 328 Datan tyder på att människor med burfågel har en förhöjd risk att drabbas av lungcancer. Genomför ett z-test för att se om andelen burfågelägare än densamma i de två patientgrupperna. prop.test(x = c(___, ___), n = c(___, ___), correct = F) Genomför ett z-test för att se om andelen cancerdrabbade är densamma i de två burfågelsgrupperna. Hur förhåller sig p-värdena i de bägge testerna till varandra? prop.test(x = c(___, ___), n = c(___, ___), correct = F) Finns det någon industri som kan ha ett intresse av att finansiera forskning som söker alternativa riskfaktorer för lungcancer? 5.4 Chi-två-test för korstabeller Data med två kategoriska variabler kan presenteras med en korstabell. Ta som (ett något deppigt) exempel överlevnadsdata från Titanic. Datan finns tillgänglig i R som Titanic. I detta fall ges överlevnad filtrerad på vuxna män, uppdelat efter klass. dat_titanic &lt;- Titanic %&gt;% data.frame() %&gt;% filter(Sex == &quot;Male&quot;, Age == &quot;Adult&quot;) dat_titanic ## Class Sex Age Survived Freq ## 1 1st Male Adult No 118 ## 2 2nd Male Adult No 154 ## 3 3rd Male Adult No 387 ## 4 Crew Male Adult No 670 ## 5 1st Male Adult Yes 57 ## 6 2nd Male Adult Yes 14 ## 7 3rd Male Adult Yes 75 ## 8 Crew Male Adult Yes 192 En korstabell kan konstrueras med pivot_wider. dat_wide &lt;- dat_titanic %&gt;% pivot_wider(names_from = Survived, values_from = Freq) dat_wide ## # A tibble: 4 × 5 ## Class Sex Age No Yes ## &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1st Male Adult 118 57 ## 2 2nd Male Adult 154 14 ## 3 3rd Male Adult 387 75 ## 4 Crew Male Adult 670 192 Datan tyder på att överlevnad är beroende av klass. Datan kan illustreras med uppdelade staplar ggplot(dat_titanic, aes(Class, Freq, fill = Survived)) + geom_col(position = position_fill(), color = &quot;black&quot;) + scale_fill_manual(values = c(&quot;red4&quot;, &quot;white&quot;)) Argumentet position i geom_bar används för att skapa proportionella staplar. Ett chi-två-test på en korstabell har nollhypotesen att det inte finns något samband mellan variabeln för rader och variabeln för kolumner. Antal frihetsgrader ges av antal rader minus ett gånger antal kolumner minus ett. Testet kan enkelt göras med chisq.test(). Som ingångsvärde kan man plocka ut kolumnerna med numeriska värden genom hakparenteser. dat_wide[, 4:5] # De två numeriska kolumnerna ## # A tibble: 4 × 2 ## No Yes ## &lt;dbl&gt; &lt;dbl&gt; ## 1 118 57 ## 2 154 14 ## 3 387 75 ## 4 670 192 chisq.test(dat_wide[, 4:5]) ## ## Pearson&#39;s Chi-squared test ## ## data: dat_wide[, 4:5] ## X-squared = 37.988, df = 3, p-value = 2.843e-08 Utskriften ger teststorheten, antal frihetsgrader, och p-värdet. I det här fallet är p-värdet mycket litet och slutsatsen blir att nollhypotesen förkastas - det finns ett samband mellan klass och överlevnad. Antalet frihetsgrader ges av antalet rader minus ett gånger antalet kolumner minus ett (här (4-1) * (2-1) = 3). Chi-två-testet är ett asymptotiskt test - dess egenskaper är beroende av stora stickprov. Som gräns för storleken används ofta att samtliga förväntade antal ska vara större än 5. Funktionen ger en varning om förväntade värden är små. En möjlig lösning i sådana fall är att slå ihop klasser. test_result &lt;- chisq.test(dat_wide[, 4:5]) test_result$expected # Samtliga förväntade värden över 5 ## No Yes ## [1,] 139.5171 35.48290 ## [2,] 133.9364 34.06359 ## [3,] 368.3251 93.67487 ## [4,] 687.2214 174.77864 Om detta krav inte är uppfyllt skriver funktionen ut en varning. Uppgift 5.14 (Ogiltig approximation) Ta följande lilla korstabell och kör chisq.test() för att få ett felmeddelande. dat &lt;- matrix(c(4,2,5,1), 2) dat ## [,1] [,2] ## [1,] 4 5 ## [2,] 2 1 Uppgift 5.15 (Burfågeln återvänder) En svensk studie på koppling mellan burfågel och lungcancer (Modigh et al, 1996) ger följande antal (för män). dat_bird_swe &lt;- data.frame(Burfågel = c(&quot;Burfågel&quot;, &quot;Ej_burfågel&quot;), Lungcancer = c(108, 144), Ej_lungcancer = c(171, 256)) dat_bird_swe ## Burfågel Lungcancer Ej_lungcancer ## 1 Burfågel 108 171 ## 2 Ej_burfågel 144 256 Genomför ett chi-två-test för att se om andelen cancerdrabbade än densamma i de två burfågelsgrupperna. Formulera tydliga hypoteser. För att få utfall som stämmer med en handräkning kan man sätta correct = F. dat_bird_swe[, c(2,3)] chisq.test(___, correct = F) Chi-två-testet kan tillämpas på korstabeller med godtyckligt antal rader och kolumner. Uppgift 5.16 (Po-ta-toes-import) I en undersökning på potatis används fyra behandlingar (a1b1, a1b2, a2b1 och a2b2). 125 potatisar från varje behandling sorteras in i fyra olika färggrupper (A, B, C och D). Datan finns i fliken Po-ta-toes i excelfilen Uppgiftsdata.xlsx på canvassidan. Ladda ned filen och läs in datan genom att fylla i stycket nedan. dat_pot &lt;- read_excel(&quot;___&quot;, sheet = &quot;Po-ta-toes&quot;) dat_pot # dat_pot &lt;- read_csv(&quot;https://raw.githubusercontent.com/adamflr/ST0060/main/Data/Uppgiftsdata/Uppgift_Po-ta-toes.csv&quot;) Uppgift 5.17 (Po-ta-toes-graf) För att göra en graf kan man pivotera datan till lång form. dat_long &lt;- dat_pot %&gt;% pivot_longer(-Färg, values_to = &quot;Antal&quot;, names_to = &quot;Behandling&quot;) dat_long Skapa ett stapeldiagram med uppdelade staplar genom att fylla i kodstycket nedan. Behandling ska vara på x-axeln och ifylld färg ska ges av Färg. ggplot(dat_long, aes(x = ___, y = ___, fill = ___)) + geom_col(col = &quot;black&quot;, width = 0.6) + scale_fill_brewer(palette = &quot;Reds&quot;) Finns det några synbara skillnader mellan behandlingar? Uppgift 5.18 (Po-ta-toes-test) Beräkna ett chi-två-test på potatisdatan för att se om det finns färgskillnader mellan behandlingarna. Formulera tydliga hypoteser och ge ett tydligt svar. dat_pot[,-1] chisq.test(___) Uppgift 5.19 (Hemmasegrar över årtionden) Vi vill undersöka om andelen hemmasegrar i herrallsvenskan förändrats över tid. Vi importerar data över matchresultat sedan 1920-talet. dat_alls &lt;- read_csv(&quot;https://raw.githubusercontent.com/adamflr/ST0060/main/Data/Allsvenskan%2C%20herrar%2C%201924-2020.csv&quot;) dat_alls ## # A tibble: 15,236 × 9 ## Hemmalag Bortalag Hemmamål Bortamål Publik Domare Arena Datum Säsong ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;date&gt; &lt;chr&gt; ## 1 Örgryte Hammarby 5 1 4000 Carl … &lt;NA&gt; 1924-08-03 1924_… ## 2 IFK Norrköp… Landskr… 0 1 1500 Ivar … &lt;NA&gt; 1924-08-03 1924_… ## 3 IFK Malmö IFK Göt… 1 1 3276 Johan… &lt;NA&gt; 1924-08-03 1924_… ## 4 Helsingborg Gais 1 2 3000 Carl … &lt;NA&gt; 1924-08-03 1924_… ## 5 Eskilstuna Sleipner 1 3 700 Oscar… &lt;NA&gt; 1924-08-03 1924_… ## 6 AIK Västerå… 5 1 2000 Arne … &lt;NA&gt; 1924-08-03 1924_… ## 7 IFK Göteborg Gais 1 3 3600 Sigfr… &lt;NA&gt; 1924-08-08 1924_… ## 8 Västerås IK Eskilst… 0 1 600 Berti… &lt;NA&gt; 1924-08-10 1924_… ## 9 Sleipner Örgryte 0 1 2280 Ernfr… &lt;NA&gt; 1924-08-10 1924_… ## 10 Landskrona IFK Göt… 0 4 1000 Gusta… &lt;NA&gt; 1924-08-10 1924_… ## # ℹ 15,226 more rows Följande kod skapar en variabel för årtionde, en variabel för hemmaseger, och räknar ut antalen hemmasegrar per årtionde. Detaljer är oviktiga här. library(lubridate) dat_hemma &lt;- dat_alls %&gt;% mutate(År = year(Datum), Årtionde = floor(År / 10) * 10, Hemmaseger = ifelse(Hemmamål &gt; Bortamål, &quot;Hemmaseger&quot;, &quot;Ej_hemmaseger&quot;)) %&gt;% count(Årtionde, Hemmaseger) %&gt;% pivot_wider(values_from = n, names_from = Hemmaseger) %&gt;% mutate(Total = Hemmaseger + Ej_hemmaseger, Proportion = Hemmaseger / (Hemmaseger + Ej_hemmaseger)) Fyll i koden nedan för att skapa en tidsserie (en linjegraf med tid på x-axeln) för andelen Proportion. ggplot(dat_hemma, aes(x = ___, y = ___)) + ___() Uppgift 5.20 (1920-talet mot 1960-talet) Använd ett z-test för att se om proportionen hemmasegrar under 1920-talet (371 av 738) är skild från 1960-talet (590 av 1320). prop.test(c(___, ___), n = c(___, ___), correct = F) 5.5 Bonus. Bilder i R Det finns en stor mängd paket som kan hantera bilder. Låt oss ta en titt på ett av dem - magick - vilket bygger på en koppling till ImageMagick (https://imagemagick.org/). # install.packages(&quot;magick&quot;) library(magick) Med funktionen image_read() kan man läsa in en bild, antingen från lokal hårddisk eller från en internetaddress. Här hämtar vi en bild av Nils Dardels Den döende dandyn (1918) från Wikipedia. url &lt;- &quot;https://upload.wikimedia.org/wikipedia/commons/thumb/2/2a/Nils_Dardel_D%C3%B6ende_dandyn.jpg/1920px-Nils_Dardel_D%C3%B6ende_dandyn.jpg&quot; img &lt;- image_read(url) img Uppgift 5.21 (Någon annan bild) Hitta någon annan bild online, vad som helst. Gör lämplig ändring i stycken ovan för att läsa in bilden med image_read(). Låt oss börja med att ändra storleken med image_resize(). Följande ger en bild där den kortaste av höjd och bredd är 500 pixlar. img &lt;- img %&gt;% image_resize(&quot;500&quot;) img Uppgift 5.22 (Storlek) Vad kan vara koden för att sätta en bild till halva storleken, alltså 50% av den ursprungliga bilden? Man kan också manipulera egenskaper som kontrast, mättnad och färgton. img %&gt;% image_modulate(saturation = 50) %&gt;% image_modulate(hue = 50) För mer information av tillgängliga funktioner, titta på paketets hjälpsida med ?magick och introduktionen på https://docs.ropensci.org/magick/articles/intro.html. En enkel vetenskaplig tillämpning av bildanalys kan baseras på de relativa andelarna av olika färger. Det kan till exempel användas för att beräkna skadegrad på löv (som efter färgning kan ha specifika färger för skadade delar) eller storlek på trädkronor. Funktionen image_quantize() kan minska antalet färger i en bild till ett mer hanterbart antal. img %&gt;% image_quantize(max = 10) Uppgift 5.23 (Antal färger) Med 50 enskilda färger blir Den döende dandyn något mattare, men karaktärernas klädsel har klara färger. Hur få måste det totala antalet färger bli innan du ser en klar försämring av bilden? Funktionen image_data() kan användas för att ta ut färgvärdet för varje pixel. Därefter kan man enkelt beräkna andelen för olika färger. Följande stycke förenklar bilden till tio färger, extraherar datan och beräknar antalet pixlar med respektive färg. Den exakta koden är inte så viktig här och kan läsas kursivt. img &lt;- img %&gt;% image_quantize(max = 10) info &lt;- img %&gt;% image_info() pixel_values &lt;- img %&gt;% image_data() %&gt;% as.vector() dat_pix &lt;- expand_grid(y = info$height:1, x = 1:info$width, color = c(&quot;R&quot;, &quot;G&quot;, &quot;B&quot;)) %&gt;% mutate(value = pixel_values) %&gt;% pivot_wider(values_from = value, names_from = color) %&gt;% mutate(hex = paste0(&quot;#&quot;, R, G, B)) dat_pix Den konstruerade datan innehåller koordinater med x och y samt färgvärden i tre färgband och en hexkod som anger färgen. Härifrån kan vi göra en grafversion av bilden med geom_raster(). ggplot(dat_pix, aes(x, y)) + geom_raster(fill = dat_pix$hex) Notera att vi sätter fill i geom-funktionen, eftersom målet är att sätta färgen till den som anges i kolumnen hex. Uppgift 5.24 (Färg som aesthetic) Vad händer om man sätter fill = hex inom aes()-funktionen istället? ggplot(dat_pix, aes(x, y, fill = ___)) + geom_raster() Funktionen scale_fill_manual() kan styra färgvalet i det fallet. ggplot(dat_pix, aes(x, y, fill = ___)) + geom_raster() + scale_fill_manual(values = c(&#39;white&#39;, &#39;aliceblue&#39;, &#39;antiquewhite&#39;, &#39;antiquewhite1&#39;, &#39;antiquewhite2&#39;, &#39;antiquewhite3&#39;, &#39;antiquewhite4&#39;, &#39;aquamarine&#39;, &#39;aquamarine1&#39;, &#39;aquamarine2&#39;)) + theme_void() Tillgängliga färger kan tas fram med colors(). Slutligen kan vi nu göra en enkel bildanalys genom att räkna antal eller andel pixlar med en viss färg. dat_pix_count &lt;- dat_pix %&gt;% count(hex) %&gt;% mutate(hex = reorder(hex, n)) ggplot(dat_pix_count, (aes(n, hex))) + geom_col(fill = dat_pix_count$hex) Uppgift 5.25 (Avslutande proportionstest) Låt oss ta ett mindre stickprov från bilden. Funktionen set.seed() sätter ett startvärde för slumtalsgeneratorn, vilket är bra om man vill reproducera ett visst utfall. set.seed(1573) dat_sample &lt;- dat_pix %&gt;% slice_sample(n = 100) dat_sample %&gt;% count(hex) ggplot(dat_sample, aes(x, y)) + geom_point(color = dat_sample$hex, size = 8) I stickprovet är 62 av 100 pixlar en mörkblå färg. Genomför ett test med prop.test() för att se om andelen i populationen (som i detta fall är hela tavlan) är skild från 0.7. Jämför med proportionen i den större datamängden dat_pix. "],["variansanalys.html", "6 Variansanalys 6.1 Repetition av datorövning 5 6.2 Allmänt 6.3 Variansanalys. En faktor 6.4 Variansanalys. En faktor med block 6.5 Variansanalys. Två faktorer med block 6.6 Modellantaganden och residualer 6.7 Bonus. Statistik för ekologi", " 6 Variansanalys Datorövning 6 handlar om variansanalys. Efter övningen ska vi kunna beräkna en anova-modell i R, ta fram och tolka en anova-tabell, göra lämpliga tester av modellantaganden, göra parvisa jämförelser mellan behandlingar. 6.1 Repetition av datorövning 5 När man startar en ny R-session bör man ladda de paket man vet kommer behövas med library(). Om paket inte finns installerade måste man först köra install.packages(). # install.packages(&quot;tidyverse&quot;) library(tidyverse) I datorövning 6 tittade vi på tester för två stickprov. För normalfördelad data kan man då använda ett t-test för två stickprov (för två matchade stickprov eller för två oberoende stickprov beroende på situation) för data med utfall i två eller flera kategorier kan man använda ett z-test för två stickprov eller ett chi-två-test för en korstabell. Ett t-test för matchade stickprov används när de två grupper man jämför är matchade så att en observation i den ena gruppen är kopplad till en observation i den andra gruppen. Ett t-test för oberoende stickprov används om man inte har matchade stickprov, det vill säga då det inte finns någon koppling mellan behandlinggrupperna. Ta som exempel följande fiskefångster för sex båtar från två regioner och två fiskearter. dat_fish &lt;- data.frame(Vessel = c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;, &quot;E&quot;, &quot;F&quot;), Region = c(&quot;N&quot;, &quot;N&quot;, &quot;N&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;), Species1 = c(115.7, 98.5, 82.1, 89.2, 95.7, 99.4), Species2 = c(122.8, 105.3, 99.8, 106.8, 114, 102.7)) Vi vill här testa om det finns en skillnad mellan arter och om det finns skillnad mellan regioner. dat_long &lt;- dat_fish %&gt;% pivot_longer(-c(Vessel, Region), names_to = &quot;Species&quot;, values_to = &quot;Catch&quot;) ggplot(dat_long, aes(Species, Catch, group = Vessel)) + geom_point() + geom_line() + labs(title = &quot;Fångster av två arter&quot;, subtitle = &quot;Linje sammanbinder observationer från samma fartyg&quot;) ggplot(dat_fish, aes(Species1, Region)) + geom_point() + labs(title = &quot;Fångster i två regioner&quot;) För arterna har vi matchad data - varje observation av den ena arten är kopplad till en observation från den andra arten eftersom den kommer från samma båt - och vi kan testa om medelfångsterna av de två arterna är lika med ett t-test. Hypoteserna ges av H0: populationsmedelvärdet av fångster för art 1 är lika med det för art 2, H1: populationsmedelvärdena är ej lika. I R kan ett test för matchad data genomföras med t.test() och argumentet paired, eller genom att beräkna differensen per båt och göra ett t-test för ett stickprov. t.test(dat_fish$Species1, dat_fish$Species2, paired = T) ## ## Paired t-test ## ## data: dat_fish$Species1 and dat_fish$Species2 ## t = -4.2613, df = 5, p-value = 0.008005 ## alternative hypothesis: true mean difference is not equal to 0 ## 95 percent confidence interval: ## -18.918238 -4.681762 ## sample estimates: ## mean difference ## -11.8 # Alternativt # t.test(dat_fish$Species1 - dat_fish$Species2) Det beräknade p-värdet ställs mot en signifikansnivå, vanligen fem procent, och om p-värdet är under signifikansnivån förkastar vi nollhypotesen. I det här exemplet tyder på värdet på att nollhypotesen inte stämmer - en art är vanligare än den andra. För att jämföra regioner kan vi göra ett t-test för två oberoende stickprov. Hypoteser ges av H0: populationsmedelvärdet av fångster är lika mellan regioner, H1: populationsmedelvärdet av fångster är ej lika mellan regioner. Testet kan genomföras med t.test() och kan antingen göras med ett antagande om lika varianser (vilket motsvarar det som görs för hand under kursen) eller utan det antagandet. Variabler kan anges med en formel som Species1 ~ Group, vilket vi kan tänka på som värden för art 1 uppdelat efter grupp. t.test(Species1 ~ Region, data = dat_fish, var.equal = T) ## ## Two Sample t-test ## ## data: Species1 by Region ## t = 0.39416, df = 4, p-value = 0.7136 ## alternative hypothesis: true difference in means between group N and group S is not equal to 0 ## 95 percent confidence interval: ## -24.17586 32.17586 ## sample estimates: ## mean in group N mean in group S ## 98.76667 94.76667 Ett högt p-värde tyder på att det inte finns någon skillnad i fångst mellan regioner. För data där utfallen är två eller flera kategorier kan ett chi-två-test testa om det finns något samband mellan två variabler. Följande data anger vilka partier ett urval väljare från tre kommuner planerar rösta på i nästa riksdagsval. dat_parti &lt;- data.frame(Kommun = c(&quot;Malmö&quot;, &quot;Lund&quot;, &quot;Kävlinge&quot;), S = c(54, 102, 40), M = c(30, 98, 53), MP = c(7, 50, 5)) dat_parti ## Kommun S M MP ## 1 Malmö 54 30 7 ## 2 Lund 102 98 50 ## 3 Kävlinge 40 53 5 För att testa om det finns något samband mellan kommun och parti sätter vi upp hypoteserna H0: det finns inget samband mellan parti och kommun (ingen skillnad mellan kommuner), H1: det finns något samband mellan parti och kommun. Detta kan testas med ett chi-två-test med funktionen chisq.test(). Som argument ges den numeriska delen av korstabellen - vi tar alltså bort den första kolumnen för kommun. chisq.test(dat_parti[, -1]) ## ## Pearson&#39;s Chi-squared test ## ## data: dat_parti[, -1] ## X-squared = 25.659, df = 4, p-value = 3.706e-05 Det låga p-värdet på 0.000037 ger att vi förkastar nollhypotesen och drar slutsatsen att det finns ett samband mellan kommun och parti. 6.2 Allmänt Variansanalys (eller anova-modellen) är en statistisk modell där medelvärdet varierar beroende på en behandling och ett normalfördelat slumpfel. Från en anova-modell kan man beräkna ett F-test, som testar om det finns någon övergripande gruppskillnad, och post-hoc-test, som jämför specifika grupper med varandra. Den specifika modellen beror på försöksupplägget. Här ges exempel på variansanalys med en faktor, en faktor med block, och två faktorer. 6.3 Variansanalys. En faktor Vid variansanalys med en faktor har man observationer av en kontinuerlig utfallsvariabel från två eller flera behandlingsgrupper. Som exempel används en datamängd på ett odlingsförsök med tre behandlingar (varav en kontroll). Exemplet finns tillgängligt i R som PlantGrowth. PlantGrowth ## weight group ## 1 4.17 ctrl ## 2 5.58 ctrl ## 3 5.18 ctrl ## 4 6.11 ctrl ## 5 4.50 ctrl ## 6 4.61 ctrl ## 7 5.17 ctrl ## 8 4.53 ctrl ## 9 5.33 ctrl ## 10 5.14 ctrl ## 11 4.81 trt1 ## 12 4.17 trt1 ## 13 4.41 trt1 ## 14 3.59 trt1 ## 15 5.87 trt1 ## 16 3.83 trt1 ## 17 6.03 trt1 ## 18 4.89 trt1 ## 19 4.32 trt1 ## 20 4.69 trt1 ## 21 6.31 trt2 ## 22 5.12 trt2 ## 23 5.54 trt2 ## 24 5.50 trt2 ## 25 5.37 trt2 ## 26 5.29 trt2 ## 27 4.92 trt2 ## 28 6.15 trt2 ## 29 5.80 trt2 ## 30 5.26 trt2 Datan har 30 observationer av vikt weight och varje observation tillhör någon specifik behandling group. Datan kan illustreras med ett spridningsdiagram. ggplot(PlantGrowth, aes(group, weight)) + geom_point() Behandling 1 verkar vara något lägre än kontrollen medan behandling 2 verkar vara något högre. En anova-modell kan i R skattas med funktionen lm() (för linjär modell). Från modellobjektet kan man sedan plocka fram en anova-tabell (som bland annat anger utfallet av F-testet) och genomföra parvisa jämförelser genom emmeans. mod &lt;- lm(weight ~ group, data = PlantGrowth) Modellen anges som en formel weight ~ group, vilket kan utläsas vikt beroende på behandlingsgrupp. Därefter anges data med argumentet data. För anova-tabellen finns flera alternativ. Här används funktionen Anova() från paketet car. library(car) Anova(mod) ## Anova Table (Type II tests) ## ## Response: weight ## Sum Sq Df F value Pr(&gt;F) ## group 3.7663 2 4.8461 0.01591 * ## Residuals 10.4921 27 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Anova-tabellen ger kvadratsummor (Sum Sq), frihetsgrader (Df) och utfallet av ett F-test. Testets hypoteser ges av H0: alla behandlingsgrupper har samma medelvärde H1: alla behandlingsgrupper har inte samma medelvärde Det låga p-värdet tyder på att nollhypotesen bör förkastas, vilket alltså pekar på att det finns någon eller några skillnader i medelvärde. Uppgift 6.1 (Anova för hand) Anovatabell från Anova() ger kvadratsummor och frihetsgrader. Använd den informationen för att, för hand, beräkna medelkvadratsummor och F-värdet. Uppgift 6.2 (Tabellvärde för F-fördelningen) Anova-tabellen ger ett p-värde från vilket vi kan dra en direkt slutsats. Om man istället löser uppgiften för hand ställer man det beräknade F-värdet mot ett kritiskt värde från en tabell över F-fördelningen. Se efter om man kan hitta ett lämpligt tabellvärde för det aktuella testet (med 2 och 27 frihetsgrader). Det är möjligt att det inte finns en rad för 27 i en vanlig F-fördelningstabell, använd isåfall värdet på närmast övre rad (t.ex. 26 eller 25). I R kan kvantiler för F-fördelningen tas fram med qf(), t.ex. qf(0.95, 2, 27) ## [1] 3.354131 En naturlig följdfråga är vilka behandlingsgrupper som skiljer sig åt. För att besvara det krävs parvisa jämförelser där behandlingarna jämförs två och två. Parvisa jämförelse kan göras med paketet emmeans och funktionen med samma namn. Funktionen tar modellobjektet som första argument och en formel för jämförelsetyp som andra argument (här pairwise ~ group, en parvis jämförelse mellan nivåer i group). # install.packages(&quot;emmeans&quot;) library(emmeans) emmeans(mod, pairwise ~ group) ## $emmeans ## group emmean SE df lower.CL upper.CL ## ctrl 5.03 0.197 27 4.63 5.44 ## trt1 4.66 0.197 27 4.26 5.07 ## trt2 5.53 0.197 27 5.12 5.93 ## ## Confidence level used: 0.95 ## ## $contrasts ## contrast estimate SE df t.ratio p.value ## ctrl - trt1 0.371 0.279 27 1.331 0.3909 ## ctrl - trt2 -0.494 0.279 27 -1.772 0.1980 ## trt1 - trt2 -0.865 0.279 27 -3.103 0.0120 ## ## P value adjustment: tukey method for comparing a family of 3 estimates I den nedre tabellen med jämförelser ges alla parvisa jämförelser. Nollhypotesen är att de två grupper som jämförs har samma medelvärde - ett lågt p-värde tyder alltså på att de två grupperna är signifikant skilda. Notera också att p-värden justeras med tukey-metoden, även känt som Tukeys HSD. Om man istället vill använda Fishers LSD kan man styra justeringen med argumentet adjust. emmeans(mod, pairwise ~ group, adjust = &quot;none&quot;) ## $emmeans ## group emmean SE df lower.CL upper.CL ## ctrl 5.03 0.197 27 4.63 5.44 ## trt1 4.66 0.197 27 4.26 5.07 ## trt2 5.53 0.197 27 5.12 5.93 ## ## Confidence level used: 0.95 ## ## $contrasts ## contrast estimate SE df t.ratio p.value ## ctrl - trt1 0.371 0.279 27 1.331 0.1944 ## ctrl - trt2 -0.494 0.279 27 -1.772 0.0877 ## trt1 - trt2 -0.865 0.279 27 -3.103 0.0045 Parvisa jämförelser presenteras ofta med signifikansbokstäver (en. compact letter display, cld). Dessa kan plockas fram med multcomp-paketet och funktionen cld(). em &lt;- emmeans(mod, pairwise ~ group) library(multcomp) cld(em, Letters = letters) ## group emmean SE df lower.CL upper.CL .group ## trt1 4.66 0.197 27 4.26 5.07 a ## ctrl 5.03 0.197 27 4.63 5.44 ab ## trt2 5.53 0.197 27 5.12 5.93 b ## ## Confidence level used: 0.95 ## P value adjustment: tukey method for comparing a family of 3 estimates ## significance level used: alpha = 0.05 ## NOTE: If two or more means share the same grouping symbol, ## then we cannot show them to be different. ## But we also did not show them to be the same. Tolkning av grupperingen till höger är att grupper som delar en bokstav inte är signifikant skilda. I det här fallet är den lägsta nivån skild från de två högsta. I övrigt finns inga signifikanta skillnader. Jämför gärna med p-värdena från tabellen med parvisa jämförelser. Man bör se att parvisa jämförelser med ett p-värde under fem procent motsvaras av att de behandlingarna inte delar någon bokstav i bokstavstabellen. Uppgift 6.3 (Anova med två behandlingar) Följande kod skapar en datamängd med två behandlingar. dat_two &lt;- PlantGrowth %&gt;% filter(group %in% c(&quot;trt1&quot;, &quot;trt2&quot;)) Använd den datan för att göra ett t-test för två oberoende stickprov med lika varians, ett t-test för två oberoende stickprov utan antagande om lika varians, och ett F-test (ofullständig exempelkod nedan). Vad kan sägas om p-värdena från de tre testen? t.test(___ ~ group, data = dat_two, var.equal = T) t.test(weight ~ ___, data = dat_two, var.equal = F) mod &lt;- lm(weight ~ group, data = ___) Anova(mod) Uppgift 6.4 (Mass-signifikans) Anledning till att vi justerar p-värden är att man vid varje test har en sannolikhet att förkasta. Om man gör ett stort antal tester är man nästan garanterad att få något (falskt) signifikant resultat. Justering höjer p-värdena för att minska den risken. Följande kod simulerar data med 5 grupper och producerar de parvisa jämförelserna. n_groups &lt;- 5 dat_sim &lt;- expand_grid(obs = 1:10, group = letters[1:n_groups]) %&gt;% mutate(y = rnorm(n())) mod &lt;- lm(y ~ group, dat_sim) emmeans(mod, pairwise ~ group, adjust = &quot;none&quot;) ## $emmeans ## group emmean SE df lower.CL upper.CL ## a -0.3222 0.241 45 -0.807 0.163 ## b -0.1861 0.241 45 -0.671 0.299 ## c 0.3512 0.241 45 -0.134 0.836 ## d 0.0255 0.241 45 -0.459 0.511 ## e 0.1911 0.241 45 -0.294 0.676 ## ## Confidence level used: 0.95 ## ## $contrasts ## contrast estimate SE df t.ratio p.value ## a - b -0.136 0.341 45 -0.400 0.6913 ## a - c -0.673 0.341 45 -1.978 0.0541 ## a - d -0.348 0.341 45 -1.021 0.3126 ## a - e -0.513 0.341 45 -1.507 0.1387 ## b - c -0.537 0.341 45 -1.578 0.1216 ## b - d -0.212 0.341 45 -0.622 0.5374 ## b - e -0.377 0.341 45 -1.108 0.2739 ## c - d 0.326 0.341 45 0.956 0.3440 ## c - e 0.160 0.341 45 0.470 0.6405 ## d - e -0.166 0.341 45 -0.486 0.6292 Kör koden tio gånger. Hur många gånger av de tio ger de parvisa jämförelserna någon signifikant skillnad (det vill säga något p-värde under 0.05)? En passande xkcd-serie: https://xkcd.com/882/ Uppgift 6.5 (Äppelinfektionsimport) En studie har givit ett mått på infektion hos äppelträd. Fyra sorter jämförs med tre replikat per sort. Data finns i fliken Äppelangrepp i excelfilen Uppgiftsdata.xslx på canvassidan. Fyll i kodstycket nedan för att importera datan. Uppgift 6.6 (Äppelinfektionsgraf) Fyll i kodstycket nedan för att skapa en graf av äppeldatan. ggplot(___, aes(x = ___, y = ___)) + geom_point() Uppgift 6.7 (Äppelinfektionsmodell) Fyll i kodstycket nedan för att skatta en anovamodell och ta fram anovatabellen. Vad är F-testets noll- och alternativhypotes? Vilken slutsats kan man dra från testet? mod &lt;- lm(___ ~ ___, data = dat_apple) Anova(mod) 6.4 Variansanalys. En faktor med block I en blockdesign delas försöksobjekten (de enheter man ger en behandling och sedan mäter, t.ex. en försöksruta eller en planta) in i grupper av lika objekt (ett block). Sedan ger man enheterna inom blocket varsin behandling. Blockförsök är ofta balanserade, så att varje behandling förekommer en gång i varje block. Som exempel på ett blockförsök kan vi titta på datan oats från paketet MASS. Datan kommer från ett agrikulturellt försök och blockdesignen sker genom att man delar in ett fält i flera delar (blocken) och sätter varje behandling i varje block. Datan har två faktorer (kväve N och sort V), men låt oss i den här första delen titta på en specifik sort. library(MASS) oats_marvel &lt;- oats %&gt;% filter(V == &quot;Marvellous&quot;) oats_marvel ## B V N Y ## 1 I Marvellous 0.0cwt 105 ## 2 I Marvellous 0.2cwt 140 ## 3 I Marvellous 0.4cwt 118 ## 4 I Marvellous 0.6cwt 156 ## 5 II Marvellous 0.0cwt 96 ## 6 II Marvellous 0.2cwt 124 ## 7 II Marvellous 0.4cwt 121 ## 8 II Marvellous 0.6cwt 144 ## 9 III Marvellous 0.0cwt 89 ## 10 III Marvellous 0.2cwt 129 ## 11 III Marvellous 0.4cwt 132 ## 12 III Marvellous 0.6cwt 124 ## 13 IV Marvellous 0.0cwt 70 ## 14 IV Marvellous 0.2cwt 89 ## 15 IV Marvellous 0.4cwt 104 ## 16 IV Marvellous 0.6cwt 117 ## 17 V Marvellous 0.0cwt 63 ## 18 V Marvellous 0.2cwt 70 ## 19 V Marvellous 0.4cwt 109 ## 20 V Marvellous 0.6cwt 99 ## 21 VI Marvellous 0.0cwt 97 ## 22 VI Marvellous 0.2cwt 99 ## 23 VI Marvellous 0.4cwt 119 ## 24 VI Marvellous 0.6cwt 121 En vanlig illustration av ett blockförsök är ett punktdiagram kombinerat med ett linjediagram. ggplot(oats_marvel, aes(N, Y, color = B, group = B)) + geom_point(size = 4) + geom_line() Färg och linje sammanbinder observationer från samma block. Det finns tecken på en blockeffekt: block I är nästan alltid högst och block V är nästan alltid lägst. Det finns också en tydlig behandlingseffekt i att högre kväve ger högre skörd. Blockeffekten kan enkelt föras in i modellen genom att lägga till variabeln B i lm-funktionen. Anova-tabellen och parvisa jämförelser kan göras på samma sätt som tidigare. Resultaten påverkas av att modellen har en blockfaktor; man behöver vanligen inte ange det explicit. mod_bl &lt;- lm(Y ~ N + B, data = oats_marvel) Anova(mod_bl) ## Anova Table (Type II tests) ## ## Response: Y ## Sum Sq Df F value Pr(&gt;F) ## N 5287.5 3 14.6241 0.0001004 *** ## B 5708.7 5 9.4735 0.0003106 *** ## Residuals 1807.8 15 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 P-värdet från F-testet på variabeln N är nu klart mindre än tidigare. Detta beror på att en stor del av variationen kan förklaras med blockeffekten, vilket är tydligt i att blockeffekten också har ett litet p-värde i F-testet. Det kan vara intressant att jämföra med modellen utan block. mod_wo_block &lt;- lm(Y ~ N, data = oats_marvel) Anova(mod_wo_block) ## Anova Table (Type II tests) ## ## Response: Y ## Sum Sq Df F value Pr(&gt;F) ## N 5287.5 3 4.6896 0.01227 * ## Residuals 7516.5 20 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Det som är residualens kvadratsumma i modellen utan block är i blockmodellen uppdelat i en blockeffekt och en residualterm. Eftersom F-testet bygger på en jämförelse mellan behandlingseffekten och residualtermen leder blockdesignen till starkare signifikans i blockmodellen. Å andra sidan kostar blockfaktorn frihetsgrader vilket ger oss ett svagare test. Effekten av att ta med ett block beror alltså på om det finns en verklig skillnad mellan blocken eller ej. Vi kan gå vidare med att titta på parvisa jämförelser mellan kvävenivåer. Funktionen emmeans() och cld() fungerar som tidigare. cld(emmeans(mod_bl, ~ N), Letters = letters) ## N emmean SE df lower.CL upper.CL .group ## 0.0cwt 86.7 4.48 15 77.1 96.2 a ## 0.2cwt 108.5 4.48 15 98.9 118.1 b ## 0.4cwt 117.2 4.48 15 107.6 126.7 bc ## 0.6cwt 126.8 4.48 15 117.3 136.4 c ## ## Results are averaged over the levels of: B ## Confidence level used: 0.95 ## P value adjustment: tukey method for comparing a family of 4 estimates ## significance level used: alpha = 0.05 ## NOTE: If two or more means share the same grouping symbol, ## then we cannot show them to be different. ## But we also did not show them to be the same. Signifikansbokstäver anger att den lägsta nivån är skild från övriga och att den näst lägsta är skild från den högsta. Även här kan det vara intressant att jämföra med modellen utan block. cld(emmeans(mod_wo_block, ~ N), Letters = letters) ## N emmean SE df lower.CL upper.CL .group ## 0.0cwt 86.7 7.91 20 70.2 103 a ## 0.2cwt 108.5 7.91 20 92.0 125 ab ## 0.4cwt 117.2 7.91 20 100.7 134 ab ## 0.6cwt 126.8 7.91 20 110.3 143 b ## ## Confidence level used: 0.95 ## P value adjustment: tukey method for comparing a family of 4 estimates ## significance level used: alpha = 0.05 ## NOTE: If two or more means share the same grouping symbol, ## then we cannot show them to be different. ## But we also did not show them to be the same. Modellen utan block ger samma medelvärden emmean men större medelfel SE och färre signifikanta skillnader. Uppgift 6.8 (Block med två behandlingar. Graf) Det minsta möjliga blocket är det med två behandlingar. Vi filtrerar havredatan för att den situationen. dat_small_block &lt;- oats %&gt;% filter(V == &quot;Marvellous&quot;, N %in% c(&quot;0.6cwt&quot;, &quot;0.0cwt&quot;)) dat_small_block ## B V N Y ## 1 I Marvellous 0.0cwt 105 ## 2 I Marvellous 0.6cwt 156 ## 3 II Marvellous 0.0cwt 96 ## 4 II Marvellous 0.6cwt 144 ## 5 III Marvellous 0.0cwt 89 ## 6 III Marvellous 0.6cwt 124 ## 7 IV Marvellous 0.0cwt 70 ## 8 IV Marvellous 0.6cwt 117 ## 9 V Marvellous 0.0cwt 63 ## 10 V Marvellous 0.6cwt 99 ## 11 VI Marvellous 0.0cwt 97 ## 12 VI Marvellous 0.6cwt 121 Fyll i stycket nedan för att skapa en graf med N på x-axeln, Y på y-axeln och en gruppering som länkar observationer från samma block. ggplot(dat_small_block, aes(x = ___, y = ___, group = ___)) + geom_point() + geom_line() Uppgift 6.9 (Block med två behandlingar. Test) Eftersom det är ett försök med en förklarande faktor och block kan man modellera det med den tidigare blockmodellen. Men eftersom man bara har två observationer per block kan man också se det som matchade stickprov, vilket kan lösas med ett t-test. Fyll i stycket nedan för att göra de två testen - utfallsvariabeln är skörd Y och den förklarande faktorn är kvävenivån N. Jämför resultaten. mod &lt;- lm(___ ~ ___ + B, data = dat_small_block) Anova(mod) t.test(___ ~ ___, data = dat_small_block, paired = ___) Uppgift 6.10 (Majshybridimport) I fliken Majshybrider i excelfilen Uppgiftsdata.xlsx finns data på fyra majssorter, vardera sorterad på fem platser (som agerar som block). Importera datan med funktionen read_excel() genom att fylla i kodstycket nedan. dat_corn &lt;- read_excel(&quot;&quot;, sheet = ___) Uppgift 6.11 (Majshybridgraf) Skapa en lämplig graf av datan på majshybrider. Grafen ska illustrera både jämförelsen mellan hybrider och jämförelsen mellan platser. Se exemplet ovan som guide. Uppgift 6.12 (Majshybridmodell) Fyll i koden nedan för att skatta en anova-modell med block för datan på majshybrider. Ta fram anovatabellen med Anova(). Vilka slutsatser kan man dra från anovatabellen? mod &lt;- lm(___ ~ ___ + Plats, data = dat_corn) Anova(mod) Uppgift 6.13 (Majshybridjämförelser) Gör lämplig ändring i koden nedan för att jämföra hybrider, istället för platser. emmeans(mod, pairwise ~ Plats) 6.5 Variansanalys. Två faktorer med block Exempeldata på havre tar med två förklarande faktorer och ett block. Datan kan illustreras med ett punktdiagram där facet_wrap delar grafen efter sort. ggplot(oats, aes(N, Y, color = B)) + geom_point(size = 4) + facet_wrap(~ V) Grafen visar samma kvävesamband som tidigare. Det finns inga tydliga skillnader mellan sorter, möjligen har sorten Victory givit något lägre skörd än övriga. Det finns fortfarande en tydlig blockeffekt, till exempel har block I höga värden och block V låga värden. Modellen skattas genom att lägga till variabeln för sort (V för variety) i lm-formeln. En modell med två faktorer kan antingen vara med eller utan en interaktion. Interaktionstermen fångar påverkan mellan faktorerna. Ett exempel hade varit om någon sort svarat starkare på ökad kväve än någon annan. Standardmodellen är att ta med interaktionen, vilket vi anger genom att sätta N * V istället för N + V. Blocket tas fortfarande med som en adderad faktor mod_two_fact &lt;- lm(Y ~ N * V + B, data = oats) Anovatabellen kan plockas fram på samma sätt som tidigare. Anova(mod_two_fact) ## Anova Table (Type II tests) ## ## Response: Y ## Sum Sq Df F value Pr(&gt;F) ## N 20020.5 3 26.2510 1.135e-10 *** ## V 1786.4 2 3.5134 0.03665 * ## B 15875.3 5 12.4894 4.093e-08 *** ## N:V 321.7 6 0.2109 0.97187 ## Residuals 13982.1 55 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Raden N:V gäller interaktionseffekten mellan kväve och sort. I det här fallet är det ingen signifikant interaktion - vilket tyder på att sorterna svarar på kvävebehandling på liknande sätt. Samtliga huvudeffekter (raderna för N, V och B) är signifikanta. Kvadratsummorna och p-värdena tyder på att kväve förklarar mer av variationen än sort, vilket också är i linje med grafen ovan. Vid flerfaktoriella försök kan man presentera parvisa jämförelser på flera olika sätt. Man kan ange huvudeffekter för en faktor utan att ange den andra faktorn, man kan ange medelvärden för samtliga kombinationer av två faktorer, och man kan ange medelvärden uppdelat efter nivåer i en annan faktor. emmeans(mod_two_fact, ~ N) ## N emmean SE df lower.CL upper.CL ## 0.0cwt 79.4 3.76 55 71.9 86.9 ## 0.2cwt 98.9 3.76 55 91.4 106.4 ## 0.4cwt 114.2 3.76 55 106.7 121.8 ## 0.6cwt 123.4 3.76 55 115.9 130.9 ## ## Results are averaged over the levels of: V, B ## Confidence level used: 0.95 emmeans(mod_two_fact, ~ N + V) ## N V emmean SE df lower.CL upper.CL ## 0.0cwt Golden.rain 80.0 6.51 55 67.0 93.0 ## 0.2cwt Golden.rain 98.5 6.51 55 85.5 111.5 ## 0.4cwt Golden.rain 114.7 6.51 55 101.6 127.7 ## 0.6cwt Golden.rain 124.8 6.51 55 111.8 137.9 ## 0.0cwt Marvellous 86.7 6.51 55 73.6 99.7 ## 0.2cwt Marvellous 108.5 6.51 55 95.5 121.5 ## 0.4cwt Marvellous 117.2 6.51 55 104.1 130.2 ## 0.6cwt Marvellous 126.8 6.51 55 113.8 139.9 ## 0.0cwt Victory 71.5 6.51 55 58.5 84.5 ## 0.2cwt Victory 89.7 6.51 55 76.6 102.7 ## 0.4cwt Victory 110.8 6.51 55 97.8 123.9 ## 0.6cwt Victory 118.5 6.51 55 105.5 131.5 ## ## Results are averaged over the levels of: B ## Confidence level used: 0.95 emmeans(mod_two_fact, ~ N | V) ## V = Golden.rain: ## N emmean SE df lower.CL upper.CL ## 0.0cwt 80.0 6.51 55 67.0 93.0 ## 0.2cwt 98.5 6.51 55 85.5 111.5 ## 0.4cwt 114.7 6.51 55 101.6 127.7 ## 0.6cwt 124.8 6.51 55 111.8 137.9 ## ## V = Marvellous: ## N emmean SE df lower.CL upper.CL ## 0.0cwt 86.7 6.51 55 73.6 99.7 ## 0.2cwt 108.5 6.51 55 95.5 121.5 ## 0.4cwt 117.2 6.51 55 104.1 130.2 ## 0.6cwt 126.8 6.51 55 113.8 139.9 ## ## V = Victory: ## N emmean SE df lower.CL upper.CL ## 0.0cwt 71.5 6.51 55 58.5 84.5 ## 0.2cwt 89.7 6.51 55 76.6 102.7 ## 0.4cwt 110.8 6.51 55 97.8 123.9 ## 0.6cwt 118.5 6.51 55 105.5 131.5 ## ## Results are averaged over the levels of: B ## Confidence level used: 0.95 Även här kan man göra jämförelser mellan nivåer genom att sätta pairwise ~ N + V eller beräkna signifikansbokstäver med cld. Följande kod jämför kvävenivåer inom sort. Uppgift 6.14 (Sort uppdelat efter kvävenivå) Gör lämplig ändring i koden ovan för att jämföra sorter inom kvävenivå. Finns det några signifikanta skillnader? Uppgift 6.15 (Interaktion med ett block) I modellen ovan är block en additiv faktor - den ingår inte i någon interaktionseffekt. Vad händer med testerna om man skattar modellen där samtliga interaktioner tas med? Varför? mod_two_fact &lt;- lm(Y ~ N * V * B, data = oats) 6.6 Modellantaganden och residualer Samtliga anovamodeller har samma grundläggande antaganden: feltermerna (den kvarvarande slumpmässigheten) är normalfördelade, sinsemellan oberoende, och variansen är samma för samtliga behandlingsgrupper. Antagandena testas oftast genom att titta på modellens residualer - skillnaden mellan det faktiska värdet och det skattade värdet. För en skattad modell kan man ta upp residualerna med residuals() och de skattade värdena med fitted(). Vi kan lägga till residualer och skattningar till datan med ett mutate()-steg. oats &lt;- oats %&gt;% mutate(Residualer = residuals(mod_two_fact), Skattade = fitted(mod_two_fact)) Normalfördelning kan undersökas grafiskt med ett histogram eller en QQ-graf. g_hist &lt;- ggplot(oats, aes(Residualer)) + geom_histogram(bins = 20) g_qq &lt;- ggplot(oats, aes(sample = Residualer)) + geom_qq() + geom_qq_line() library(patchwork) g_hist + g_qq Punkterna avviker något från normalfördelningen i svansarna, men det är förstås alltid en bedömningsfråga. Lika varians undersöks ofta med ett spridningsdiagram med de skattade värdena på x-axeln och residualerna på y-axeln. ggplot(oats, aes(x = Skattade, y = Residualer)) + geom_point() + geom_hline(yintercept = 0, alpha = 0.3) Om datan är i linje med antaganden ska diagrammet se ut som slumpmässigt placerade punkter med ungefär lika stor spridning kring noll-linjen för samtliga nivåer på x-axeln. För det här exemplet ser det okej ut. Uppgift 6.16 (Bakterieimport) Fliken Bakterier i filen Uppgiftsdata.xlsx innehåller data om tillväxt hos gräs efter inokulering av bakterier. Ladda ner filen och importera datan genom att fylla i koden nedan. dat_bact &lt;- read_excel(&quot;___&quot;, sheet = &quot;Bakterier&quot;) Uppgift 6.17 (Bakterieimport) Illustrera datan med en lämplig graf, till exempel ett spridningsdiagram med Inoculation på x-axeln, Dry weight på y-axeln, småfönster efter Cultivar och färg efter Block. ggplot(dat_bact, aes(x = ___, y = `___`, color = Block)) + geom_point(size = 6) + facet_wrap(~ ___) Hur blev färgerna för blocket? Om de inte blev distinkta färger kan variabeln Block ha blivit inläst som numerisk. Transformera variabeln med as.character() och gör om grafen. Ändras färgerna? dat_bact &lt;- dat_bact %&gt;% mutate(Block = as.character(Block)) Uppgift 6.18 (Bakteriemodell) Bakteriedatan har två faktorer och en blockfaktor. Skatta en anova-modell med interaktion och block genom att fylla i stycket nedan. Ta fram anovatabell och dra en slutsats från F-testen. Ligger slutsatsen i linje med grafen? mod &lt;- lm(`___` ~ ___ * ___ + ___, data = dat_bact) Anova(mod) Uppgift 6.19 (Bakteriejämförelser) Använd emmeans() för parvisa jämförelser mellan inokuleringsmetoder. Vilka par är signifikant åtskilda? emmeans(mod, pairwise ~ ___) Uppgift 6.20 (Bakterieresidualer) Vi använder den skattade modellen för att ta fram skattade värden och residualer. dat_bact &lt;- dat_bact %&gt;% mutate(Residualer = residuals(mod), Skattade = fitted(mod)) Använd exemplet på residualtester ovan för att undersöka antagandet om normalfördelade residualer. 6.7 Bonus. Statistik för ekologi Här tittar vi på några statistiska metoder som är vanliga inom ekologin, men går bortom materialet på en statistisk grundkurs. Vi börjar med datastruktur och visualisering för populationsdata, för att sedan titta på diversitetsmått, principalkomponentanalys (PCA) och hierarkisk klustering. Det vanligaste paketet för ekologi är vegan, så vi kan börja med att installera och ladda det. Vi kommer också använda factoextra för en graf. # install.packages(&quot;vegan&quot;) library(vegan) # install.packages(&quot;factoextra&quot;) library(factoextra) Data för ekologiska populationer för flera platser eller tillfällen ordnas oftast i en tabell med plats som rad och arter som kolumner. Värdena i tabellen anger antingen antalet observerade individer eller ett binärt utfall (1 för förekomst, 0 för ingen förekomst). Exempeldatan dune, som kan laddas med funktionen data(), ger ett exempel. För att illustrera en typisk jämförelsestudie skapar vi en kolumn för platstyp och lägger till ett plats-id. data(dune) dune &lt;- dune %&gt;% mutate(Site = 1:n(), Type = rep(c(&quot;A&quot;, &quot;B&quot;), each = 10)) Vi kan illustrera data genom att pivotera till långt format och göra en graf med ggplot(). En heatmap eller ett spridningsdiagram med storlek för antal observationer kan vara lämpliga grafer. Tolkning kräver förstås kod artkännedom och beror på den vetenskapliga frågan. dune_long &lt;- dune %&gt;% pivot_longer(-c(Site, Type), names_to = &quot;Species&quot;, values_to = &quot;Abundance&quot;) ggplot(dune_long, aes(Site, Species, fill = Abundance)) + geom_tile() + scale_fill_gradient2() + theme_minimal() ggplot(dune_long %&gt;% filter(Abundance &gt; 0), aes(Site, Species, size = Abundance, color = Type)) + geom_point() Ytterligare alternativ kan vara upprepade lådagram eller staplar med småfönster per art. Uppgift 6.21 (Populationsgrafer) Vad måste läggas till i stycket nedan för göra ett lådagram (med art på y-axeln och abundans på x-axeln) och ett stapeldiagram (med platstyp på x-axeln och abundans på y-axeln)? dune_long ggplot(dune_long, aes(x = ___, y = ___, fill = Type)) + geom_boxplot() ggplot(dune_long, aes(x = ___, y = ___, fill = Type)) + geom_col() + facet_wrap(~ ___, nrow = 2) Ekologiska populationer kan analyseras genom heirarkisk klustring - metoder där platser (rader) eller arter (kolumner) sorteras efter hur lika de är. Först beräknas ett avstånd mellan samtliga enheter (platser eller arter) och därefter sker klustringen genom att slå ihop enheter som ligger nära varandra. Resultatet illustreras med ett träddiagram. dune_data &lt;- dune %&gt;% dplyr::select(-Site, -Type) d &lt;- dist(dune_data, method = &quot;euclidean&quot;) hc &lt;- hclust(d) plot(hc, hang = -1, labels = dune$Type, axes = F, xlab = &quot;&quot;, ylab = &quot;&quot;, ann = F) Uppgift 6.22 (Avståndsmått) Ta upp hjälpsidan till distansfunktionen med ?dist. Under method finns flera möjliga avståndsmått. Vad måste ändras i kodstycket ovan för att ange ett Manhattan-avstånd? Har avståndet någon betydande effekt på träddiagrammet? För att göra en klustring av arter kan man transponera data så att rader och kolumner byter plats med varandra. Här kommer artnamn automatisk med eftersom raderna i datan har namn. Det är inte alltid fallet, så det kan vara nödvändigt att sätta etiketter med argumentet labels i plot(). dune_data &lt;- t(dune_data) d &lt;- dist(dune_data, method = &quot;euclidean&quot;) hc &lt;- hclust(d) plot(hc, hang = -1, axes = F, xlab = &quot;&quot;, ylab = &quot;&quot;, ann = F) Träddiagrammet tolkas så att enheter vars koppling ligger lågt är mer lika varandra - arterna förekommer ofta på samma plats. En annan vanlig metod för multivariat data, vilket populationsdata är ett exempel på, är principalkomponentsanalys (PCA, Principal Component Analysis). En PCA är ett försök att sammanfatta den ursprungliga datans 30 variabler (en per art) med ett mindre antal variabler. De nya variablerna - komponenterna - skapas genom att väga och addera de ursprungliga variablerna på ett sätt som förklarar så mycket som möjligt av variationen med minsta möjliga antal variabler. Resultatet illustreras vanligen med en biplot - ett spridningsdiagram som placerar ut både platser och arter. I R kan en PCA göras med prcomp() och en biplot kan göras med fviz_pca_biplot() från factoextra. dune_data &lt;- dune %&gt;% dplyr::select(-Site, -Type) pca &lt;- prcomp(dune_data, scale. = F) fviz_pca_biplot(pca, geom.ind = &quot;point&quot;, habillage = dune$Type, labelsize = 3) Platserna illustreras med punkter och arterna med pilar. Pilar i samma riktning motsvarar arter som är lika (de finns på samma platser), närliggande punkter motsvarar lika platser (de har samma arter), och punkter i samma riktning som en pil har höga värden för den arten. Uppgift 6.23 (Skalning i en PCA) En PCA kan göras med och utan att skala variablerna. Om variablerna skalas får en variabel som varierar mycket samma vikt som en variabel som varierar lite. Det kan vara bra om man har variabler som är mätta på olika sätt, till exempel om en variabel är i meter och en är i centimeter. Gör lämplig ändring i kodstycket ovan för att skala variablerna i prcomp(). Har det någon effekt på grafen? Den sista ansatsen vi ska titta på är att sammanfatta en population i ett enskilt tal - ett diversitetsindex. Genom att beräkna ett index kan man reducera datan till en observation på plats. Man kan därifrån tillämpa de metoder vi sett i övriga delar av kursen (t-test och variansanalys). Det finns en stor mängd olika index. Det vanligaste än Shannon-Weaver indexet (eller entropi), vilket beräknas genom att ta andelen per art, multiplicera med logaritmen av andelen, summera över arter, och multiplicera med minus ett. Om man har tre arter med andelarna 0.3, 0.5 och 0.2 ges Shannon-Weaver alltså av -(0.3 * log(0.3) + 0.5 * log(0.5) + 0.2 * log(0.2)) ## [1] 1.029653 Indexet ökar om det finns många arter och om andelen per art är samma. En population med en dominant art kommer alltså ha ett lågt index. För en tabell med data kan index beräknas med diversity(). diver &lt;- diversity(dune_data, index = &quot;shannon&quot;) dune &lt;- dune %&gt;% mutate(Diversity = diver) Diversitetsindexen kan sedan illustreras och analyseras som vilken numerisk variabel som helst. ggplot(dune, aes(Diversity, Type)) + geom_point() mod &lt;- lm(Diversity ~ Type, data = dune) Anova(mod) ## Anova Table (Type II tests) ## ## Response: Diversity ## Sum Sq Df F value Pr(&gt;F) ## Type 0.37586 1 6.6647 0.01881 * ## Residuals 1.01513 18 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 emmeans(mod, ~ Type) ## Type emmean SE df lower.CL upper.CL ## A 2.30 0.0751 18 2.14 2.46 ## B 2.03 0.0751 18 1.87 2.18 ## ## Confidence level used: 0.95 Här finns en signifikant skillnad med platstyper. Uppgift 6.24 (Diversitetsindex) Ta upp hjälpsidan till funktionen diversity(). Hur anger man att funktionen ska ge Simpsons index? Uppgift 6.25 (Test på nytt index) Gör om analysen på diversitet (anovamodellen och F-testet) med Simpsons index istället för Shannon-Weaver. Påverkar valet av diversitetsindex utfallet av testet? "],["regression-och-korrelation.html", "7 Regression och korrelation 7.1 Repetition av datorövning 6 7.2 Regression 7.3 Korrelation 7.4 Bonus. Skrapa data från webbsidor", " 7 Regression och korrelation Datorövning 7 handlar om regression och korrelation. Efter övningen ska vi kunna skatta en regressionsmodell i R, testa parametrar i modellen med F-test och t-test, göra lämpliga tester av modellantaganden, beräkna och tolka korrelationen mellan två variabler. 7.1 Repetition av datorövning 6 När man startar en ny R-session bör man ladda de paket man vet kommer behövas med library(). Om paket inte finns installerade måste man först köra install.packages(). # install.packages(&quot;tidyverse&quot;) library(tidyverse) I datorövning 7 tittade vi på variansanalys - en metod som gör det möjligt att utvidga t-testet för två grupper till ett godtyckligt antal grupper eller kombinationer av faktorer. I variansanalys skattar man en modell som förklarar ett datautfall. Utifrån modellen sätter man upp en anova-tabell som delar upp den totala variansen i en förklarad del och en kvarvarande residualdel. Anova-tabell ger också ett F-test som testar om det finns några skillnader mellan grupper. Från en skattad modell kan man sedan göra parvisa jämförelser mellan specifika grupper och testa modellantaganden (främst antagande om normalfördelning och lika varians inom grupper). Ta som exempel följande data på tandtillväxt (len) hos marsvin under C-vitaminbehandling i olika doser (dose) och två olika metoder (supp), tillgängligt i R som objektet ToothGrowth. ToothGrowth &lt;- ToothGrowth %&gt;% mutate(dose = as.character(dose)) ggplot(ToothGrowth, aes(len, supp, fill = dose)) + geom_boxplot() Ett lådagram visar en klar skillnad mellan doser och en svagare skillnad mellan metoder. Det finns också tecken på att metoderna svarar olika på dos i att metoden VC ligger lägre än OJ vid de låga doserna men över (eller iallafall lika) vid den höga dosen. En envägsanova-modell (en modell med en faktor) kan skattas med lm() och en anovatabell kan tas fram med Anova() från paketet car. mod &lt;- lm(len ~ dose, data = ToothGrowth) library(car) Anova(mod) ## Anova Table (Type II tests) ## ## Response: len ## Sum Sq Df F value Pr(&gt;F) ## dose 2426.4 2 67.416 9.533e-16 *** ## Residuals 1025.8 57 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 F-testets nollhypotes är att alla grupper (här alla doser) har samma populationsmedelvärde. Det låga p-värdet pekar på en klar skillnad mellan doser. En anovamodell bygger på antaganden om normalfördelning och lika varianser. Normalfördelningsantagandet kan undersökas med en QQ-graf över residualerna och variansantagandet kan undersökas med en spridningsgraf över skattade värden och residualer. library(patchwork) ToothGrowth &lt;- ToothGrowth %&gt;% mutate(Skattade = fitted(mod), Residualer = residuals(mod)) g1 &lt;- ggplot(ToothGrowth, aes(sample = Residualer)) + geom_qq() + geom_qq_line() g2 &lt;- ggplot(ToothGrowth, aes(Skattade, Residualer)) + geom_point() + geom_hline(yintercept = 0, color = &quot;red&quot;) g1 + g2 Punkterna ligger ungefär på linjen i QQ-grafen och punkterna har ungefär samma spridning för alla nivåer av det skattade värdet. Anova-modeller kan lätt byggas ut genom att lägga till fler faktorer. Här är det till exempel naturligt att skatta en modell med både metod och dos, vilket kan göras genom att lägga till supp till formeln i lm(). mod &lt;- lm(len ~ dose * supp, ToothGrowth) Anova(mod) ## Anova Table (Type II tests) ## ## Response: len ## Sum Sq Df F value Pr(&gt;F) ## dose 2426.43 2 92.000 &lt; 2.2e-16 *** ## supp 205.35 1 15.572 0.0002312 *** ## dose:supp 108.32 2 4.107 0.0218603 * ## Residuals 712.11 54 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Resultaten är i linje med grafen - dos har en stor effekt medan metod och interaktionen mellan dos och metod är något svagare, om än signifikanta. En anovamodell kan användas för parvisa jämförelse, vilket ibland kallas post-hoc-test. Den vanligaste är Tukey-testet, men andra tester kan också förekomma. Testet kan utföras med emmeans() från paketet med samma namn. Följande ger en jämförelse mellan doser uppdelat efter metod. library(emmeans) emmeans(mod, pairwise ~ dose | supp) ## $emmeans ## supp = OJ: ## dose emmean SE df lower.CL upper.CL ## 0.5 13.23 1.15 54 10.93 15.5 ## 1 22.70 1.15 54 20.40 25.0 ## 2 26.06 1.15 54 23.76 28.4 ## ## supp = VC: ## dose emmean SE df lower.CL upper.CL ## 0.5 7.98 1.15 54 5.68 10.3 ## 1 16.77 1.15 54 14.47 19.1 ## 2 26.14 1.15 54 23.84 28.4 ## ## Confidence level used: 0.95 ## ## $contrasts ## supp = OJ: ## contrast estimate SE df t.ratio p.value ## dose0.5 - dose1 -9.47 1.62 54 -5.831 &lt;.0001 ## dose0.5 - dose2 -12.83 1.62 54 -7.900 &lt;.0001 ## dose1 - dose2 -3.36 1.62 54 -2.069 0.1060 ## ## supp = VC: ## contrast estimate SE df t.ratio p.value ## dose0.5 - dose1 -8.79 1.62 54 -5.413 &lt;.0001 ## dose0.5 - dose2 -18.16 1.62 54 -11.182 &lt;.0001 ## dose1 - dose2 -9.37 1.62 54 -5.770 &lt;.0001 ## ## P value adjustment: tukey method for comparing a family of 3 estimates 7.2 Regression I en regression modelleras en numerisk variabel som en funktion av en annan numerisk variabel. Vid enkel linjär regression finns en sådan förklarande variabel och förhållandet mellan variablerna antas vara linjärt. Ta som exempel data på förväntad medellivslängd och bnp per capita. Datan hämtas från gapminder-paketet. Paketet ggrepel och funktionen geom_text_repel() kan användas för att sätta punktetiketter som inte överlappar. För enklare tolkning av modellen transformeras bnp per capita till att vara i tusen dollar, snarare än dollar. library(gapminder) dat_eu07 &lt;- gapminder %&gt;% filter(year == 2007, continent == &quot;Europe&quot;) %&gt;% mutate(gdpPercap = gdpPercap / 1000) library(ggrepel) ggplot(dat_eu07, aes(gdpPercap, lifeExp)) + geom_point() + geom_text_repel(aes(label = country), size = 3) Datan visar ett positivt samband mellan variablerna - högre bnp per capita är kopplat till högre medellivslängd. Uppgift 7.1 (Data för 1957) Vad måste ändras i stycket nedan för att plocka ut data och göra en graf för Europa 1957? dat_eu57 &lt;- gapminder %&gt;% filter(year == 2007, continent == &quot;Europe&quot;) %&gt;% mutate(gdpPercap = gdpPercap / 1000) ggplot(dat_eu57, aes(gdpPercap, lifeExp)) + geom_point() + geom_text_repel(aes(label = country), size = 3) En regressionmodell kan i R skattas med lm-funktionen. Syntaxen är väldigt lik den för anovamodellen, men istället för en faktor som förklarande variabel används nu en kontinuerlig variabel. mod &lt;- lm(lifeExp ~ gdpPercap, data = dat_eu07) summary(mod) ## ## Call: ## lm(formula = lifeExp ~ gdpPercap, data = dat_eu07) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.79839 -1.30472 0.00807 1.33443 2.87766 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 72.27106 0.69416 104.113 &lt; 2e-16 *** ## gdpPercap 0.21463 0.02514 8.537 2.8e-09 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.598 on 28 degrees of freedom ## Multiple R-squared: 0.7225, Adjusted R-squared: 0.7125 ## F-statistic: 72.88 on 1 and 28 DF, p-value: 2.795e-09 Funktionen summary ger en sammanfattning av modellen. Skattningen av modellens konstanta parameter ges som raden (Intercept) och dess tolkning är som förväntat värde i medellivslängd om bnp per capita är noll. Det är ofta lutningsparametern som är mer intressant. Skattningen av lutningsparametern ges på den rad som har samma namn som den förklarande variabeln, här gdpPercap. Den skattade parametern är 0.2146. Lutningsparametern har den generella tolkning som ökningen i y-variabeln när x-variabeln ökar med 1. I det här fallet ger 0.2146 att ett lands medellivslängd ökar med ungefär 0.2146 år (eller 78 dagar) när bnp per capita ökar med 1000 dollar. Uppgift 7.2 (Modell för 1957) Skatta samma modell som ovan, denna gång med data från 1957. Tolka lutningsparametern i ord. Är effekten av ökad bnp större 2007 än den var 1957? Man kan enkelt rita ut regressionlinjen i en graf med geom_smooth() och argumentet method satt till lm. ggplot(dat_eu07, aes(gdpPercap, lifeExp)) + geom_point() + geom_text_repel(aes(label = country), size = 3) + geom_smooth(method = lm) Den blå linjen illustrerar regressionlinjen 72.27 + 0.2146x. Det grå bandet kring linjen är ett konfidensintervall för skattningen av y-variabeln. Uppgift 7.3 (Graf för 1957) Använd geom_smooth(method = lm) för att lägga till en regressionslinje för data för 1957. Hur mycket påverkar de två avvikande länderna? Utskriften från summary ger också tester av parametrarna (den högra kolumnen Pr(&gt;|t|) ger p-värdet för ett test där nollhypotesen är att populationsparametern är noll). I det här fallet är både intercept och lutning skilda från noll. Motsvarande F-test för lutningen kan tas fram med en anova-tabell. library(car) Anova(mod) ## Anova Table (Type II tests) ## ## Response: lifeExp ## Sum Sq Df F value Pr(&gt;F) ## gdpPercap 186.031 1 72.883 2.795e-09 *** ## Residuals 71.469 28 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Testerna av en regressionsmodell bygger på ett normalfördelningsantagande och ett antagande om homoskedasticitet (lika varians i y oavsett position på x-axeln). Antagandena kan undersökas genom att titta på skattningens residualer - skillnaden mellan det faktiska y-värdet och modellens värde. Residualerna kan undersökas med ett histogram eller en QQ-plot. En annan vanlig diagnosplot är ett spridningsdiagram med skattade värden på x-axeln och residualerna på y-axeln. dat_eu07 &lt;- dat_eu07 %&gt;% mutate(Residualer = residuals(mod), Skattade = fitted(mod)) ggplot(dat_eu07, aes(sample = Residualer)) + geom_qq() + geom_qq_line() ggplot(dat_eu07, aes(Skattade, Residualer)) + geom_point() Om data följer en normalfördelning bör histogrammet visa en ungefärlig normalkurva, QQ-plotten bör visa punkter på den diagonala linjen och spridningsdiagrammet bör visa en slumpmässig spridning av punkter. Graferna pekar i det här fallet inte på några tydliga avvikelser från normalfördelningsantagandet, möjligen pekar QQ-plotten på mindre spridning i svansarna än en teoretisk normalfördelning. Uppgift 7.4 (Diagnos för 1957) Gör lämpliga ändringar i data ovan för diagnosgrafer för data från 1957. Finns det några tydliga avvikande värden? Uppgift 7.5 (Icke-linjära samband) Låt oss titta på hela gapminder-datan för 2007. dat_2007 &lt;- gapminder %&gt;% filter(year == 2007) ggplot(dat_2007, aes(gdpPercap, lifeExp)) + geom_point() Hur ser sambandet mellan bnp och medellivslängd ut? Vad skulle vara problematiskt med simpel linjär regression i det här fallet? När vi tittade på normalfördelningen sa vi att man ofta kan logaritmera en variabeln och få bättre egenskaper. Vad ska ändras i koden ovan för att använda logaritmerad gdpPercap istället för den ursprungliga variabeln? Är det sambandet mer linjärt? Uppgift 7.6 (Log-transformerad data) Vad ska ändras i koden nedan för att använda logaritmerad gdpPercap istället för den ursprungliga variabeln? Är det sambandet mer linjärt? dat_2007 &lt;- gapminder %&gt;% filter(year == 2007) ggplot(dat_2007, aes(gdpPercap, lifeExp)) + geom_point() Uppgift 7.7 (Blodtrycksdata) Gör lämplig ändring i stycket nedan för att läsa in fliken Blodtrycksdata från filen Uppgiftsdata.xlsx. library(readxl) dat_blod &lt;- read_excel(&quot;___&quot;, sheet = &quot;Blodtryck&quot;) Uppgift 7.8 (Blodtrycksgraf) Gör ett spridningsdiagram med ålder på x-axeln och blodtryck på y-axeln. Lägg till en regressionslinje med geom_smooth(method = lm). ggplot(___, aes(x = ___, y = ___)) + ___() + ___() Uppgift 7.9 (Blodtrycksmodell) Skatta och tolka en regressionmodell med ålder som förklarande variabel och blodtryck som förklarad variabel. mod &lt;- lm(___ ~ ___, data = dat_blod) Uppgift 7.10 (Blodtryckstest) Använd Anova() för att testa om det finns ett signifikant samband mellan ålder och blodtryck. Vad är testets nollhypotes och alternativhypotes? Uppgift 7.11 (Blodtrycksdiagnos) Ta fram diagnosgrafer för blodtrycksmodell och avgör om det finns några tydliga avvikelser från normalfördelning eller några extrema värden. dat_blod &lt;- dat_blod %&gt;% mutate(Residualer = residuals(mod), Skattade = fitted(mod)) ggplot(___, aes(sample = ___)) + geom_qq() + geom_qq_line() ggplot(___, aes(Skattade, ___)) + geom_point() 7.3 Korrelation Korrelation ger ett mått mellan \\(-1\\) och \\(1\\) på hur väl två variabler samvarierar. En korrelation över noll tyder på ett positivt samband mellan variablerna - en observation med ett högt värde i den ena variabeln har också ett högt värde på den andra - medan en korrelation under noll tyder på ett negativt samband. I R kan korrelation beräknas med cor() och två variabler som första och andra argument. Funktionen cor.test() ger ett test där nollhypotesen är att korrelationen är noll. cor(dat_eu07$lifeExp, dat_eu07$gdpPercap) ## [1] 0.8499711 cor.test(dat_eu07$lifeExp, dat_eu07$gdpPercap) ## ## Pearson&#39;s product-moment correlation ## ## data: dat_eu07$lifeExp and dat_eu07$gdpPercap ## t = 8.5372, df = 28, p-value = 2.795e-09 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## 0.7058444 0.9265221 ## sample estimates: ## cor ## 0.8499711 Medellivslängd och bnp per capita har en stark positiv korrelation på 0.85 och den korrelation är signifikant skild från noll (p &lt; 0.001). Notera att p-värdet är detsamma som för lutningsparametern i regressionen. Uppgift 7.12 (Korrelationsmatris) Om man har fler än två variabler sammanfattas korrelationer ofta med en korrelationsmatris. dat_eu07[, 4:6] ## # A tibble: 30 × 3 ## lifeExp pop gdpPercap ## &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 76.4 3600523 5.94 ## 2 79.8 8199783 36.1 ## 3 79.4 10392226 33.7 ## 4 74.9 4552198 7.45 ## 5 73.0 7322858 10.7 ## 6 75.7 4493312 14.6 ## 7 76.5 10228744 22.8 ## 8 78.3 5468120 35.3 ## 9 79.3 5238460 33.2 ## 10 80.7 61083916 30.5 ## # ℹ 20 more rows cor(dat_eu07[, 4:6]) ## lifeExp pop gdpPercap ## lifeExp 1.00000000 0.06946716 0.8499711 ## pop 0.06946716 1.00000000 0.0137427 ## gdpPercap 0.84997107 0.01374270 1.0000000 Vad är korrelationen mellan befolkningsstorlek och bnp per capita? Uppgift 7.13 (Anscombes data) Den raka regressionslinjen eller det enkla korrelationsmåttet säger lite om hur data egentligen ser ut. En vanlig illustration av detta är Anscombes kvartett, fyra exempel konstruerade av den brittiske statistikern Francis Anscombe 1973. Datan finns tillgänglig i R som datasetet anscombe. anscombe Plotta de fyra graferna (x1 paras med y1 och så vidare) i spridningsdiagram och beräkna korrelation för varje par. Ett exempel ges för den första mängden nedan. Kommentera utfallet. ggplot(anscombe, aes(x1, y1)) + geom_point() cor(anscombe$x1, anscombe$y1) Uppgift 7.14 (Datasaurus Dozen. Beskrivande mått) Datasaurus-datan är en konstruerad datamängd som illustrerar hur skilda mönster i data kan ge samma punktskattningar (medelvärden, standardavvikelser och korrelationer). Datan finns tillgänglig som en del av TidyTuesday-projektet och kan hämtas med följande rad. dat_saurus &lt;- read_csv(&#39;https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-10-13/datasaurus.csv&#39;) Datan innehåller en gruppering (dataset) och x- och y-koordinater. Beräkna medelvärden, standardavvikelser och korrelation för varje grupp i dataset genom att fylla i stycket nedan. dat_saurus %&gt;% group_by(___) %&gt;% summarise(mean(x), mean(y), sd(x), sd(y), cor(x, y)) Kommentera utfallet. Uppgift 7.15 (Datasaurus Dozen. Grafer) Illustrera datasaurus datan med spridningsdiagram. Använd facet_wrap() för småfönster per dataset. ggplot(dat_saurus, aes(x, y)) + geom_point() + facet_wrap(~ ___) Uppgift 7.16 (Galtons längdstudier. Installation av paket) En modern förståelse av regression införs under slutet av 1800-talet av Francis Galton (1822 - 1911). I en studie från 1886 samlade Galton in data på längder hos föräldrar och barn. En av Galtons slutsatser från den datan var att barn till långa föräldrar ofta blev kortade än föräldrarna. Extremvärden hade en tendes att återgå mot mitten - härifrån kommer namnet regression. Galtons längddata finns tillgänglig i paketet HistData som Galton. Installera paketet, ladda paketet, och skriv ut datan. install.packages(&quot;___&quot;) library(___) Galton Datan är i tum. Om man föredrar cm kan man multiplicera med 2.54. Galton &lt;- 2.54 * Galton Uppgift 7.17 (Galtons längdstudier. Graf) Gör en graf med föräldrars medellängd (parent) och barnets längd (child). Eftersom det finns överlappande punkter kan man använda geom_count() eller geom_jitter() istället för geom_point(). ggplot(Galton, aes(parent, child)) + geom_count() ggplot(Galton, aes(parent, child)) + geom_jitter() Uppgift 7.18 (Galtons längdstudier. Modell) Skatta en regressionmodell med barnets längd som förklarad variabel och förälderns längd som förklarande variabeln. Skriv ut resultaten och tolka lutningsparametern. Gör ett F-test med Anova(). mod &lt;- lm(___ ~ ___, Galton) summary(___) Anova(___) Uppgift 7.19 (Galtons längdstudier. Konfidensintervall) Paketet emmeans(), som vi tidigare använt för att ta fram effekter i anovamodeller, har också en funktion för lutningsparametrar emtrends(). Vi kan använda den funktionen för att beräkna konfidensintervall för lutningen. library(emmeans) emtrends(mod, ~ 1, var = &quot;parent&quot;) Funktionen emmeans() kan också användas för ett konfidensintervall för barnets längd vid ett specifikt värde för föräldrarnas längd. Följande ger ett konfidensintervall för barnets längd om föräldrarnas medellängd är 170 cm. emmeans(mod, ~ parent, at = list(parent = 68)) Vad ska ändras i stycket ovan för att beräkna ett konfidensintervall för barnets längd om föräldrarnas medellängd är 190 cm? Uppgift 7.20 (Galtons längdstudier. Diagnosgrafer) Galtondatan omfattar 928 mätningar. Ta ut residualerna med residuals(mod) och gör ett histogram med hist() eller geom_histogram(). Följer residualerna en ungefärlig normalfördelning? 7.4 Bonus. Skrapa data från webbsidor Det är väldigt vanligt att hämta in data från externa källor för att bygga ut en statistisk analys, till exempel kan offentlig väderdata vara intressant för ett odlingsförsök. Den typen av data kan vara mer eller mindre lättillgänglig. Här tittar vi på några exempel på hur allmänt tillgänglig data kan hämtas och användas. Kommunikation mellan datorer sker genom ett API (Application Programming Interface). Många organisationer som sprider data har ett öppet tillgängligt API som användare kan koppla upp sig till. Ofta finns R-paket som gör det enkelt att ange vilket data man är ute efter. Några exempel är pxweb - statistiska centralbyråns web-API, https://cran.r-project.org/web/packages/pxweb/vignettes/pxweb.html, Eurostat - europeiska statistikbyrån, https://ropengov.github.io/eurostat/articles/eurostat_tutorial.html, Rspotify - Spotifys API, https://github.com/tiagomendesdantas/Rspotify. I följande exempel används paketet osmdata för att hämta data från OpenStreetMap, https://www.openstreetmap.org/. #install.packages(&quot;osmdata&quot;) library(osmdata) dat_osm &lt;- opq(bbox = &#39;Malmö&#39;) %&gt;% add_osm_feature(key = &#39;admin_level&#39;, value = &#39;10&#39;) %&gt;% osmdata_sf() dat_osm_pol &lt;- dat_osm$osm_multipolygons ggplot(dat_osm_pol, aes()) + geom_sf() + geom_sf_text(aes(label = name), size = 3) Uppgift 7.21 (Malmös stadsdelar) Vad kan ändras i exemplet ovan för att ta ut Lunds stadsdelar i stället för Malmös? Ännu ett exempel. Denna gång Malmös restauranger efter typ. dat_osm &lt;- opq(bbox = &#39;Malmö&#39;) %&gt;% add_osm_feature(key = &#39;amenity&#39;, value = &#39;restaurant&#39;) %&gt;% osmdata_sf() dat_osm_point &lt;- dat_osm$osm_points %&gt;% filter(cuisine %in% c(&quot;pizza&quot;, &quot;sushi&quot;, &quot;burger&quot;, &quot;chinese&quot;, &quot;indian&quot;, &quot;vietnamese&quot;)) ggplot() + geom_sf(data = dat_osm_pol) + geom_sf(data = dat_osm_point, aes(color = cuisine), size = 2) Uppgift 7.22 (Offentlig konst) Offentliga konstverk är ofta registrerade med key = 'tourism' och value = 'artwork'. Vad kan ändras i exemplet ovan för att ta ut offentliga konstverk i Malmö? Det är inte alltid data finns tillgängligt genom en API. Mycket information finns publicerad som text eller tabeller på vanliga hemsidor. I såna fall kan man ofta ta hem data genom webbskrapning - att man med ett skript hämtar hem hemsidan, snarare än att själv läsa genom en webbläsare. I R kan det göras med paketet rvest. Ta som exempel den här tabellen över filmer i criterion-samlingen: https://www.criterion.com/shop/browse/list. För att läsa in den listan i R kan vi göra följande. # install.packages(&quot;rvest&quot;) library(rvest) url &lt;- &quot;https://www.criterion.com/shop/browse/list&quot; html &lt;- read_html(url) dat_crit &lt;- html %&gt;% html_table() dat_crit &lt;- dat_crit[[1]] %&gt;% select(-2) %&gt;% filter(Director != &quot;&quot;) dat_crit Uppgift 7.23 (Regissör) Vilken regissör har flest filmer i criterion-samlingen? Använd datan från exemplet ovan och räkna antal filmer per regissör, t.ex. med count(). Det finns flera paket som kan hämta data från Wikipedia, men det kan också göras med rvest. Här hämtas en tabell över mottagare av Nobelpriset i litteratur. url &lt;- &quot;https://en.wikipedia.org/wiki/List_of_Nobel_laureates_in_Literature&quot; dat_nob &lt;- url %&gt;% read_html() %&gt;% html_table() dat_nob &lt;- dat_nob[[1]] Uppgift 7.24 (Skrivspråk) Skapa ett stapeldiagram över antalet vinnare per språk (kolumnen Language(s)) genom att fylla i stycket nedan. dat_agg &lt;- dat_nob %&gt;% count(`Language(s)`) ggplot(dat_agg, aes(x = n, y = ___)) + geom_col() Uppgift 7.25 (Valfri tabell) Hitta en wikipedia-artikel med en tabell och försök hämta ner den till R genom att göra lämplig ändring i exemplet ovan. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
