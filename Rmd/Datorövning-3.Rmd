---
output: html_document
editor_options: 
  chunk_output_type: console
---
# Tester vid ett eller flera stickprov

Datorövning 3 handlar om hypotestest och konfidensintervall för ett eller två stickprov. Efter övningen ska vi kunna

- identifiera passande test för ett stickprov numerisk eller binär data,
- identifiera passande test för två stickprov numerisk eller binär data,
- analysera fördelningen av frekvenser i kvalitativ data.

## Repetition från datorövning 2

När man startar en ny R-session bör man ladda de paket man vet kommer behövas med `library()`. Om paket inte finns installerade måste man först köra `install.packages()`.

```{r thirdFile}
# install.packages("tidyverse")
library(tidyverse)
```

I datorövning 2 tittade vi på hur insamlade variabler kan sammanfattas med lägesmått och spridningsmått. Ett enkelt sätt att ta fram dem är att använda `summarise()` och ange de mått och variabler man vill använda. Vi hade uppe ett exempel på data från Gapminder som vi importerade från en excel-fil. För nu kan vi dock hämta datan från paketet `gapminder`.

```{r, results='hide'}
# install.packages("gapminder")
library(gapminder)

gapminder %>% 
  filter(year == 2007) %>% 
  group_by(continent) %>% 
  summarise(`Livslängd, medel` = mean(lifeExp),
            `Befolkning, median` = median(pop),
            `Bnp per capita, standardavvikelse` = sd(gdpPercap))
```

Beskrivande mått sammanfattas ofta i någon enkel vetenskaplig graf. Två vanliga val är lådagrammet, som illustrerar kvartiler och möjliga extremvärden, och stapeldiagrammet med felstaplar. Vi ger först ett exempel på ett lådagram över livslängd per kontinent uppdelat efter år.

```{r fig3_gm_boxplot, fig.height=6, fig.show='hide'}
ggplot(gapminder, aes(lifeExp, continent, fill = continent)) +
  geom_boxplot() +
  facet_wrap(~ year)
```

Därefter ett exempel på ett stapeldiagram med felstaplar för samma data. Felstapeln ges av standardavvikelsen.

```{r fig3_gm_bar, fig.height=6, fig.show='hide', results='hide'}
dat_sum <- gapminder %>% 
  group_by(continent, year) %>% 
  summarise(Mean = mean(lifeExp),
            SD = sd(lifeExp))
dat_sum

ggplot(dat_sum, aes(continent, Mean, fill = continent)) +
  geom_col() +
  geom_errorbar(aes(ymin = Mean - SD, ymax = Mean + SD), 
                width = 0.3) +
  facet_wrap(~ year)
```

## Ett stickprov

### Test av medelvärde för normalfördelad data

Om man har en normalfördelad variabel och vill testa om populationens medelvärde är skilt från något hypotetiskt värde $\mu_0$ kan man använda ett *t-test för ett stickprov*. Ta som exempel följande data på 8 observationer av havreskörd. Av någon historisk anledning vill man testa om populationsmedelvärdet är skilt från 50.

```{r, fig.height=2, fig.show='hide', results='hide'}
library(tidyverse)

dat <- data.frame(y = c(49.8, 58.4, 49.4, 57.1, 
                        52.2, 49.1, 44.6, 55.4))
dat

ggplot(dat, aes(y, 0)) + 
  geom_point() +
  geom_vline(xintercept = 50, color = "red")
```

I grafen ser vi att värdena ligger jämt spridda kring 50, så 50 är nog ganska rimligt som medelvärde, men låt oss göra ett formellt test. 
I R kan ett t-test genomföras med `t.test()`.

```{r}
t.test(dat$y, mu = 50)   # Ett t-test på variabeln y
```

Utskriften ger ett p-värde från vilket vi kan dra en slutsats. I det här fallet är p-värdet högt (över fem procent) så vi kan inte förkasta nollhypotesen (vilken är att populationsmedelvärdet är lika med 50).

Vi tittar nu på stegen bakom t-testet.
Ett t-test bygger, som alla hypotestest, på en serie steg:

1. sätt upp en *nollhypotes* och en *alternativhypotes*,
2. beräkna ett *testvärde* från en testfunktion,
3. identifiera en *testfördelning*,
4. beräkna ett *p-värde*, eller uppskatta ett genom att ställa testvärde mot ett kritiskt värde,
5. dra en klar *slutsats* om statistisk signifikans.

Vi vill testa om medelskörden är skild från 50, så hypoteser ges av

- $H_0$: $\mu$ lika med 50
- $H_1$: $\mu$ ej lika med 50

Alternativhypotesen är tvåsidig - vi tittar både på möjligheten att populationsmedelvärdet är större och på möjligheten att det är mindre.

::: {.exercise name="Ensidig mothypotes"}
Hur hade hypoteserna sett ut om vi ville testa om medelvärdet är *större* än 50?
:::

Från datan har vi åtta observation och vi kan ta fram stickprovsmedelvärde och standardavvikelse i R.

```{r}
mean(dat$y)
sd(dat$y)
```

Vårt mål är att testa ett medelvärde och det är rimligt att anta normalfördelning för den undersökta variabeln. Det lämpliga testet är då ett t-test för ett stickprov och testvärdet kan beräknas av en testfunktion som ges av det observerade stickprovet minus nollhypotesens värde, delat på standardavvikelsen delat på roten ur antalet observationer. 

$$t = \frac{\bar{y} - \mu_0}{s/\sqrt{n}}$$

::: {.exercise name="Handräkning"}
Beräkna t-värdet på miniräknare eller telefon. Finns det beräknade t-värdet i utskriften från `t.test()`?
:::

Nästa steg är att identifiera testfördelning, det vill säga den slumpfördelning testvärdet följet om nollhypotesen är sann. I det här fallet är testfördelningen en t-fördelning med n - 1 frihetsgrader. Vi har åtta observationer, så antalet frihetsgrader blir 7. I R kan man ta fram täthetsfunktionen för en t-fördelning med `dt()` och fördelningsfunktionen med `pt()`. Kurvorna kan plottas med `geom_function()` i en ggplot.

```{r, fig.height=2, results='hide', fig.show='hide'}
ggplot() +
  geom_function(fun = dt, args = list(df = 7)) +
  xlim(-5,5)

ggplot() +
  geom_function(fun = pt, args = list(df = 7)) +
  xlim(-5,5)
```

Från testfördelningen kan vi nu ta fram ett p-värde. P-värdet kan illustreras som ytan under t-fördelning *bortom* test-värdet. I ett tvåsidigt test tar vi med bägge svansarna.

```{r, fig.height=2, fig.show='hide'}
ggplot() +
  geom_function(fun = dt, args = list(df = 7)) +
  geom_vline(xintercept = c(-1.2086, 1.2086), 
             color = "red") +
  xlim(-5,5)
```

Ytorna i *svansarna* motsvarar p-värdet. De anger sannolikheten att få ett större t-värde än det vi fått, under antagandet att nollhypotesen stämmer. Det exakta p-värdet gavs av `t.test()`-funktionen som 0.266. En tolkning av det är om försöket upprepas ett stort antal gånger och nollhypotesen är sann, kommer vi 26.6 procent av gångerna få ett större testvärde än 1.2086. Det vi observerar är ganska sannolikt om nollhypotesen stämmer, vilket tyder på att nollhypotesen är rimlig.

Det avslutande steget är att dra en formell slutsats och ge ett tydligt svar. Det beräknade p-värdet ställs mot en förbestämd signifikansnivå, oftast fem procent. Här är p-värdet över den nivån, så vi kan inte förkasta nollhyptesen. Slutsatsen är att det *inte* finns någon signifikant skillnad från 50 i havreskörd.

::: {.exercise name="Kritiskt värde"}
Om man gör ett t-test för hand kan man inte enkelt ta fram ett p-värde, men kan se om p-värdet är större eller mindre än fem procent genom att ställa testvärdet mot ett kritiskt värde. Använd en tabell för t-fördelning för att hitta det kritiska värdet.

I R kan man ta fram kritiska värden med `qt()`. För fem procent i svansarna har man 0.025 i respektive svans och det kritiska värdet ges av

```{r, results='hide'}
qt(0.975, 7)
```
:::

::: {.exercise name="Ensidigt test"}
Använd `?t.test` för att ta fram funktionens hjälpsida. Försök att utifrån hjälpsidan beräkna ett *ensidigt* test för att se om medelskörden är *större* än 50.
:::

### Konfidensintervall för normalfördelad data

Utfallet av ett t-test beror på nollhypotesen värde, så om vi ändrar det kommer vi få ett annat p-värde.

```{r, eval = F}
t.test(dat$y, mu = 50)
t.test(dat$y, mu = 48)
```

Från p-värdena kan man dra slutsatsen att förkasta vid nollhypotesen att $\mu$ är 48, men inte förkasta vid nollhypotesen att mu är 50. Värdet 50 är alltså i någon mening ett mer troligt värde på populationens medelvärde än vad 48 är. *Konfidensintervall* kan ses som en generalisering av den tanken: ett konfidensintervall ger ett spann av värden där man *inte* förkastar. Intervallet tolkas vanligen som att det täcker det sanna populationsmedelvärdet med en viss konfidens.

För ett stickprov och antagen normalfördelning ges konfidensintervallet (med konfidensgraf $1-\alpha$) av

$$\bar y \pm t_{(1-\alpha/2,n-1)} \frac{s}{\sqrt n}$$

Kvantilen från t-fördelningen kan hämtas från en tabell (samma som det kritiska värdet i testet) eller genom R. Antalet frihetsgrader ges av antalet observationer minus ett. I det här fallet ges delarna av

```{r, results='hide'}
mean(dat$y)
sd(dat$y)
qt(0.975, 7)
```

och konfidensintervallet ges alltså av

$$52 \pm 2.365 \cdot 4.680 / \sqrt 8$$

Funktionen `t.test()` ger automatiskt ett konfidensintervall, direkt under utfallet av testet. Notera att konfidensintervallet inte beror på nollhypotesen. Konfidensintervall kan beräknas med skilda konfidensnivåer, oftast 95 procent, vilket sätts med argumentet `conf.level`.

::: {.exercise name="Konfidensnivå"}
Gör lämplig ändring i koden nedan för att beräkna ett 99-procentigt konfidensintervall, istället för ett 95-procentigt.

```{r}
t.test(dat$y, conf.level = 0.95)
```

Är ett 99-procentigt konfidensintervall bredare eller smalare än ett 95-procentigt?
:::

### Ett stickprov av binär data

Binär data är data där en observation har ett av två utfall, vilka kan kodas som noll och ett. Man talar ibland om utfallet ett som ett *positivt* utfall. Binär data kan sammanfattas med en proportion - antalet positiva utfall delat på det totala antalet upprepningar. En proportion kan testas med ett z-test för proportioner (eller *relativ frekvens*). Testet följer stegen för hypotestest (Hypoteser - Testvärde - Testfördelning - P-värde (eller jämförelse med kritiskt värde) - Slutsats). 

Låt oss importera lite exempeldata och beräkna ett exempel. Följande rad importerar matchresultat i fotbollsallsvenskan för damer 2000-2020.

```{r, fig.show='hide'}
library(tidyverse)
dat_alls <- read_csv("https://raw.githubusercontent.com/adamflr/ST0060/main/Data/Allsvenskan%2C%20damer%2C%202000-2020.csv")

ggplot(dat_alls, aes(hemmamal, bortamal)) +
  geom_jitter(size = 0.1)
```

::: {.exercise name="En interaktiv målgraf"}
Kör stycket nedan för en interaktiv målgraf. Vilken match gav det högsta antalet gjorda bortamål?
```{r, eval = F}
# install.packages("plotly")
library(plotly)
g <- ggplot(dat_alls, aes(hemmamal, bortamal, 
                      text = paste(sasong, hemma, "-", borta))) +
  geom_jitter(size = 0.1)

ggplotly(g)
```
:::

Gammal bollkunskap säger att var tredje match är en bortavinst. Vi kan testa det med ett z-test för proportioner. För att ta fram antalet bortasegrar och totalt antal matcher använder vi `count()` på kolumnen `resultat`. Man kan också använda funktionen `table()` för ett liknande resultat.

```{r, results='hide'}
dat_alls %>% count(resultat)
table(dat_alls$resultat)
```

Datan har 947 bortasegrar av totalt 947 + 1803 matcher. Vår skattade proportion `p` och totala antal `n` är alltså

```{r, results='hide'}
n <- 947 + 1803
p_est <- 947 / n

p_est
n
```

För att genomföra ett z-test sätter vi upp hypoteser om proportionen bortasegrar.

- Nollhypotes $H_0$: p lika med 0.33
- Alternativhypotes $H_1$: p ej lika med 0.33

Ett test kan köras i R med `prop.test()`.

```{r}
prop.test(x = 947, n = 2750, p = 0.33, correct = F)
```

P-värdet ställs mot en förbestämd signifikansnivå (vanligen 5 procent). I det här fallet leder det höga p-värdet till att nollhypotesen accepteras.

Om vi tar en närmre titt på testets steg börjar vi med att beräkna ett testvärde.

```{r}
p0 <- 0.33
z_value <- (p_est - p0) / sqrt(p0 * (1 - p0) / n)
z_value
```

Därefter kan p-värdet räknas ut som arean under en standardiserad normalfördelning bortom z-värdet. Eftersom vi har en tvåsidig mothypotes adderas de två svansarna.

```{r, fig.show='hide'}
ggplot() +
  geom_function(fun = dnorm) +
  geom_vline(xintercept = c(-z_value, z_value)) +
  xlim(-3,3)
```

Areans yta kan tas fram med normalfördelningens fördelningsfunktion `pnorm()`.

```{r}
2 * pnorm(-z_value)
```

Testets p-värde är ungefär 11 procent. Vår observation är alltså inte ett orimligt utfall om den faktiska sannolikheten för bortaseger är 0.33 och vi kan inte förkasta nollhypotesen på femprocentsnivån.

Om man löste uppgiften för hand skulle man istället för att beräkna p-värdet jämföra z-värdet med ett kritisk värde ur en tabell. Det kritiska värdet för femprocentig signifikans är 1.96. Vi kan också ta fram det genom `qnorm(0.975)`.

Vi kan jämföra den beräkning med den direkta R-funktionen.

```{r, results='hide'}
prop.test(x = 947, n = 2750, p = 0.33, correct = F)
```

Den stegvisa beräkningen gav samma utfall som funktionen (`p-value = 0.1092`). Funktionen ger inte z-värdet utan ett chi-två-värde (2.5661). Här är det värdet lika med z-värdet i kvadrat.

```{r, results='hide'}
z_value^2
```

::: {.exercise name="Test för proportionen oavgjorda"}
Samma gamla bollkunskap säger att 20 procent av matcher blir oavgjorda. I datan är 518 av 2750 matcher oavgjorda. Ställ upp hypoteser och fyll i koden nedan för att testa om bollkunskapen stämmer. Beräkna också z-värdet för hand.

```{r, eval = F}
prop.test(x = ___, n = ___, p = ___, correct = F)
```
:::

::: {.exercise name="Test för proportionen hemmasegrar"}
Slutligen är då resten av matcherna, 1285 av 2750, hemmasegrar. Gammal bollkunskap säger: *47 procent av alla matcher är hemmasegrar*. Genomför ett z-test för att testa det påstående.

```{r, eval = F}
prop.test(x = ___, n = ___, p = ___, correct = F)
```
:::

::: {.exercise name="Population och stickprov"}
Ett hypotestest bygger på en underliggande tanke med en population (med någon för oss okänd proportion positiva utfall) och ett stickprov (i vilket vi kan observera andelen positiva utfall). Det är inte alltid uppenbart vad som egentligen är populationen. I fallet med fotbollsdatan, vad kan ses som populationen? Hur långt skulle man kunna generalisera de slutsatser man kan dra från datan?
:::

Hypotestestet för proportioner som används här, *z-testet*, bygger på en normalapproximation av en binomialfördelning. Approximation blir bättre när antalet observationer är stort och nollhypotesens värde p0 ligger nära 0.5. En vanlig tumregel för när approximationen är giltig är att n gånger $p_0$ gånger $(1 - p_0)$ ska vara större än 10.

### Konfidensintervall för proportioner

Konstruktionen av ett konfidensintervall för en proportion är ganska lik konstruktionen för ett medelvärde. För en skattad proportion p och antal observationer n kan man beräkna p plus/minus ett z-värde från tabell gånger medelfelet, där medelfelet ges av roten ur $p \cdot (1 - p) / n$. För exemplet med bortasegrar i allsvenskan är $p = 0.344$ och $n = 2750$. Tabellvärdet hämtas från en tabell över kvantiler. För ett 95-procentigt konfidensintervall tar vi kvantilen 0.975 (2.5 procent i respektive svans) vilket ger värdet 1.96. Konfidensintervallet ges av

```{r, results='hide'}
n <- 947 + 1803
p <- 947 / n

p - 1.96 * sqrt(p * (1 - p) / n)
p + 1.96 * sqrt(p * (1 - p) / n)
```

Notera att 0.33, det värde som var nollhypotesen i det tidigare testet, *ingår* i intervallet. Om man tittar på utskriften från `prop.test()` kan man se ett konfidensintervall. Det intervallet är dock inte beräknat på samma sätt den formel som förekommer på föreläsningarna. För att få matchande utskrift kan vi använda paketet `binom` och funktionen `binom.asymp()`.

```{r, results='hide'}
#install.packages("binom")
library(binom)
binom.asymp(x = 947, n = 2750)
```

::: {.exercise name="99-procentigt konfidensintervall"}
Gör lämplig ändring i koden nedan för att beräkna ett 99-procentigt konfidensintervall för andelen bortasegrar.

```{r, eval = F}
binom.asymp(x = 947, n = 2750, conf.level = 0.95)
```
:::

### Chi-två-test för goodness-of-fit

Ett proportionstest kan ses som ett test av en variabel med två möjliga klasser som utfall. Ett *goodness-of-fit*-test utvecklar det till valfritt antal klasser. Testet utförs som ett chi-två-test genom att beräkna ett observerat antal O och ett förväntat antal E för varje klass. Testvärdet ges av att man beräknar $(O - E)^2 / E$ för varje klass och sedan summerar. Testfunktionen är en chi-två-fördelning där antalet frihetsgrader beror på antalet klasser.

Låt oss göra ett exempel baserat på fotbollsdatan. Där hade vi utfallet 947, 518 och 1285 för bortaseger, oavgjort och hemmaseger. Klassisk bollkunskap ger oss sannolikheterna 33, 20 och 47 procent. Testets hypoteser ges av

$H_0$: sannolikheterna för de olika utfallet ges av 33, 20 respektive 47 procent

$H_1$: minst något utfall har en annan sannolikhet än 33, 20 respektive 47 procent

För att få de förväntade värdena E multipliceras nollhypotesens sannolikheter med det totala antalet matcher.

```{r}
O <- c(947, 518, 1285)
E <- c(0.33,0.20,0.47) * 2750
```

::: {.exercise name="Granska E"}
Skriv ut objektet `E` och jämför med de observerade värdena. Notera att de förväntade värdena inte måste vara heltal, trots att de observerade värdena förstås alltid kommer vara det.
:::

Testvärdet beräknas genom formeln för varje term följt av summan.

```{r}
chisq_value <- sum((O - E)^2 / E)
```

P-värdet beräknas från en chi-två-fördelning. Antalet frihetsgrader ges av antalet klasser minus antalet skattade parametrar minus ett. I det här fallet har inga parametrar skattats från datan så antalet frihetsgrader blir två. Ett chi-två-test beräknas med kvadrater så vi är enbart intresserade av högra svansen.

```{r, fig.show='hide'}
ggplot() +
  geom_function(fun = dchisq, args = list(df = 2)) +
  geom_vline(xintercept = chisq_value) +
  xlim(0,10)
```

Man kan också beräkna ytan i svansen med `pchisq()`. Ett minus det resultatet ger den övre delen.

```{r, results='hide'}
1 - pchisq(chisq_value, df = 2)
```

P-värdet är alltså 0.16, över den klassiska signifikansnivån på 5 procent, vilket ger att vi inte kan förkasta nollhypotesen. Om man gör ett chi-två-test för hand jämför man det observerade chi-två-värdet med ett tabellvärde över kvantiler. Tabellvärdet kan också hämtas med funktionen `qchisq()`, i det här fallet

```{r, results='hide'}
qchisq(0.95, df = 2)
```

Notera att man tar 0.95 eftersom man alltid tittar på den yttre svansen i ett chi-två-test.

R har en inbyggd funktion för chi-två-test. Dess argument ges av observerade antal och sannolikheter.

```{r, results='hide'}
chisq.test(O, p = c(0.33, 0.2, 0.47))
```

Testet ger samma chi-två-värde och p-värde som beräknats ovan.

Situationen med flera klasser kan som sagt ses som en generalisering av fallet med två klasser. Det är alltså logiskt att chi-två-test kan användas även när man har två klasser. Följande exempel ger samma test som vi sett tidigare av andelen bortasegrar.

```{r, results='hide'}
chisq.test(x = c(947, 1803), p = c(0.33, 0.67), correct = F)
```

Likt `prop.test()` sätter vi `correct` till `FALSE` för att inte göra en korrektion. Notera att `x` här anges som positiva och negativa utfall istället för positiva utfall och totalt antal utfall, vilket var fallet i `prop.test()`.

Chi-två-testet bygger på en underliggande normal-liknande approximation. En vanlig tumregel är att alla förväntade värden ska vara större än 5. R ger en varning om så inte är fallet.

```{r, results='hide'}
chisq.test(c(6,4), p = c(0.51, 0.49))
```

::: {.exercise name="Chi-två med lika sannolikheter"}
En vanlig tillämpning av goodness-of-fit-testet är för att testa om alla klasser är lika sannolika. En jämn fördelning är grundinställning i `chisq.test()` så i det fallet behöver man bara ange de observerade värdena. En datainsamling om M&M-godis gav följande antal.

```{r, fig.show='hide'}
dat_mnm <- data.frame(Color = c("blue", "brown", "green", 
                                "orange", "red", "yellow"),
                      Count = c(180, 80, 88, 160, 134, 166))

ggplot(dat_mnm, aes(Color, Count, fill = Color)) +
  geom_col() +
  scale_fill_manual(values = dat_mnm$Color)
```

Använd de observerade värdena i kolumnen `Count` för att testa om alla godisfärger är lika vanliga.
:::

## Två stickprov 

### Test av normalfördelad data

Vid normalfördelad data från två stickprov eller grupper vill vi nästan alltid testa om populationerna har samma medelvärde. Det kan också ses som att vi testar om differensen mellan medelvärdena är noll. Vi skiljer mellan två fall: *matchade stickprov* - där varje observation i den ena gruppen är *kopplad* till en observation i den andra gruppen; och *oberoende stickprov* - där det inte finns någon sådan koppling mellan stickproven. Typiska exempel på matchade stickprov är när man mäter samma individ för och efter en behandling och syskonstudier där ett syskon får en behandling och den andra en annan behandling.

#### t-test för två matchade stickprov

Vid matchade stickprov kan varje observation i en behandlingsgrupp paras med en observation i den andra gruppen. Själva testet är ett t-test för *ett* stickprov på differensserien beräknat från varje par. I R kan man antingen beräkna den differensserien eller använda `t.test()` med två dataserier och argumentet för parvisa observationer satt till sant, `paired = T`.
Som exempel ges följande data från en studie på äpple, där trädhöjd mätts före och efter en näringsbehandling.

```{r, results='hide'}
dat_apple <- tibble(Tree = 1:4, 
              Before = c(48, 43, 30, 47), 
              After = c(51, 44, 42, 54))
dat_apple
```

Datan kan illustreras med ett punktdiagram där en linje binder samman paret. För att enkelt skapa grafen i `ggplot2` kan man först omstrukturera datan till lång form genom `pivot_longer`.

```{r, results='hide'}
dat_long <- dat_apple %>% 
  pivot_longer(-Tree, names_to = "Time", values_to = "Height")
dat_long
```

::: {.exercise name="Äppelgraf"}
Fyll i kodstycket nedan för en graf av äppeldatan. Axlarna ges av `Time` och `Height`. Två observationer kan kopplas genom att sätta `Tree` som grupp.
```{r, eval = F}
ggplot(dat_long, aes(___, ___, group = ___)) +
  geom_point() +
  geom_line()
```
:::

För att testa för skillnad före och efter behandling sätter vi upp hypoteser

- $H_0$: $\mu$ före behandling är lika med $\mu$ efter behandling
- $H_1$: $\mu$ före behandling är skild från $\mu$ efter behandling

Testet kan antingen utföras som ett enkelt t-test på differensserien

```{r, results='hide'}
t.test(dat_apple$Before - dat_apple$After)
```

eller som ett t-test för två stickprov där man särskilt anger att datan är parad

```{r, results='hide'}
t.test(dat_apple$Before, dat_apple$After, paired = T)
```

För bägge alternativen måste datan vara ordnad så att de två vektorerna matchar varandra parvis. Ett p-värde på $0.0987$ ger att man inte förkastar vid en signifikansnivå på fem procent. Vi drar därmed slutsatsen att det inte finns någon signifikant skillnad före och efter behandling.

::: {.exercise name="Ensidigt test"}
Gör ett tillägg till ett av kodstyckena med `t.test()` för att beräkna ett ensidigt test med mothypotesen att träden ökar i höjd efter behandling. Hjälpsidan för `t.test()` kan tas fram genom att köra `?t.test()`.
:::

Konfidensintervallet beräknas från differenserna på samma sätt som vid ett stickprov med normalfördelad data. Tolkningen liknar den för ett stickprov: med 95 procents konfidens ligger den sanna skillnaden i medelvärden i intervallet.

#### t-test för två oberoende stickprov

Ett t-test för två oberoende stickprov testar om två populationsmedelvärden är lika. Ta som exempel följande data på jordgubbsskörd vid två olika näringsbehandlingar (A och B). Här är stickproven inte matchade - det finns **ingen** direkt koppling mellan en observation i den ena behandlingsgruppen till någon observation i den andra.

```{r, results='hide'}
dat_berry <- data.frame(Behandling = c("A", "A", "A", "A", 
                                       "B", "B", "B", "B"),
                        Vikt = c(40, 48.2, 39.2, 47.9, 
                                 57.5, 61.5, 58, 66.5))
dat_berry
```

Datan kan illustreras med ett enkelt punktdiagram.

```{r, fig.show='hide'}
ggplot(dat_berry, aes(Behandling, Vikt)) +
  geom_point()
```

Ett t-test för två oberoende stickprov har nollhypotesen att grupperna har samma populationsmedelvärde och alternativhypotesen att populationsmedelvärdena är skilda (för det tvåsidiga fallet):

- $H_0$: $\mu_A$ är lika med $\mu_B$
- $H_1$: $\mu_A$ är ej lika med $\mu_B$

Testet kan utföras i R genom funktionen `t.test()`. Data kan antingen anges som en formel med dess data `Vikt ~ Behandling, data = dat_berry` (vilket man kan läsa som *vikt uppdelat efter behandling*) eller som två skilda vektorer. Det förra alternativet är oftast enklare om man har datan på lång form - med en kolumn som anger grupp (i exemplet *Behandling*) och en kolumn som anger utfallsvärdet (i exemplet *Vikt*).

För formen med formel ger det

```{r, results='hide'}
# Formelskrivning
t.test(Vikt ~ Behandling, data = dat_berry, var.equal = T)
```

och för formen med vektorer

```{r, results='hide'}
# Två separata vektorer
## Filtrera ut data där behandling är A
Vikt_A <- dat_berry$Vikt[dat_berry$Behandling == "A"]

## Filtrera ut data där behandling är B
Vikt_B <- dat_berry$Vikt[dat_berry$Behandling == "B"]

t.test(Vikt_A, Vikt_B, var.equal = T)
```

Argumentet `var.equal = T` används för att beräkna testet där gruppernas varianser antas vara lika. Grundinställningen är testet där varianser inte antas vara lika, så `t.test(Vikt ~ Behandling, data = dat)` ger ett lite annat resultat.

::: {.exercise name="Ej lika varianser"}
Vilka resultatvärden ändras i utskriften om man sätter `var.equal = F`?
:::

Testet ger ett p-värde på $0.0018$, vilket leder till att nollhypotesen förkastas på enprocentsnivån. Detta tyder på att det finns en viktskillnad mellan behandlingarna. Utskriften ger också ett 95-procentigt konfidensintervall på $(-24.898, -9.202)$. Tolkningen är att *skillnaden* mellan populationsmedelvärden ligger i intervallet med 95 procents konfidens. Notera att värdet noll inte ligger i intervallet.

Om man har fler än två grupper kan man vilja göra parvisa t-test - alltså ett t-test för varje par av grupper. 
Ett exempel på funktionen `pairwise.t.test()` ges nedan. Funktionen bygger på att datan är i *lång* form, med en kolumn som anger det numeriska utfallet och en kolumn som anger behandlingen.

```{r}
pairwise.t.test(dat_berry$Vikt, dat_berry$Behandling, 
                p.adjust.method = "none", pool.sd = F)
```

*Matchade* observationer kan också kallas *parade* (eng. paired) så se upp med terminologin. Funktionen `pairwise.t.test()` för *parvisa jämförelse* mellan behandlingar, men testerna är t-test för oberoende stickprov.

### z-test och konfidensintervall för två proportioner

Om man vill jämföra två proportioner kan man använda z-testet för två stickprov. Säg till exempel att man har två sorter av någon planta och vill se hur stor proportion som är infekterad av bladmögel. I den ena gruppen (sort A) är 17 av 50 infektera och i den andra (sort B) är 26 av 60 infekterade. Testets hypoteser är i det tvåsidiga fallet

- $H_0$: proportion A är lika med proportion B
- $H_1$: proportion A är skild från proportion B

I R kan testet genomföras med `prop.test()`-funktionen. Funktionens första argument är antalen infekterade, som en vektor med två värden, och dess andra argument är totalerna. Likt testet med ett stickprov finns en möjlighet att göra en kontinuitetskorrektion med `correct`-argumentet. För att få samma resultat som räkning för hand anger vi att korrektion inte ska göras med `correct = F`.

```{r, results='hide'}
prop.test(x = c(17, 26), n = c(50, 60), correct = F)
```

Notera att funktionen inte ger ett z-värde utan ett $\chi^2$-värde (utskrivet `X-squared`). Det beror på att funktionen beräknar z-testet som ett likvärdigt $\chi^2$-test. Det z-värde man får om man genomför testet som ett z-test är detsamma som roten ur utskriftens $\chi^2$-värde. Testet ger ett högt p-värde på 0.32 vilket innebär att nollhypotesen inte förkastas: det finns ingen signifikant skillnad i infektionsproportion.

Funktionen `prop.test()` ger också en utskrift av konfidensintervallet. Tolkning är att skillnaden i proportioner mellan populationerna ligger i intervallet med 95 procents konfidens. Notera att nollan ingår i intervallet.

::: {.exercise name="Burfågel"}
Det finns en förvånansvärt stor mängd studier på kopplingen mellan innehav av burfågel och lungcancer. En sådan studie (Kohlmeier et al 1992) ger följande antal för burfågelägande och lungcancer.

```{r, echo = T, results='hide'}
dat_bird <- data.frame(Burfågel = c("Burfågel", "Ej_burfågel"),
              Lungcancer = c(98, 141),
              Ej_lungcancer = c(101, 328))
dat_bird
```

Datan tyder på att människor med burfågel har en förhöjd risk att drabbas av lungcancer. Genomför ett z-test för att se om andelen burfågelägare än densamma i de två patientgrupperna.

```{r, eval = F}
prop.test(x = c(___, ___), n = c(___, ___), correct = F)
```
:::

### Chi-två-test för korstabeller

Data med två kategoriska variabler kan presenteras med en korstabell. Ta som (ett något deppigt) exempel överlevnadsdata från Titanic. Datan finns tillgänglig i R som `Titanic`. I detta fall ges överlevnad filtrerad på vuxna män, uppdelat efter klass.

```{r, results='hide'}
dat_titanic <- Titanic %>% 
  data.frame() %>% 
  filter(Sex == "Male", Age == "Adult")
dat_titanic
```

En korstabell kan konstrueras med `pivot_wider`.

```{r, results='hide'}
dat_wide <- dat_titanic %>% 
  pivot_wider(names_from = Survived, values_from = Freq)
dat_wide
```

Datan tyder på att överlevnad är beroende av klass. Vi kan illustrera med uppdelade staplar.

```{r, fig.show='hide'}
ggplot(dat_titanic, aes(Class, Freq, fill = Survived)) +
  geom_col(position = position_fill(), color = "black") +
  scale_fill_manual(values = c("red4", "white"))
```

Argumentet `position` i `geom_bar` används för att skapa proportionella staplar.

Ett chi-två-test på en korstabell har nollhypotesen att det inte finns något samband mellan variabeln för rader och variabeln för kolumner. Chi-två-testet kan tillämpas på korstabeller med godtyckligt antal rader och kolumner. Antal frihetsgrader ges av antal rader minus ett gånger antal kolumner minus ett. Testet kan enkelt göras med `chisq.test()`. Som ingångsvärde kan man plocka ut kolumnerna med numeriska värden genom hakparenteser.

```{r, results='hide'}
dat_wide[, 4:5] # De två numeriska kolumnerna

chisq.test(dat_wide[, 4:5])
```

Utskriften ger teststorheten, antal frihetsgrader, och p-värdet. I det här fallet är p-värdet mycket litet och slutsatsen blir att nollhypotesen förkastas - det finns ett samband mellan klass och överlevnad. Antalet frihetsgrader ges av antalet rader minus ett gånger antalet kolumner minus ett (här $(4-1) \cdot (2-1) = 3$).

Chi-två-testet är ett asymptotiskt test - dess egenskaper är beroende av *stora* stickprov. Som gräns för storleken används ofta att samtliga förväntade antal ska vara större än 5. Funktionen ger en varning om förväntade värden är små. En möjlig lösning i sådana fall är att slå ihop klasser.

```{r, results='hide'}
test_result <- chisq.test(dat_wide[, 4:5])
test_result$expected # Samtliga förväntade värden över 5
```

Om detta krav inte är uppfyllt skriver funktionen ut en varning.

::: {.exercise name="Ogiltig approximation"}
Ta följande lilla korstabell och kör `chisq.test()` för att få ett felmeddelande.
```{r}
dat <- matrix(c(4,2,5,1), 2)
dat
```
:::

::: {.exercise name="Burfågeln återvänder"}
En svensk studie på koppling mellan burfågel och lungcancer (Modigh et al, 1996) ger följande antal (för män).

```{r, results='hide'}
dat_bird_swe <- data.frame(Burfågel = c("Burfågel", "Ej_burfågel"),
              Lungcancer = c(108, 144),
              Ej_lungcancer = c(171, 256))
dat_bird_swe
```

Genomför ett chi-två-test för att se om andelen cancerdrabbade än densamma i de två burfågelsgrupperna. Formulera tydliga hypoteser. För att få utfall som stämmer med en handräkning kan man sätta `correct = F`.

```{r, eval = F}
dat_bird_swe[, c(2,3)]
chisq.test(___, correct = F)
```
:::

## AI-uppgift III

Det finns många studier som pekar på att p-värdet är svårtolkat. Det är särskilt vanligt att p-värdet tolkas som sannolikheten att nollhypotesen är sann. Den korrekta tolkningen är dock snarare tvärtom: p-värdet är sannolikheten för datautfallet givet att nollhypotesen är sann.

::: {.exercise name="Tolkning av p-värdet"}
Be en AI-chatbot besvara en t-test-fråga t.ex. från en tidigare tenta eller uppgiften i början av den här övningen. Fråga särskilt om tolkningen av p-värdet och om det finns några vanliga feltolkningar.
:::
