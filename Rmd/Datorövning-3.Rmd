---
output: html_document
editor_options: 
  chunk_output_type: console
---
# Tester vid ett eller flera stickprov

Datorövning 3 handlar om hypotestest och konfidensintervall för ett eller två stickprov. Efter övningen ska vi kunna

- identifiera passande test för ett stickprov numerisk eller binär data,
- identifiera passande test för två stickprov numerisk eller binär data,
- analysera fördelningen av frekvenser i kvalitativ data.

## Repetition från datorövning 2

När man startar en ny R-session bör man ladda de paket man vet kommer behövas med `library()`. Om paket inte finns installerade måste man först köra `install.packages()`.

```{r thirdFile}
# install.packages("tidyverse")
library(tidyverse)
```

I datorövning 2 tittade vi på hur insamlade variabler kan sammanfattas med lägesmått och spridningsmått. Ett enkelt sätt att ta fram dem är att använda `summarise()` och ange de mått och variabler man vill använda. Vi hade uppe ett exempel på data från Gapminder som vi importerade från en excel-fil. Idag kommer vi istället arbeta med *Palmers pingvindata*, en vanlig vetenskaplig exempeldata. Datan finns tillgänglig i paketet `palmerpenguins`. Vi laddar paketet och skriver ut de första raderna med data.

```{r, results='hide', eval=FALSE}
install.packages("palmerpenguins")
library(palmerpenguins)
penguins
```

```{r, results='hide'}
# install.packages("palmerpenguins")
library(palmerpenguins)
penguins
```

Vi kan länka samman steg med en *pipe* `%>%`. Här ser vi ett filter, en gruppering, och en summering. Inom `summarise()` beräknas beskrivande statistik med funktionerna `mean()`, `median()` och `sd()`.

```{r, results='hide'}
penguins %>% 
  drop_na() %>% 
  filter(year == 2007) %>% 
  group_by(species, sex) %>% 
  summarise(`Vikt, medel` = mean(body_mass_g),
            `Flipperlängd, median` = median(flipper_length_mm),
            `Näbblängd, standardavvikelse` = sd(bill_length_mm))
```

Beskrivande mått sammanfattas ofta i någon enkel vetenskaplig graf. Två vanliga val är lådagrammet, som illustrerar kvartiler och möjliga extremvärden, och stapeldiagrammet med felstaplar. Vi ger först ett exempel på ett lådagram över vikt.

```{r fig3_gm_boxplot, fig.height=6, fig.show='hide'}
ggplot(penguins, aes(body_mass_g, species, fill = sex)) +
  geom_boxplot() +
  facet_wrap(~ year)
```

Därefter ett exempel på ett stapeldiagram med felstaplar för samma data. Felstapeln ges av standardavvikelsen.

```{r fig3_gm_bar, fig.height=6, fig.show='hide', results='hide'}
dat_sum <- penguins %>% 
  drop_na() %>% 
  group_by(species, sex) %>% 
  summarise(Mean = mean(body_mass_g),
            SD = sd(body_mass_g))
dat_sum

ggplot(dat_sum, aes(sex, Mean)) +
  geom_col() +
  geom_errorbar(aes(ymin = Mean - SD, ymax = Mean + SD), 
                width = 0.3) +
  facet_wrap(~ species)
```

## Allmänt om hypotestester

Ett hypotestest används för att värdera en hypotes i situationer med slumpmässig spridning. Testets centrala utfall är ett p-värde, som ger sannolikheten för datan om nollhypotesen är sann. Om datan inte är i linje med nollhypotesen bör p-värdet bli lågt. Ofta används en förbestämd signifikansnivå på $0.05$ och vid p-värden under det talar man om ett *signifikant* utfall.

Hypotestestet är en allmän konstruktion och beroende på datatyp landar man i något specifikt test. I dagens datorövning tittar vi på följande test:

- För ett stickprov (en grupp)
  - t-test vid normalfördelad data
  - z-test vid binär data
  - $\chi^2$-test vid nominal data
- För två stickprov (jämföra två grupper)
  - t-test vid normalfördelad data
  - z-test vid binär data
  - $\chi^2$-test vid nominal data

För att illustrera de här testerna på en lite mer hanterbar datamängd drar vi slumpmässigt trettio observationer från pingvindatan.

```{r}
set.seed(437)
dat <- slice_sample(penguins, n = 30)
dat %>% print(n = 30)
```

## Ett stickprov

### Test av medelvärde för normalfördelad data

Om man har en normalfördelad variabel och vill testa om populationens medelvärde är skilt från något hypotetiskt värde $\mu_0$ kan man använda ett *t-test för ett stickprov*. För vårt urval av pingvindata vill vi se om vikten är skild från 4500 gram.

```{r, fig.height=2, fig.show='hide', results='hide'}
ggplot(dat, aes(body_mass_g, 0)) + 
  geom_point() +
  geom_vline(xintercept = 4500, color = "red", linewidth = 2)
```

I grafen ser vi att värdena ligger jämt spridda kring 4500, så 4500 är nog ganska rimligt som medelvärde, men låt oss göra ett formellt test. 
I R kan ett t-test genomföras med `t.test()`.

```{r}
t.test(dat$body_mass_g, mu = 4500)   # Ett t-test på variabeln body_mass_g
```

Utskriften ger ett p-värde från vilket vi kan dra en slutsats. I det här fallet är p-värdet högt (över fem procent) så vi kan inte förkasta nollhypotesen (vilken är att populationsmedelvärdet är lika med 4500).

Vi tittar nu på stegen bakom t-testet.
Ett t-test bygger, som alla hypotestest, på en serie steg:

1. sätt upp en *nollhypotes* och en *alternativhypotes*,
2. beräkna ett *testvärde* från en testfunktion,
3. identifiera en *testfördelning*,
4. beräkna ett *p-värde*, eller uppskatta ett genom att ställa testvärde mot ett kritiskt värde,
5. dra en klar *slutsats* om statistisk signifikans.

Vi vill testa om medelskörden är skild från 4500, så hypoteser ges av

- $H_0$: $\mu$ lika med 4500
- $H_1$: $\mu$ ej lika med 4500

Alternativhypotesen är tvåsidig - vi tittar både på möjligheten att populationsmedelvärdet är större och på möjligheten att det är mindre.

::: {.exercise name="Ensidig mothypotes"}
Hur hade hypoteserna sett ut om vi ville testa om medelvärdet är *större* än 4500?
:::

Vi kan ta fram stickprovsmedelvärde och standardavvikelse i R.

```{r}
mean(dat$body_mass_g)
sd(dat$body_mass_g)
```

Vårt mål är att testa ett medelvärde och det är rimligt att anta normalfördelning för den undersökta variabeln. Det lämpliga testet är då ett t-test för ett stickprov och testvärdet kan beräknas av en testfunktion som ges av det observerade stickprovet minus nollhypotesens värde, delat på standardavvikelsen delat på roten ur antalet observationer. 

$$t = \frac{\bar{y} - \mu_0}{s/\sqrt{n}}$$

::: {.exercise name="Handräkning"}
Beräkna t-värdet på miniräknare eller telefon. Finns det beräknade t-värdet i utskriften från `t.test()`?
:::

Nästa steg är att identifiera testfördelning, det vill säga den slumpfördelning testvärdet följet om nollhypotesen är sann. I det här fallet är testfördelningen en t-fördelning med n - 1 frihetsgrader. Vi har trettio observationer, så antalet frihetsgrader blir 29. I R kan man ta fram täthetsfunktionen för en t-fördelning med `dt()` och fördelningsfunktionen med `pt()`. Kurvorna kan plottas med `geom_function()` i en ggplot.

```{r, fig.height=2, results='hide', fig.show='hide'}
ggplot() +
  geom_function(fun = dt, args = list(df = 29)) +
  xlim(-5,5)

ggplot() +
  geom_function(fun = pt, args = list(df = 29)) +
  xlim(-5,5)
```

Från testfördelningen kan vi nu ta fram ett p-värde. P-värdet kan illustreras som ytan under t-fördelning *bortom* test-värdet. I ett tvåsidigt test tar vi med bägge svansarna.

```{r, fig.height=2, fig.show='hide'}
ggplot() +
  geom_function(fun = dt, args = list(df = 29)) +
  geom_vline(xintercept = c(-1.6203, 1.6203), 
             color = "red") +
  xlim(-5,5)
```

Ytorna i *svansarna* motsvarar p-värdet. De anger sannolikheten att få ett större t-värde än det vi fått, under antagandet att nollhypotesen stämmer. Det exakta p-värdet gavs av `t.test()`-funktionen som 0.116. En tolkning av det är om försöket upprepas ett stort antal gånger och nollhypotesen är sann, kommer vi 11.6 procent av gångerna få ett större testvärde än det observerade. Det vi observerar är ganska sannolikt om nollhypotesen stämmer, vilket tyder på att nollhypotesen är rimlig.

Det avslutande steget är att dra en formell slutsats och ge ett tydligt svar. Det beräknade p-värdet ställs mot en förbestämd signifikansnivå, oftast fem procent. Här är p-värdet över den nivån, så vi kan inte förkasta nollhyptesen. Slutsatsen är att det *inte* finns någon signifikant skillnad från 4500 i vikt.

::: {.exercise name="Kritiskt värde"}
Om man gör ett t-test för hand kan man inte enkelt ta fram ett p-värde, men kan se om p-värdet är större eller mindre än fem procent genom att ställa testvärdet mot ett kritiskt värde. Använd en tabell för t-fördelning för att hitta det kritiska värdet.

I R kan man ta fram kritiska värden med `qt()`. För fem procent i svansarna har man 0.025 i respektive svans och det kritiska värdet ges av

```{r, results='hide'}
qt(0.975, 29)
```
:::

::: {.exercise name="Ensidigt test"}
Använd `?t.test` för att ta fram funktionens hjälpsida. Försök att utifrån hjälpsidan beräkna ett *ensidigt* test för att se om medelvikten är *större* än 4500.
:::

### Konfidensintervall för normalfördelad data

Funktionen `t.test()` ger automatiskt ett konfidensintervall, direkt under utfallet av testet. Notera att konfidensintervallet inte beror på nollhypotesen. Konfidensintervall kan beräknas med skilda konfidensnivåer, oftast 95 procent, vilket sätts med argumentet `conf.level`.

::: {.exercise name="Konfidensnivå"}
Gör lämplig ändring i koden nedan för att beräkna ett 99-procentigt konfidensintervall, istället för ett 95-procentigt.

```{r}
t.test(dat$body_mass_g, conf.level = 0.95)
```

Är ett 99-procentigt konfidensintervall bredare eller smalare än ett 95-procentigt?
:::

### Ett stickprov av binär data

Binär data är data där en observation har ett av två utfall, vilka kan kodas som noll och ett. Man talar ibland om utfallet ett som ett *positivt* utfall. Binär data kan sammanfattas med en proportion - antalet positiva utfall delat på det totala antalet upprepningar. En proportion kan testas med ett z-test för proportioner (eller *relativ frekvens*). 

Vi tittar på könsfördelningen bland pingvinerna.

```{r, fig.show='hide'}
dat %>% count(sex)
```

Stickprovet har 16 honor av 30.

För att genomföra ett z-test sätter vi upp hypoteser om proportionen. I det här fallet vill vi testa om proportionen är 0.5.

- Nollhypotes $H_0$: p lika med 0.5
- Alternativhypotes $H_1$: p ej lika med 0.5

Ett test kan köras i R med `prop.test()`.

```{r}
prop.test(x = 16, n = 30, p = 0.5, correct = F)
```

P-värdet ställs mot en förbestämd signifikansnivå (vanligen 5 procent). I det här fallet leder det höga p-värdet till att nollhypotesen accepteras.

Om man beräknat för hand hade vi fått z-värdet. Det värdet i kvadrat är utskriftens `X-squared`.

```{r}
p0 <- 0.5
p <- 16/30
n <- 30
z_value <- (p - p0) / sqrt(p0 * (1 - p0) / n)
z_value^2
```

Testets p-värde är ungefär 71 procent. Vår observation är alltså inte ett orimligt utfall om den faktiska sannolikheten är 0.5 och vi kan inte förkasta nollhypotesen på femprocentsnivån.

Om man löste uppgiften för hand skulle man istället för att beräkna p-värdet jämföra z-värdet med ett kritisk värde ur en tabell. Det kritiska värdet för femprocentig signifikans är 1.96. Vi kan också ta fram det genom `qnorm(0.975)`.

Hypotestestet för proportioner som används här, *z-testet*, bygger på en normalapproximation av en binomialfördelning. Approximation blir bättre när antalet observationer är stort och nollhypotesens värde p0 ligger nära 0.5. En vanlig tumregel för när approximationen är giltig är att n gånger $p_0$ gånger $(1 - p_0)$ ska vara större än 10.

### Konfidensintervall för proportioner

Konstruktionen av ett konfidensintervall för en proportion är ganska lik konstruktionen för ett medelvärde. För en skattad proportion p och antal observationer n kan man beräkna p plus/minus ett z-värde från tabell gånger medelfelet, där medelfelet ges av roten ur $p \cdot (1 - p) / n$. 

Om man tittar på utskriften från `prop.test()` kan man se ett konfidensintervall. Det intervallet är dock inte beräknat på samma sätt den formel som förekommer på föreläsningarna. För att få matchande utskrift kan vi använda paketet `binom` och funktionen `binom.asymp()`.

```{r, results='hide'}
#install.packages("binom")
library(binom)
binom.asymp(x = 16, n = 30)
```

::: {.exercise name="99-procentigt konfidensintervall"}
Gör lämplig ändring i koden nedan för att beräkna ett 99-procentigt konfidensintervall för andelen bortasegrar.

```{r, eval = F}
binom.asymp(x = 16, n = 30, conf.level = 0.95)
```
:::

### Chi-två-test för goodness-of-fit

Ett proportionstest kan ses som ett test av en variabel med två möjliga klasser som utfall. Ett *goodness-of-fit*-test utvecklar det till valfritt antal klasser. Testet utförs som ett chi-två-test genom att beräkna ett observerat antal O och ett förväntat antal E för varje klass. Testvärdet ges av att man beräknar $(O - E)^2 / E$ för varje klass och sedan summerar. Testfunktionen är en chi-två-fördelning där antalet frihetsgrader beror på antalet klasser.

Vi illustrerar med pingvindatans fördelnings av arter. Vårt mål är att testa om arterna är lika vanliga.

```{r}
dat %>% count(species)
```

$H_0$: sannolikheterna för de olika utfallet ges av 33, 33 respektive 33 procent (lika vanliga arter)

$H_1$: minst något utfall har en annan sannolikhet än 33.

R har en inbyggd funktion för chi-två-test. Dess argument ges av observerade antal och sannolikheter.

```{r, results='hide'}
chisq.test(x = c(10, 8, 12), p = c(1/3, 1/3, 1/3))
```

Situationen med flera klasser kan som sagt ses som en generalisering av fallet med två klasser. Det är alltså logiskt att chi-två-test kan användas även när man har två klasser. Följande exempel ger samma test som vi sett tidigare av andelen honor.

```{r, results='hide'}
chisq.test(x = c(16, 14), p = c(0.5, 0.5), correct = F)
```

Likt `prop.test()` sätter vi `correct` till `FALSE` för att inte göra en korrektion. Notera att `x` här anges som positiva och negativa utfall istället för positiva utfall och totalt antal utfall, vilket var fallet i `prop.test()`.

Chi-två-testet bygger på en underliggande normal-liknande approximation. En vanlig tumregel är att alla förväntade värden ska vara större än 5. R ger en varning om så inte är fallet.

```{r, results='hide'}
chisq.test(c(6,4), p = c(0.51, 0.49))
```

::: {.exercise name="Chi-två med lika sannolikheter"}
En vanlig tillämpning av goodness-of-fit-testet är för att testa om alla klasser är lika sannolika. En jämn fördelning är grundinställning i `chisq.test()` så i det fallet behöver man bara ange de observerade värdena. En datainsamling om M&M-godis gav följande antal.

```{r, fig.show='hide'}
dat_mnm <- data.frame(Color = c("blue", "brown", "green", 
                                "orange", "red", "yellow"),
                      Count = c(180, 80, 88, 160, 134, 166))

ggplot(dat_mnm, aes(Color, Count, fill = Color)) +
  geom_col() +
  scale_fill_manual(values = dat_mnm$Color)
```

Använd de observerade värdena i kolumnen `Count` för att testa om alla godisfärger är lika vanliga.
:::

## Två stickprov 

### Test av normalfördelad data

Vid normalfördelad data från två stickprov eller grupper vill vi nästan alltid testa om populationerna har samma medelvärde. Det kan också ses som att vi testar om differensen mellan medelvärdena är noll. Vi skiljer mellan två fall: 

- *matchade stickprov* - där varje observation i den ena gruppen är *kopplad* till en observation i den andra gruppen; och 
- *oberoende stickprov* - där det inte finns någon sådan koppling mellan stickproven. 

Typiska exempel på matchade stickprov är när man mäter samma individ för och efter en behandling och syskonstudier där ett syskon får en behandling och den andra en annan behandling.

#### t-test för två matchade stickprov

Vid matchade stickprov kan varje observation i en behandlingsgrupp paras med en observation i den andra gruppen. Själva testet är ett t-test för *ett* stickprov på differensserien beräknat från varje par. I R kan man antingen beräkna den differensserien eller använda `t.test()` med två dataserier och argumentet för parvisa observationer satt till sant, `paired = T`.
Som exempel ges följande data från en studie på äpple, där trädhöjd mätts före och efter en näringsbehandling.

```{r, results='hide'}
dat_apple <- tibble(Tree = 1:4, 
              Before = c(48, 43, 30, 47), 
              After = c(51, 44, 42, 54))
dat_apple
```

Datan kan illustreras med ett punktdiagram där en linje binder samman paret. För att enkelt skapa grafen i `ggplot2` kan man först omstrukturera datan till lång form genom `pivot_longer`.

```{r, results='hide'}
dat_long <- dat_apple %>% 
  pivot_longer(-Tree, names_to = "Time", values_to = "Height")
dat_long
```

::: {.exercise name="Äppelgraf"}
Fyll i kodstycket nedan för en graf av äppeldatan. Axlarna ges av `Time` och `Height`. Två observationer kan kopplas genom att sätta `Tree` som grupp.
```{r, eval = F}
ggplot(dat_long, aes(___, ___, group = ___)) +
  geom_point() +
  geom_line()
```
:::

För att testa för skillnad före och efter behandling sätter vi upp hypoteser

- $H_0$: $\mu$ före behandling är lika med $\mu$ efter behandling
- $H_1$: $\mu$ före behandling är skild från $\mu$ efter behandling

Testet kan antingen utföras som ett enkelt t-test på differensserien

```{r, results='hide'}
t.test(dat_apple$Before - dat_apple$After)
```

eller som ett t-test för två stickprov där man särskilt anger att datan är parad

```{r, results='hide'}
t.test(dat_apple$Before, dat_apple$After, paired = T)
```

För bägge alternativen måste datan vara ordnad så att de två vektorerna matchar varandra parvis. Ett p-värde på $0.0987$ ger att man inte förkastar vid en signifikansnivå på fem procent. Vi drar därmed slutsatsen att det inte finns någon signifikant skillnad före och efter behandling.

::: {.exercise name="Ensidigt test"}
Gör ett tillägg till ett av kodstyckena med `t.test()` för att beräkna ett ensidigt test med mothypotesen att träden ökar i höjd efter behandling. Hjälpsidan för `t.test()` kan tas fram genom att köra `?t.test()`.
:::

Konfidensintervallet beräknas från differenserna på samma sätt som vid ett stickprov med normalfördelad data. Tolkningen liknar den för ett stickprov: med 95 procents konfidens ligger den sanna skillnaden i medelvärden i intervallet.

#### t-test för två oberoende stickprov

Ett t-test för två oberoende stickprov testar om två populationsmedelvärden är lika. Vi återvänder till pingvindatan och testar om honor och hanar har skild kroppsvikt.

```{r, fig.show='hide'}
ggplot(dat, aes(sex, body_mass_g)) +
  geom_point()

ggplot(dat, aes(sex, body_mass_g)) +
  geom_boxplot(width = 0.3)
```

Ett t-test för två oberoende stickprov har nollhypotesen att grupperna har samma populationsmedelvärde och alternativhypotesen att populationsmedelvärdena är skilda (för det tvåsidiga fallet):

- $H_0$: $\mu_A$ är lika med $\mu_B$
- $H_1$: $\mu_A$ är ej lika med $\mu_B$

Testet kan utföras i R genom funktionen `t.test()`. Data kan antingen anges som en formel med dess data `y ~ x, data = dat` (vilket man kan läsa som *y uppdelat efter grupper i x*) eller som två skilda vektorer. Det förra alternativet är oftast enklare om man har datan på lång form - med en kolumn som anger grupp.

För formen med formel ger det

```{r, results='hide'}
t.test(body_mass_g ~ sex, data = dat, var.equal = T)
```

och för formen med vektorer

```{r, results='hide'}
vikt_hon <- dat$body_mass_g[dat$sex == "female"]

vikt_han <- dat$body_mass_g[dat$sex == "male"]

t.test(vikt_hon, vikt_han, var.equal = T)
```

Argumentet `var.equal = T` används för att beräkna testet där gruppernas varianser antas vara lika. Grundinställningen är testet där varianser inte antas vara lika, så `t.test(body_mass_g ~ sex, data = dat)` ger ett lite annat resultat.

::: {.exercise name="Ej lika varianser"}
Vilka resultatvärden ändras i utskriften om man sätter `var.equal = F`?
:::

Testet ger ett p-värde på $0.1602$, vilket leder till att nollhypotesen inte förkastas på femprocentsnivån. Detta tyder på att det inte finns en viktskillnad mellan behandlingarna. Utskriften ger också ett 95-procentigt konfidensintervall. Tolkningen är att *skillnaden* mellan populationsmedelvärden ligger i intervallet med 95 procents konfidens. Notera att värdet noll ligger i intervallet.

Om man har fler än två grupper kan man vilja göra parvisa t-test - alltså ett t-test för varje par av grupper. 
Ett exempel på funktionen `pairwise.t.test()` ges nedan. Funktionen bygger på att datan är i *lång* form, med en kolumn som anger det numeriska utfallet och en kolumn som anger behandlingen. För att jämföra arter skulle man till exempel skriva följande.

```{r}
pairwise.t.test(dat$body_mass_g, dat$species, 
                p.adjust.method = "none", pool.sd = F)
```

*Matchade* observationer kan också kallas *parade* (eng. paired) så se upp med terminologin. Funktionen `pairwise.t.test()` för *parvisa jämförelse* mellan behandlingar, men testerna är t-test för oberoende stickprov.

### z-test och konfidensintervall för två proportioner

Om man vill jämföra två proportioner kan man använda z-testet för två stickprov. Bland pingvinerna kan vi ta fram antalet per kön per art med `count()`.

```{r}
dat %>% count(sex, species)
```

Säg att vi vill ställa Adelie (6 av 10 honor) mot övriga (10 av 20 honor).

- $H_0$: proportion A är lika med proportion B
- $H_1$: proportion A är skild från proportion B

I R kan testet genomföras med `prop.test()`-funktionen. Funktionens första argument är antalen honor, som en vektor med två värden, och dess andra argument är totalerna. Likt testet med ett stickprov finns en möjlighet att göra en kontinuitetskorrektion med `correct`-argumentet. För att få samma resultat som räkning för hand anger vi att korrektion inte ska göras med `correct = F`.

```{r, results='hide'}
prop.test(x = c(6, 10), n = c(10, 20), correct = F)
```

Notera att funktionen inte ger ett z-värde utan ett $\chi^2$-värde (utskrivet `X-squared`). Det beror på att funktionen beräknar z-testet som ett likvärdigt $\chi^2$-test. Det z-värde man får om man genomför testet som ett z-test är detsamma som roten ur utskriftens $\chi^2$-värde. Testet ger ett högt p-värde på 0.60 vilket innebär att nollhypotesen inte förkastas: det finns ingen signifikant skillnad i proportionen honor.

Funktionen `prop.test()` ger också en utskrift av konfidensintervallet. Tolkning är att skillnaden i proportioner mellan populationerna ligger i intervallet med 95 procents konfidens. Notera att nollan ingår i intervallet.

::: {.exercise name="Burfågel"}
Det finns en förvånansvärt stor mängd studier på kopplingen mellan innehav av burfågel och lungcancer. En sådan studie (Kohlmeier et al 1992) ger följande antal för burfågelägande och lungcancer.

```{r, echo = T, results='hide'}
dat_bird <- data.frame(Burfågel = c("Burfågel", "Ej_burfågel"),
              Lungcancer = c(98, 141),
              Ej_lungcancer = c(101, 328))
dat_bird
```

Datan tyder på att människor med burfågel har en förhöjd risk att drabbas av lungcancer. Genomför ett z-test för att se om andelen burfågelägare än densamma i de två patientgrupperna.

```{r, eval = F}
prop.test(x = c(___, ___), n = c(___, ___), correct = F)
```
:::

### Chi-två-test för korstabeller

Data med två kategoriska variabler kan presenteras med en korstabell. Vi tar uppdelningen av pingviner i kön och art.
En korstabell kan konstrueras med `pivot_wider`.

```{r, results='hide'}
dat_table <- dat %>% count(sex, species)
dat_table
dat_table_wide <- dat_table %>% 
  pivot_wider(values_from = n, names_from = sex)
dat_table_wide
```

Datan tyder inte på några större skillnader mellan arter. Vi kan illustrera med uppdelade staplar.

```{r, fig.show='hide'}
ggplot(dat_table, aes(species, n, fill = sex)) +
  geom_col(position = position_fill(), color = "black") +
  geom_text(aes(label = n), position = position_fill(0.5), size = 7) +
  scale_fill_manual(values = c("hotpink", "green"))
```

Argumentet `position` i `geom_bar()` används för att skapa proportionella staplar.

Ett chi-två-test på en korstabell har nollhypotesen att det inte finns något samband mellan variabeln för rader och variabeln för kolumner. Chi-två-testet kan tillämpas på korstabeller med godtyckligt antal rader och kolumner - det är alltså inte begränsat till fallet med jämförelse mellan två grupper. Antal frihetsgrader ges av antal rader minus ett gånger antal kolumner minus ett. Testet kan enkelt göras med `chisq.test()`. Som ingångsvärde kan man plocka ut kolumnerna med numeriska värden genom hakparenteser.

```{r, results='hide'}
dat_table_wide[, 2:3] # De två numeriska kolumnerna

chisq.test(dat_table_wide[, 2:3])
```

Utskriften ger teststorheten, antal frihetsgrader, och p-värdet. I det här fallet är p-värdet högt och slutsatsen blir att nollhypotesen inte förkastas - det finns inget signifikant samband mellan kön och art. Antalet frihetsgrader ges av antalet rader minus ett gånger antalet kolumner minus ett (här $(2-1) \cdot (3-1) = 2$).

Chi-två-testet är ett asymptotiskt test - dess egenskaper är beroende av *stora* stickprov. Som gräns för storleken används ofta att samtliga förväntade antal ska vara större än 5. Funktionen ger en varning om förväntade värden är små. En möjlig lösning i sådana fall är att slå ihop klasser.

Exemplet på pingvindatan har några små klasser och funktionen gav därför en varning.

::: {.exercise name="Burfågeln återvänder"}
En svensk studie på koppling mellan burfågel och lungcancer (Modigh et al, 1996) ger följande antal (för män).

```{r, results='hide'}
dat_bird_swe <- data.frame(Burfågel = c("Burfågel", "Ej_burfågel"),
              Lungcancer = c(108, 144),
              Ej_lungcancer = c(171, 256))
dat_bird_swe
```

Genomför ett chi-två-test för att se om andelen cancerdrabbade än densamma i de två burfågelsgrupperna. Formulera tydliga hypoteser. För att få utfall som stämmer med en handräkning kan man sätta `correct = F`.

```{r, eval = F}
dat_bird_swe[, c(2,3)]
chisq.test(___, correct = F)
```
:::

## AI-uppgift III

Det finns många studier som pekar på att p-värdet är svårtolkat. Det är särskilt vanligt att p-värdet tolkas som sannolikheten att nollhypotesen är sann. Den korrekta tolkningen är dock snarare tvärtom: p-värdet är sannolikheten för datautfallet givet att nollhypotesen är sann.

::: {.exercise name="Tolkning av p-värdet"}
Be en AI-chatbot besvara en t-test-fråga t.ex. från en tidigare tenta eller uppgiften i början av den här övningen. Fråga särskilt om tolkningen av p-värdet och om det finns några vanliga feltolkningar.
:::
